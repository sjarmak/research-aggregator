{
  "papers": [
    {
      "id": "paper-1",
      "bibcode": "2025.Paper.1",
      "title": "Efficient Code Search with Graph Neural Networks",
      "authors": [
        "Alice Smith",
        "Bob Jones"
      ],
      "abstract": "We present a new method for semantic code search using graph neural networks that outperforms existing baselines by 15%. Our approach leverages structural information from the abstract syntax tree.",
      "year": "2025",
      "publication": "ICSE 2025",
      "source": "ads",
      "ingestedAt": "2025-11-21T03:13:11.552Z",
      "libraryId": "lib-1"
    },
    {
      "id": "paper-2",
      "bibcode": "2025.Paper.2",
      "title": "LLM Agents for Automated Refactoring: A Case Study",
      "authors": [
        "Charlie Brown",
        "Diana Prince"
      ],
      "abstract": "This paper explores the effectiveness of LLM-based agents in large-scale code refactoring tasks. We find that agents can successfully handle 80% of routine refactoring but struggle with complex architectural changes.",
      "year": "2025",
      "publication": "ASE 2025",
      "source": "ads",
      "ingestedAt": "2025-11-21T03:13:11.552Z",
      "libraryId": "lib-1"
    },
    {
      "id": "paper-3",
      "bibcode": "2025.Paper.3",
      "title": "Retrieval Augmented Generation for Legacy Code Understanding",
      "authors": [
        "Eve White",
        "Frank Black"
      ],
      "abstract": "We propose a RAG-based framework for helping developers understand legacy COBOL systems. By indexing code and documentation, our system provides relevant context for modernization efforts.",
      "year": "2025",
      "publication": "FSE 2025",
      "source": "ads",
      "ingestedAt": "2025-11-21T03:13:11.552Z",
      "libraryId": "lib-1"
    }
  ],
  "articles": [
    {
      "id": "5e59a8e3a87a68eb8723077bd2fe1e05",
      "title": "OpenAI and Foxconn collaborate to strengthen U.S. manufacturing across the AI supply chain",
      "url": "https://openai.com/index/openai-and-foxconn-collaborate",
      "content": "OpenAI and Foxconn are collaborating to design and manufacture next-generation AI infrastructure hardware in the U.S. The partnership will develop multiple generations of data-center systems, strengthen U.S. supply chains, and build key components domestically to accelerate advanced AI infrastructure.",
      "summary": "OpenAI and Foxconn are collaborating to design and manufacture next-generation AI infrastructure hardware in the U.S. The partnership will develop multiple generations of data-center systems, strengthen U.S. supply chains, and build key components domestically to accelerate advanced AI infrastructure.",
      "publishedAt": "2025-11-20T14:50:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.006Z"
    },
    {
      "id": "72be2ab1ebb821913376387da739f8d4",
      "title": "Helping 1,000 small businesses build with AI",
      "url": "https://openai.com/index/small-business-ai-jam",
      "content": "OpenAI is partnering with DoorDash, SCORE, and local organizations to help 1,000 small businesses build with AI. The Small Business AI Jam gives Main Street business owners hands-on tools and training to compete and grow.",
      "summary": "OpenAI is partnering with DoorDash, SCORE, and local organizations to help 1,000 small businesses build with AI. The Small Business AI Jam gives Main Street business owners hands-on tools and training to compete and grow.",
      "publishedAt": "2025-11-20T06:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.006Z"
    },
    {
      "id": "0c40a000ff645391fcc87c00e55a58bd",
      "title": "Early experiments in accelerating science with GPT-5",
      "url": "https://openai.com/index/accelerating-science-gpt-5",
      "content": "OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math, physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover new insights, and reshape the pace of discovery.",
      "summary": "OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math, physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover new insights, and reshape the pace of discovery.",
      "publishedAt": "2025-11-20T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.006Z"
    },
    {
      "id": "0ebef0cfe225255149ed76d29443910d",
      "title": "Strengthening our safety ecosystem with external testing",
      "url": "https://openai.com/index/strengthening-safety-with-external-testing",
      "content": "OpenAI works with independent experts to evaluate frontier AI systems. Third-party testing strengthens safety, validates safeguards, and increases transparency in how we assess model capabilities and risks.",
      "summary": "OpenAI works with independent experts to evaluate frontier AI systems. Third-party testing strengthens safety, validates safeguards, and increases transparency in how we assess model capabilities and risks.",
      "publishedAt": "2025-11-19T12:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.006Z"
    },
    {
      "id": "2aba7a56124890447b62f7caad623b9d",
      "title": "How evals drive the next chapter in AI for businesses",
      "url": "https://openai.com/index/evals-drive-next-chapter-of-ai",
      "content": "Learn how evals help businesses define, measure, and improve AI performance—reducing risk, boosting productivity, and driving strategic advantage.",
      "summary": "Learn how evals help businesses define, measure, and improve AI performance—reducing risk, boosting productivity, and driving strategic advantage.",
      "publishedAt": "2025-11-19T11:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.006Z"
    },
    {
      "id": "94c1a542d3710b59d4d9aec07e4b9c31",
      "title": "OpenAI and Target team up on new AI-powered experiences",
      "url": "https://openai.com/index/target-partnership",
      "content": "OpenAI and Target are partnering to bring a new Target app to ChatGPT, offering personalized shopping and faster checkout. Target will also expand its use of ChatGPT Enterprise to boost productivity and guest experiences.",
      "summary": "OpenAI and Target are partnering to bring a new Target app to ChatGPT, offering personalized shopping and faster checkout. Target will also expand its use of ChatGPT Enterprise to boost productivity and guest experiences.",
      "publishedAt": "2025-11-19T06:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.006Z"
    },
    {
      "id": "8a6a49d607bcd5fa4da85f6781aec3aa",
      "title": "Building more with GPT-5.1-Codex-Max",
      "url": "https://openai.com/index/gpt-5-1-codex-max",
      "content": "Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed for long-running, project-scale work with enhanced reasoning and token efficiency.",
      "summary": "Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed for long-running, project-scale work with enhanced reasoning and token efficiency.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.006Z"
    },
    {
      "id": "2cebf18ae568df8657f35714cc29b1bc",
      "title": "GPT-5.1-Codex-Max System Card",
      "url": "https://openai.com/index/gpt-5-1-codex-max-system-card",
      "content": "This system card outlines the comprehensive safety measures implemented for GPT‑5.1-CodexMax. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.",
      "summary": "This system card outlines the comprehensive safety measures implemented for GPT‑5.1-CodexMax. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.006Z"
    },
    {
      "id": "e6949d4d910f746de520e1d46478a327",
      "title": "Teacher Access Terms",
      "url": "https://openai.com/policies/education-terms",
      "content": "Teacher Access Terms outline how verified educators may use ChatGPT for Teachers, covering eligibility, account management, and data privacy requirements.",
      "summary": "Teacher Access Terms outline how verified educators may use ChatGPT for Teachers, covering eligibility, account management, and data privacy requirements.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "10c90d7cc7819d97e798a3759b2b0abf",
      "title": "A free version of ChatGPT built for teachers",
      "url": "https://openai.com/index/chatgpt-for-teachers",
      "content": "ChatGPT for Teachers is a secure workspace with education‑grade privacy and admin controls. Free for verified U.S. K–12 educators through June 2027.",
      "summary": "ChatGPT for Teachers is a secure workspace with education‑grade privacy and admin controls. Free for verified U.S. K–12 educators through June 2027.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "17045c091cb6e6fcb5f6a7f519b1245e",
      "title": "How Scania is accelerating work with AI across its global workforce",
      "url": "https://openai.com/index/scania",
      "content": "Description: Global manufacturer Scania is scaling AI with ChatGPT Enterprise. With team-based onboarding and strong guardrails, AI is boosting productivity, quality, and innovation.",
      "summary": "Description: Global manufacturer Scania is scaling AI with ChatGPT Enterprise. With team-based onboarding and strong guardrails, AI is boosting productivity, quality, and innovation.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "b7f6337287f50eb44829e8f73a37876f",
      "title": "Intuit and OpenAI join forces on new AI-powered experiences",
      "url": "https://openai.com/index/intuit-partnership",
      "content": "OpenAI and Intuit have entered a $100M+ multi-year partnership to launch Intuit app experiences in ChatGPT and expand Intuit’s use of OpenAI’s frontier models to power personalized financial tools.",
      "summary": "OpenAI and Intuit have entered a $100M+ multi-year partnership to launch Intuit app experiences in ChatGPT and expand Intuit’s use of OpenAI’s frontier models to power personalized financial tools.",
      "publishedAt": "2025-11-18T05:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "0ee69ec84e3309ca88e2a257f13122c4",
      "title": "OpenAI named Emerging Leader in Generative AI",
      "url": "https://openai.com/index/gartner-2025-emerging-leader",
      "content": "OpenAI has been named an Emerging Leader in Gartner’s 2025 Innovation Guide for Generative AI Model Providers. The recognition reflects our enterprise momentum, with over 1 million companies building with ChatGPT.",
      "summary": "OpenAI has been named an Emerging Leader in Gartner’s 2025 Innovation Guide for Generative AI Model Providers. The recognition reflects our enterprise momentum, with over 1 million companies building with ChatGPT.",
      "publishedAt": "2025-11-17T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "41722a5599ac5dfac4a04db42448e49f",
      "title": "Introducing OpenAI for Ireland",
      "url": "https://openai.com/index/openai-for-ireland",
      "content": "OpenAI launches OpenAI for Ireland, partnering with the Irish Government, Dogpatch Labs and Patch to help SMEs, founders and young builders use AI to innovate, boost productivity and build the next generation of Irish tech startups.",
      "summary": "OpenAI launches OpenAI for Ireland, partnering with the Irish Government, Dogpatch Labs and Patch to help SMEs, founders and young builders use AI to innovate, boost productivity and build the next generation of Irish tech startups.",
      "publishedAt": "2025-11-14T04:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "965e60a14502559303595f93f6b0ee74",
      "title": "Understanding neural networks through sparse circuits",
      "url": "https://openai.com/index/understanding-neural-networks-through-sparse-circuits",
      "content": "OpenAI is exploring mechanistic interpretability to understand how neural networks reason. Our new sparse model approach could make AI systems more transparent and support safer, more reliable behavior.",
      "summary": "OpenAI is exploring mechanistic interpretability to understand how neural networks reason. Our new sparse model approach could make AI systems more transparent and support safer, more reliable behavior.",
      "publishedAt": "2025-11-13T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "a7818ab7bde93e745d5e7e936314b982",
      "title": "How Philips is scaling AI literacy across 70,000 employees",
      "url": "https://openai.com/index/philips",
      "content": "Philips is scaling AI literacy with ChatGPT Enterprise, training 70,000 employees to use AI responsibly and improve healthcare outcomes worldwide.",
      "summary": "Philips is scaling AI literacy with ChatGPT Enterprise, training 70,000 employees to use AI responsibly and improve healthcare outcomes worldwide.",
      "publishedAt": "2025-11-13T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "402d1c676b28ff91394671aa38a74c10",
      "title": "Introducing group chats in ChatGPT",
      "url": "https://openai.com/index/group-chats-in-chatgpt",
      "content": "We’re piloting group chats in ChatGPT to make collaboration simple. Bring others—and ChatGPT—into one shared conversation to plan, brainstorm, and create together.",
      "summary": "We’re piloting group chats in ChatGPT to make collaboration simple. Bring others—and ChatGPT—into one shared conversation to plan, brainstorm, and create together.",
      "publishedAt": "2025-11-13T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "c78557dbdad9b4f12ac173ddd735e477",
      "title": "Introducing GPT-5.1 for developers",
      "url": "https://openai.com/index/gpt-5-1-for-developers",
      "content": "GPT-5.1 is now available in the API, bringing faster adaptive reasoning, extended prompt caching, improved coding performance, and new apply_patch and shell tools.",
      "summary": "GPT-5.1 is now available in the API, bringing faster adaptive reasoning, extended prompt caching, improved coding performance, and new apply_patch and shell tools.",
      "publishedAt": "2025-11-13T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "39cff7c19932507f265b3e9ed2a3a7c3",
      "title": "Neuro drives national retail wins with ChatGPT Business",
      "url": "https://openai.com/index/neurogum",
      "content": "Neuro uses ChatGPT Business to scale nationwide with fewer than seventy employees. From drafting contracts to uncovering insights in customer data, the team saves time, cuts costs, and turns ideas into growth.",
      "summary": "Neuro uses ChatGPT Business to scale nationwide with fewer than seventy employees. From drafting contracts to uncovering insights in customer data, the team saves time, cuts costs, and turns ideas into growth.",
      "publishedAt": "2025-11-12T11:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "b377a85ca19b7ac5211137128691f9b5",
      "title": "Fighting the New York Times’ invasion of user privacy",
      "url": "https://openai.com/index/fighting-nyt-user-privacy-invasion",
      "content": "OpenAI is fighting the New York Times’ demand for 20 million private ChatGPT conversations and accelerating new security and privacy protections to protect your data.",
      "summary": "OpenAI is fighting the New York Times’ demand for 20 million private ChatGPT conversations and accelerating new security and privacy protections to protect your data.",
      "publishedAt": "2025-11-12T06:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "9cbe22667b832a7e186116d4a4eebc4c",
      "title": "GPT-5.1: A smarter, more conversational ChatGPT",
      "url": "https://openai.com/index/gpt-5-1",
      "content": "We’re upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPT’s tone and style. GPT-5.1 starts rolling out today to paid users.",
      "summary": "We’re upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPT’s tone and style. GPT-5.1 starts rolling out today to paid users.",
      "publishedAt": "2025-11-12T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "36ade2f70cc53016a3448fc3a473cc35",
      "title": "GPT-5.1 Instant and GPT-5.1 Thinking System Card Addendum",
      "url": "https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1",
      "content": "This GPT-5 system card addendum provides updated safety metrics for GPT-5.1 Instant and Thinking, including new evaluations for mental health and emotional reliance.",
      "summary": "This GPT-5 system card addendum provides updated safety metrics for GPT-5.1 Instant and Thinking, including new evaluations for mental health and emotional reliance.",
      "publishedAt": "2025-11-12T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "963896ca7550df724537c1d3a3f6fb07",
      "title": "Free ChatGPT for transitioning U.S. servicemembers and veterans",
      "url": "https://openai.com/index/chatgpt-for-veterans",
      "content": "OpenAI is offering U.S. servicemembers and veterans within 12 months of retirement or separation a free year of ChatGPT Plus to support their transition to civilian life. The tools can help with resumes, interviews, education, and planning for what’s next.",
      "summary": "OpenAI is offering U.S. servicemembers and veterans within 12 months of retirement or separation a free year of ChatGPT Plus to support their transition to civilian life. The tools can help with resumes, interviews, education, and planning for what’s next.",
      "publishedAt": "2025-11-10T02:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "fe9a5f2a83a904e45e648632b6863145",
      "title": "Understanding prompt injections: a frontier security challenge ",
      "url": "https://openai.com/index/prompt-injections",
      "content": "Prompt injections are a frontier security challenge for AI systems. Learn how these attacks work and how OpenAI is advancing research, training models, and building safeguards for users.",
      "summary": "Prompt injections are a frontier security challenge for AI systems. Learn how these attacks work and how OpenAI is advancing research, training models, and building safeguards for users.",
      "publishedAt": "2025-11-07T11:30:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "fbb44934033164d0cf9a7af53ff519bc",
      "title": "Notion’s rebuild for agentic AI: How GPT‑5 helped unlock autonomous workflows",
      "url": "https://openai.com/index/notion",
      "content": "Discover how Notion rebuilt its AI architecture with GPT-5 to create autonomous agents that reason, act, and adapt across workflows. Learn how this shift unlocked smarter, faster, and more flexible productivity in Notion 3.0.",
      "summary": "Discover how Notion rebuilt its AI architecture with GPT-5 to create autonomous agents that reason, act, and adapt across workflows. Learn how this shift unlocked smarter, faster, and more flexible productivity in Notion 3.0.",
      "publishedAt": "2025-11-07T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "79d8d3cdcb4b7b140ef6ae2a79cbfb99",
      "title": "From Pilot to Practice: How BBVA Is Scaling AI Across the Organization",
      "url": "https://openai.com/index/bbva-2025",
      "content": "BBVA is reimagining how employees work with ChatGPT Enterprise, embedding AI into everyday operations. The bank has saved hours per week per employee, created 20,000+ Custom GPTs, and achieved up to 80% efficiency gains.",
      "summary": "BBVA is reimagining how employees work with ChatGPT Enterprise, embedding AI into everyday operations. The bank has saved hours per week per employee, created 20,000+ Custom GPTs, and achieved up to 80% efficiency gains.",
      "publishedAt": "2025-11-06T09:30:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "98b1ba064888fdf56902e113065c3f82",
      "title": "AI progress and recommendations",
      "url": "https://openai.com/index/ai-progress-and-recommendations",
      "content": "AI is advancing fast. We have the chance to shape its progress—toward discovery, safety, and a better future for everyone.",
      "summary": "AI is advancing fast. We have the chance to shape its progress—toward discovery, safety, and a better future for everyone.",
      "publishedAt": "2025-11-06T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "18d486d98d8e15ab9bd6e59a4cf8fb68",
      "title": "Introducing the Teen Safety Blueprint",
      "url": "https://openai.com/index/introducing-the-teen-safety-blueprint",
      "content": "Discover OpenAI’s Teen Safety Blueprint—a roadmap for building AI responsibly with safeguards, age-appropriate design, and collaboration to protect and empower young people online.",
      "summary": "Discover OpenAI’s Teen Safety Blueprint—a roadmap for building AI responsibly with safeguards, age-appropriate design, and collaboration to protect and empower young people online.",
      "publishedAt": "2025-11-06T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "b0c322f8b9c6c755a6cdaa6ded1b80bb",
      "title": "How CRED is tapping AI to deliver premium customer experiences",
      "url": "https://openai.com/index/cred-swamy-seetharaman",
      "content": "CRED is transforming premium customer experiences in India with OpenAI. Using GPT-powered tools, the company is improving support accuracy, reducing response times, and boosting customer satisfaction. ",
      "summary": "CRED is transforming premium customer experiences in India with OpenAI. Using GPT-powered tools, the company is improving support accuracy, reducing response times, and boosting customer satisfaction.",
      "publishedAt": "2025-11-05T21:30:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "903883be1da5291d9c594b8e86c84af9",
      "title": "How Chime is redefining marketing through AI",
      "url": "https://openai.com/index/chime-vineet-mehra",
      "content": "Vineet Mehra, Chief Marketing Officer at Chime, shares how AI is reshaping marketing into an agent-driven discipline. He explains why CMOs who champion AI literacy and thoughtful adoption will lead in the new era of growth.",
      "summary": "Vineet Mehra, Chief Marketing Officer at Chime, shares how AI is reshaping marketing into an agent-driven discipline. He explains why CMOs who champion AI literacy and thoughtful adoption will lead in the new era of growth.",
      "publishedAt": "2025-11-05T15:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "0116832adda7180dde75dfc8f43bf0e9",
      "title": "1 million business customers putting AI to work",
      "url": "https://openai.com/index/1-million-businesses-putting-ai-to-work",
      "content": "More than 1 million business customers around the world now use OpenAI. Across healthcare, life sciences, financial services, and more, ChatGPT and our APIs are driving a new era of intelligent, AI-powered work.",
      "summary": "More than 1 million business customers around the world now use OpenAI. Across healthcare, life sciences, financial services, and more, ChatGPT and our APIs are driving a new era of intelligent, AI-powered work.",
      "publishedAt": "2025-11-05T05:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "cfa7130eb87b757a8f3079190eb6c6b6",
      "title": "Brazil’s AI moment is here",
      "url": "https://openai.com/global-affairs/brazil-ai-moment-is-here",
      "content": "Brazil is now one of the most engaged countries in the world when it comes to AI. From classrooms to farms and small businesses, Brazilians are using OpenAI products to learn, create, and drive innovation.",
      "summary": "Brazil is now one of the most engaged countries in the world when it comes to AI. From classrooms to farms and small businesses, Brazilians are using OpenAI products to learn, create, and drive innovation.",
      "publishedAt": "2025-11-04T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "5f20663e3457bcdb3265601be63b85dd",
      "title": "Introducing IndQA",
      "url": "https://openai.com/index/introducing-indqa",
      "content": "OpenAI introduces IndQA, a new benchmark for evaluating AI systems in Indian languages. Built with domain experts, IndQA tests cultural understanding and reasoning across 12 languages and 10 knowledge areas.",
      "summary": "OpenAI introduces IndQA, a new benchmark for evaluating AI systems in Indian languages. Built with domain experts, IndQA tests cultural understanding and reasoning across 12 languages and 10 knowledge areas.",
      "publishedAt": "2025-11-03T22:30:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "e68f6330a84831492f791da1bba7c027",
      "title": "AWS and OpenAI announce multi-year strategic partnership",
      "url": "https://openai.com/index/aws-and-openai-partnership",
      "content": "OpenAI and AWS have entered a multi-year, $38 billion partnership to scale advanced AI workloads. AWS will provide world-class infrastructure and compute capacity to power OpenAI’s next generation of models.",
      "summary": "OpenAI and AWS have entered a multi-year, $38 billion partnership to scale advanced AI workloads. AWS will provide world-class infrastructure and compute capacity to power OpenAI’s next generation of models.",
      "publishedAt": "2025-11-03T06:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "505e58f8ab61940d5c691b82e6f50f7e",
      "title": "Expanding Stargate to Michigan",
      "url": "https://openai.com/index/expanding-stargate-to-michigan",
      "content": "OpenAI is expanding Stargate to Michigan with a new one-gigawatt campus that strengthens America’s AI infrastructure. The project will create jobs, drive investment, and support economic growth across the Midwest.",
      "summary": "OpenAI is expanding Stargate to Michigan with a new one-gigawatt campus that strengthens America’s AI infrastructure. The project will create jobs, drive investment, and support economic growth across the Midwest.",
      "publishedAt": "2025-10-30T13:30:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "c4440d30b857fbf5c0a2e557dd7047c2",
      "title": "Introducing Aardvark: OpenAI’s agentic security researcher",
      "url": "https://openai.com/index/introducing-aardvark",
      "content": "OpenAI introduces Aardvark, an AI-powered security researcher that autonomously finds, validates, and helps fix software vulnerabilities at scale. The system is in private beta—sign up to join early testing.",
      "summary": "OpenAI introduces Aardvark, an AI-powered security researcher that autonomously finds, validates, and helps fix software vulnerabilities at scale. The system is in private beta—sign up to join early testing.",
      "publishedAt": "2025-10-30T11:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "da48b434eb0d31b33c96b13edca512c6",
      "title": "How we built OWL, the new architecture behind our ChatGPT-based browser, Atlas",
      "url": "https://openai.com/index/building-chatgpt-atlas",
      "content": "A deep dive into OWL, the new architecture powering ChatGPT Atlas—decoupling Chromium, enabling fast startup, rich UI, and agentic browsing with ChatGPT.",
      "summary": "A deep dive into OWL, the new architecture powering ChatGPT Atlas—decoupling Chromium, enabling fast startup, rich UI, and agentic browsing with ChatGPT.",
      "publishedAt": "2025-10-30T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "38a263f439fa2281877e4af4ff39e33c",
      "title": "Technical Report: Performance and baseline evaluations of gpt-oss-safeguard-120b and gpt-oss-safeguard-20b",
      "url": "https://openai.com/index/gpt-oss-safeguard-technical-report",
      "content": "gpt-oss-safeguard-120b and gpt-oss-safeguard-20b are two open-weight reasoning models post-trained from the gpt-oss models and trained to reason from a provided policy in order to label content under that policy. In this report, we describe gpt-oss-safeguard’s capabilities and provide our baseline safety evaluations on the gpt-oss-safeguard models, using the underlying gpt-oss models as a baseline. For more information about the development and architecture of the underlying gpt-oss models, see the original gpt-oss model model card⁠.",
      "summary": "gpt-oss-safeguard-120b and gpt-oss-safeguard-20b are two open-weight reasoning models post-trained from the gpt-oss models and trained to reason from a provided policy in order to label content under that policy. In this report, we describe gpt-oss-safeguard’s capabilities and provide our baseline safety evaluations on the gpt-oss-safeguard models, using the underlying gpt-oss models as a baseline. For more information about the development and architecture of the underlying gpt-oss models, see the original gpt-oss model model card⁠.",
      "publishedAt": "2025-10-29T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "d210a60ba3c9ac11de685cfaad8c759f",
      "title": "Introducing gpt-oss-safeguard",
      "url": "https://openai.com/index/introducing-gpt-oss-safeguard",
      "content": "OpenAI introduces gpt-oss-safeguard—open-weight reasoning models for safety classification that let developers apply and iterate on custom policies.",
      "summary": "OpenAI introduces gpt-oss-safeguard—open-weight reasoning models for safety classification that let developers apply and iterate on custom policies.",
      "publishedAt": "2025-10-29T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "d0aeb835ebcc55244a78cab0dea6c915",
      "title": "Knowledge preservation powered by ChatGPT",
      "url": "https://openai.com/index/dai-nippon-printing",
      "content": "Dai Nippon Printing (DNP) rolled out ChatGPT Enterprise across ten core departments to drive companywide adoption. Within three months, it achieved 95% faster patent research, 10x processing volume, 100% weekly active usage, 87% automation, and 70% knowledge reuse.",
      "summary": "Dai Nippon Printing (DNP) rolled out ChatGPT Enterprise across ten core departments to drive companywide adoption. Within three months, it achieved 95% faster patent research, 10x processing volume, 100% weekly active usage, 87% automation, and 70% knowledge reuse.",
      "publishedAt": "2025-10-28T17:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "c9a5421993a12907c5ef4f4b2a1bbb29",
      "title": "Doppel’s AI defense system stops attacks before they spread",
      "url": "https://openai.com/index/doppel",
      "content": "Discover how Doppel uses OpenAI’s GPT-5 and reinforcement fine-tuning (RFT) to stop deepfake and impersonation attacks before they spread, cutting analyst workloads by 80% and reducing threat response from hours to minutes.",
      "summary": "Discover how Doppel uses OpenAI’s GPT-5 and reinforcement fine-tuning (RFT) to stop deepfake and impersonation attacks before they spread, cutting analyst workloads by 80% and reducing threat response from hours to minutes.",
      "publishedAt": "2025-10-28T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "3b1dccf662884f705b8f3ee8f71556ad",
      "title": "Built to benefit everyone",
      "url": "https://openai.com/index/built-to-benefit-everyone",
      "content": "OpenAI’s recapitalization strengthens mission-focused governance, expanding resources to ensure AI benefits everyone while advancing innovation responsibly.",
      "summary": "OpenAI’s recapitalization strengthens mission-focused governance, expanding resources to ensure AI benefits everyone while advancing innovation responsibly.",
      "publishedAt": "2025-10-28T06:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "e38d1cab2aaf508a8f8c92e705c84a1e",
      "title": "The next chapter of the Microsoft–OpenAI partnership",
      "url": "https://openai.com/index/next-chapter-of-microsoft-openai-partnership",
      "content": "Microsoft and OpenAI sign a new agreement that strengthens its long-term partnership, expands innovation, and ensures responsible AI progress.",
      "summary": "Microsoft and OpenAI sign a new agreement that strengthens its long-term partnership, expands innovation, and ensures responsible AI progress.",
      "publishedAt": "2025-10-28T06:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "0b114fe032efff2c9e404ee3519459ad",
      "title": "Seizing the AI opportunity",
      "url": "https://openai.com/global-affairs/seizing-the-ai-opportunity",
      "content": "Meeting the demands of the Intelligence Age will require strategic investment in energy and infrastructure. OpenAI’s submission to the White House details how expanding capacity and workforce readiness can sustain U.S. leadership in AI and economic growth.",
      "summary": "Meeting the demands of the Intelligence Age will require strategic investment in energy and infrastructure. OpenAI’s submission to the White House details how expanding capacity and workforce readiness can sustain U.S. leadership in AI and economic growth.",
      "publishedAt": "2025-10-27T12:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "645cb42d567084e0db8ca964b86b17cb",
      "title": "Addendum to GPT-5 System Card: Sensitive conversations",
      "url": "https://openai.com/index/gpt-5-system-card-sensitive-conversations",
      "content": "This system card details GPT-5’s improvements in handling sensitive conversations, including new benchmarks for emotional reliance, mental health, and jailbreak resistance.",
      "summary": "This system card details GPT-5’s improvements in handling sensitive conversations, including new benchmarks for emotional reliance, mental health, and jailbreak resistance.",
      "publishedAt": "2025-10-27T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "0b4d41f3f0256100b027dc00b4f17856",
      "title": "Strengthening ChatGPT’s responses in sensitive conversations",
      "url": "https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations",
      "content": "OpenAI collaborated with 170+ mental health experts to improve ChatGPT’s ability to recognize distress, respond empathetically, and guide users toward real-world support—reducing unsafe responses by up to 80%. Learn how we’re making ChatGPT safer and more supportive in sensitive moments.",
      "summary": "OpenAI collaborated with 170+ mental health experts to improve ChatGPT’s ability to recognize distress, respond empathetically, and guide users toward real-world support—reducing unsafe responses by up to 80%. Learn how we’re making ChatGPT safer and more supportive in sensitive moments.",
      "publishedAt": "2025-10-27T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "530334a2b1f084930d8c41f1f42dbc97",
      "title": "A law and tax firm redefines efficiency with ChatGPT Business",
      "url": "https://openai.com/index/steuerrecht",
      "content": "Learn how Steuerrecht.com uses ChatGPT Business to streamline legal workflows, automate tax research, and scale client service—helping law firms boost productivity and stay competitive.",
      "summary": "Learn how Steuerrecht.com uses ChatGPT Business to streamline legal workflows, automate tax research, and scale client service—helping law firms boost productivity and stay competitive.",
      "publishedAt": "2025-10-27T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "56c92596194fcf972d95186fa117d291",
      "title": "OpenAI acquires Software Applications Incorporated, maker of Sky",
      "url": "https://openai.com/index/openai-acquires-software-applications-incorporated",
      "content": "OpenAI has acquired Software Applications Incorporated, maker of Sky—a natural language interface for Mac that brings AI directly into your desktop experience. Together, we’re integrating Sky’s deep macOS capabilities into ChatGPT to make AI more intuitive, contextual, and action-oriented.",
      "summary": "OpenAI has acquired Software Applications Incorporated, maker of Sky—a natural language interface for Mac that brings AI directly into your desktop experience. Together, we’re integrating Sky’s deep macOS capabilities into ChatGPT to make AI more intuitive, contextual, and action-oriented.",
      "publishedAt": "2025-10-23T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "64b3f66ab547fb2f8b4bad62612426e1",
      "title": "Consensus accelerates research with GPT-5 and Responses API",
      "url": "https://openai.com/index/consensus",
      "content": "Consensus uses GPT-5 and OpenAI’s Responses API to power a multi-agent research assistant that reads, analyzes, and synthesizes evidence in minutes—helping over 8 million researchers accelerate scientific discovery.",
      "summary": "Consensus uses GPT-5 and OpenAI’s Responses API to power a multi-agent research assistant that reads, analyzes, and synthesizes evidence in minutes—helping over 8 million researchers accelerate scientific discovery.",
      "publishedAt": "2025-10-23T09:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "98db91455deebf842653cbcf27fddc0c",
      "title": "AI in South Korea—OpenAI’s Economic Blueprint",
      "url": "https://openai.com/index/south-korea-economic-blueprint",
      "content": "OpenAI's Korea Economic Blueprint outlines how South Korea can scale trusted AI through sovereign capabilities and strategic partnerships to drive growth.",
      "summary": "OpenAI's Korea Economic Blueprint outlines how South Korea can scale trusted AI through sovereign capabilities and strategic partnerships to drive growth.",
      "publishedAt": "2025-10-23T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "6cab6185e60b3c00f2df28ddd700a237",
      "title": "Work smarter with your company knowledge in ChatGPT",
      "url": "https://openai.com/index/introducing-company-knowledge",
      "content": "Company knowledge brings context from your apps into ChatGPT for answers specific to your business, with clear citations, security, privacy, and admin controls. Available now for Business, Enterprise, and Edu users.",
      "summary": "Company knowledge brings context from your apps into ChatGPT for answers specific to your business, with clear citations, security, privacy, and admin controls. Available now for Business, Enterprise, and Edu users.",
      "publishedAt": "2025-10-23T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "9e3769b2689a02b5c992bdc0aeeeff10",
      "title": "The next chapter for UK sovereign AI",
      "url": "https://openai.com/index/the-next-chapter-for-uk-sovereign-ai",
      "content": "OpenAI expands its UK partnership with a new Ministry of Justice agreement, bringing ChatGPT to civil servants. It also introduces UK data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform to support trusted and secure AI adoption.",
      "summary": "OpenAI expands its UK partnership with a new Ministry of Justice agreement, bringing ChatGPT to civil servants. It also introduces UK data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform to support trusted and secure AI adoption.",
      "publishedAt": "2025-10-22T16:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI Research",
      "ingestedAt": "2025-11-21T02:45:16.007Z"
    },
    {
      "id": "9cca8146ae73267e0b074e418633b311",
      "title": "Breaking Through Reinforcement Learning Training Limits with Scaling Rollouts in BroRL",
      "url": "https://developer.nvidia.com/blog/breaking-through-rl-training-limits-with-scaling-rollouts-in-brorl/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-jpg.webp 1209w\" sizes=\"(max-width: 768px) 100vw, 768px\" title=\"llm-training\" />When training large language models (LLMs) with reinforcement learning from verifiable rewards (RLVR), one of the most compelling questions is how to overcome...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/llm-training-jpg.webp 1209w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"llm-training\" /><p>When training large language models (LLMs) with reinforcement learning from verifiable rewards (RLVR), one of the most compelling questions is how to overcome performance plateaus. The previous NVIDIA Research solution, Prolonged Reinforcement Learning (ProRL), showed that adding more reinforcement learning (RL) steps during prolonged training could expand the reasoning boundaries of LLMs.</p>\n<p><a href=\"https://developer.nvidia.com/blog/breaking-through-rl-training-limits-with-scaling-rollouts-in-brorl/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "When training large language models (LLMs) with reinforcement learning from verifiable rewards (RLVR), one of the most compelling questions is how to overcome...\nWhen training large language models (LLMs) with reinforcement learning from verifiable rewards (RLVR), one of the most compelling questions is how to overcome performance plateaus. The previous NVIDIA Research solution, Prolonged Reinforcement Learning (ProRL), showed that adding more reinforcement learning (RL) steps during prolonged training could expand the reasoning boundaries of LLMs.\nSource",
      "publishedAt": "2025-11-19T21:51:12.000Z",
      "author": "Jian Hu",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "9d5f5d69608e84e1643ae4c15bd4438e",
      "title": "Building Better Qubits with GPU-Accelerated Computing",
      "url": "https://developer.nvidia.com/blog/building-better-qubits-with-gpu-accelerated-computing/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"image8\" />Quantum computing promises to revolutionize science and industry, from drug discovery to materials science. But building a useful, large-scale quantum computer...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image8-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"image8\" /><p>Quantum computing promises to revolutionize science and industry, from drug discovery to materials science. But building a useful, large-scale quantum computer is a significant engineering challenge, particularly when it comes to designing qubits that are less susceptible to noise. In traditional chip design, the modern semiconductor industry relies on Electronic Design Automation (EDA)…</p>\n<p><a href=\"https://developer.nvidia.com/blog/building-better-qubits-with-gpu-accelerated-computing/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Quantum computing promises to revolutionize science and industry, from drug discovery to materials science. But building a useful, large-scale quantum computer...\nQuantum computing promises to revolutionize science and industry, from drug discovery to materials science. But building a useful, large-scale quantum computer is a significant engineering challenge, particularly when it comes to designing qubits that are less susceptible to noise. In traditional chip design, the modern semiconductor industry relies on Electronic Design Automation (EDA)…\nSource",
      "publishedAt": "2025-11-19T17:00:00.000Z",
      "author": "Zhi (Jackie) Yao",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "485e7ccb21b6a2303143c565b0932e5c",
      "title": "Building Scalable AI on Enterprise Data with NVIDIA Nemotron RAG and Microsoft SQL Server 2025",
      "url": "https://developer.nvidia.com/blog/building-scalable-ai-on-enterprise-data-with-nvidia-nemotron-rag-and-microsoft-sql-server-2025/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-png.webp 1209w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"genai-nemotron\" />At Microsoft Ignite 2025, the vision for an AI-ready enterprise database becomes a reality with the announcement of Microsoft SQL Server 2025, giving developers...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/genai-nemotron-1-png.webp 1209w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"genai-nemotron\" /><p>At Microsoft Ignite 2025, the vision for an AI-ready enterprise database becomes a reality with the announcement of Microsoft SQL Server 2025, giving developers powerful new tools like built-in vector search and SQL native APIs to call external AI models. NVIDIA has partnered with Microsoft to seamlessly connect SQL Server 2025 with the NVIDIA Nemotron RAG collection of open models.</p>\n<p><a href=\"https://developer.nvidia.com/blog/building-scalable-ai-on-enterprise-data-with-nvidia-nemotron-rag-and-microsoft-sql-server-2025/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "At Microsoft Ignite 2025, the vision for an AI-ready enterprise database becomes a reality with the announcement of Microsoft SQL Server 2025, giving developers...\nAt Microsoft Ignite 2025, the vision for an AI-ready enterprise database becomes a reality with the announcement of Microsoft SQL Server 2025, giving developers powerful new tools like built-in vector search and SQL native APIs to call external AI models. NVIDIA has partnered with Microsoft to seamlessly connect SQL Server 2025 with the NVIDIA Nemotron RAG collection of open models.\nSource",
      "publishedAt": "2025-11-18T20:00:00.000Z",
      "author": "Uttara Kumar",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "8e68df86731ca1a8294de3ada17e68da",
      "title": "Faster Chemistry and Materials Discovery with AI-Powered Simulations Using NVIDIA ALCHEMI",
      "url": "https://developer.nvidia.com/blog/faster-chemistry-and-materials-discovery-with-ai-powered-simulations-using-nvidia-alchemi/",
      "content": "<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ALCHEMI-Molecules-1.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"ALCHEMI-Molecules\" />Almost all manufactured products are enabled by chemistry and materials science. However, new discoveries are costly and time-consuming and often hindered by...<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ALCHEMI-Molecules-1.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"ALCHEMI-Molecules\" /><p>Almost all manufactured products are enabled by chemistry and materials science. However, new discoveries are costly and time-consuming and often hindered by trial-and-error approaches. Computational methods such as molecular dynamics with classical force fields traditionally struggle to predict chemical properties and stability accurately. NVIDIA ALCHEMI (AI Lab for Chemistry and Materials…</p>\n<p><a href=\"https://developer.nvidia.com/blog/faster-chemistry-and-materials-discovery-with-ai-powered-simulations-using-nvidia-alchemi/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Almost all manufactured products are enabled by chemistry and materials science. However, new discoveries are costly and time-consuming and often hindered by...\nAlmost all manufactured products are enabled by chemistry and materials science. However, new discoveries are costly and time-consuming and often hindered by trial-and-error approaches. Computational methods such as molecular dynamics with classical force fields traditionally struggle to predict chemical properties and stability accurately. NVIDIA ALCHEMI (AI Lab for Chemistry and Materials…\nSource",
      "publishedAt": "2025-11-18T17:00:00.000Z",
      "author": "Wen Jie Ong",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "ae7c1da662133cdf9ee92bd27d38bf41",
      "title": "NVIDIA NVQLink Architecture Integrates Accelerated Computing with Quantum Processors",
      "url": "https://developer.nvidia.com/blog/nvidia-nvqlink-architecture-integrates-accelerated-computing-with-quantum-processors/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-jpg.webp 1209w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"nvqlink\" />Quantum computing is entering an era where progress will be driven by the integration of accelerated computing with quantum processors. The hardware that...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/nvqlink-1-jpg.webp 1209w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"nvqlink\" /><p>Quantum computing is entering an era where progress will be driven by the integration of accelerated computing with quantum processors. The hardware that controls and measures a quantum processing unit (QPU) faces demanding computational requirements—from real-time calibration to quantum error-correction (QEC) decoding. Useful quantum applications will require QEC and calibration at scales only…</p>\n<p><a href=\"https://developer.nvidia.com/blog/nvidia-nvqlink-architecture-integrates-accelerated-computing-with-quantum-processors/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Quantum computing is entering an era where progress will be driven by the integration of accelerated computing with quantum processors. The hardware that...\nQuantum computing is entering an era where progress will be driven by the integration of accelerated computing with quantum processors. The hardware that controls and measures a quantum processing unit (QPU) faces demanding computational requirements—from real-time calibration to quantum error-correction (QEC) decoding. Useful quantum applications will require QEC and calibration at scales only…\nSource",
      "publishedAt": "2025-11-17T22:31:00.000Z",
      "author": "Shane Caldwell",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "7f697db14bc655c6ea8359ee23c4855f",
      "title": "Pioneering AI Co-Scientists for Fusion Research and Cancer Treatment",
      "url": "https://developer.nvidia.com/blog/pioneering-ai-co-scientists-for-fusion-research-and-cancer-treatment/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"lanl-ai-agents-science\" />AI is reshaping scientific research and innovation. Scientists can leverage AI to generate, summarize, combine, and analyze scientific data. AI models can find...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/lanl-ai-agents-science-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"lanl-ai-agents-science\" /><p>AI is reshaping scientific research and innovation. Scientists can leverage AI to generate, summarize, combine, and analyze scientific data. AI models can find patterns in data that human scientists have overlooked, find connections between seemingly unrelated fields and phenomena, and even propose new hypotheses to be tested. An AI co-scientist is a collaborative, multi-agent AI system…</p>\n<p><a href=\"https://developer.nvidia.com/blog/pioneering-ai-co-scientists-for-fusion-research-and-cancer-treatment/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "AI is reshaping scientific research and innovation. Scientists can leverage AI to generate, summarize, combine, and analyze scientific data. AI models can find...\nAI is reshaping scientific research and innovation. Scientists can leverage AI to generate, summarize, combine, and analyze scientific data. AI models can find patterns in data that human scientists have overlooked, find connections between seemingly unrelated fields and phenomena, and even propose new hypotheses to be tested. An AI co-scientist is a collaborative, multi-agent AI system…\nSource",
      "publishedAt": "2025-11-17T22:30:00.000Z",
      "author": "Geetika Gupta",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "ed166d4d6a8d2ed7cf64a8d33f2eeb80",
      "title": "Achieve CUTLASS C++ Performance with Python APIs Using CuTe DSL",
      "url": "https://developer.nvidia.com/blog/achieve-cutlass-c-performance-with-python-apis-using-cute-dsl/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-png.webp 903w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"colored-squares-graphic\" />CuTe, a core component of CUTLASS 3.x, provides a unified algebra for describing data layouts and thread mappings, and abstracts complex memory access patterns...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/colored-squares-graphic-png.webp 903w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"colored-squares-graphic\" /><p>CuTe, a core component of CUTLASS 3.x, provides a unified algebra for describing data layouts and thread mappings, and abstracts complex memory access patterns into composable mathematical operations. While CUTLASS 3.x and CuTe have empowered kernel developers to achieve peak performance on Tensor Cores through intuitive abstractions, the extensive use of C++ templates has resulted in high…</p>\n<p><a href=\"https://developer.nvidia.com/blog/achieve-cutlass-c-performance-with-python-apis-using-cute-dsl/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "CuTe, a core component of CUTLASS 3.x, provides a unified algebra for describing data layouts and thread mappings, and abstracts complex memory access patterns...\nCuTe, a core component of CUTLASS 3.x, provides a unified algebra for describing data layouts and thread mappings, and abstracts complex memory access patterns into composable mathematical operations. While CUTLASS 3.x and CuTe have empowered kernel developers to achieve peak performance on Tensor Cores through intuitive abstractions, the extensive use of C++ templates has resulted in high…\nSource",
      "publishedAt": "2025-11-13T20:30:00.000Z",
      "author": "Brandon Sun",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "fbef07a02e2c4492a5fda71ec5338b57",
      "title": "How to Get Started with Neural Shading for Your Game or Application",
      "url": "https://developer.nvidia.com/blog/how-to-get-started-with-neural-shading-for-your-game-or-application/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-png.webp 1265w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"image1\" />For the past 25 years, real-time rendering has been driven by continuous hardware improvements. The goal has always been to create the highest fidelity image...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image1-2-png.webp 1265w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"image1\" /><p>For the past 25 years, real-time rendering has been driven by continuous hardware improvements. The goal has always been to create the highest fidelity image possible within 16 milliseconds. This has fueled significant innovation in graphics hardware, pipelines, and renderers. But the slowing pace of Moore’s Law mandates the invention of new computational architectures to keep pace with the…</p>\n<p><a href=\"https://developer.nvidia.com/blog/how-to-get-started-with-neural-shading-for-your-game-or-application/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "For the past 25 years, real-time rendering has been driven by continuous hardware improvements. The goal has always been to create the highest fidelity image...\nFor the past 25 years, real-time rendering has been driven by continuous hardware improvements. The goal has always been to create the highest fidelity image possible within 16 milliseconds. This has fueled significant innovation in graphics hardware, pipelines, and renderers. But the slowing pace of Moore’s Law mandates the invention of new computational architectures to keep pace with the…\nSource",
      "publishedAt": "2025-11-13T19:55:28.000Z",
      "author": "Shannon Woods",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "c8d444d84dd3ec64ac94e44fd6c93d1a",
      "title": "NVIDIA Blackwell Architecture Sweeps MLPerf Training v5.1 Benchmarks",
      "url": "https://developer.nvidia.com/blog/nvidia-blackwell-architecture-sweeps-mlperf-training-v5-1-benchmarks/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-png.webp 1600w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Blackwell-MLPerf\" />The NVIDIA Blackwell architecture powered the fastest time to train across every MLPerf Training v5.1 benchmark, marking a clean sweep in the latest round of...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Blackwell-MLPerf-png.webp 1600w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Blackwell-MLPerf\" /><p>The NVIDIA Blackwell architecture powered the fastest time to train across every MLPerf Training v5.1 benchmark, marking a clean sweep in the latest round of results. As developers experiment with new architectures, and models continue to grow in size, more training compute is essential. Meeting this need for delivered compute requires innovation across every layer of the AI stack—from chips and…</p>\n<p><a href=\"https://developer.nvidia.com/blog/nvidia-blackwell-architecture-sweeps-mlperf-training-v5-1-benchmarks/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "The NVIDIA Blackwell architecture powered the fastest time to train across every MLPerf Training v5.1 benchmark, marking a clean sweep in the latest round of...\nThe NVIDIA Blackwell architecture powered the fastest time to train across every MLPerf Training v5.1 benchmark, marking a clean sweep in the latest round of results. As developers experiment with new architectures, and models continue to grow in size, more training compute is essential. Meeting this need for delivered compute requires innovation across every layer of the AI stack—from chips and…\nSource",
      "publishedAt": "2025-11-13T00:08:00.000Z",
      "author": "Ashraf Eassa",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "d5be10c1406d39cb7735169d4978a68a",
      "title": "Just Released: Warp 1.10 Expands JAX Interoperability and Performance",
      "url": "https://github.com/NVIDIA/warp/releases/tag/v1.10.0#new_tab",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"NVIDIA Warp Python\" />Build high-performance GPU simulations using Warp, with enhancements across JAX, Tile programming, and Arm support.<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/warp-f1-car-aero1-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"NVIDIA Warp Python\" /><p>Build high-performance GPU simulations using Warp, with enhancements across JAX, Tile programming, and Arm support.</p>\n<p><a href=\"https://github.com/NVIDIA/warp/releases/tag/v1.10.0#new_tab\" rel=\"nofollow\" data-wpel-link=\"external\" target=\"_blank\">Source</a></p>",
      "summary": "Build high-performance GPU simulations using Warp, with enhancements across JAX, Tile programming, and Arm support.\nBuild high-performance GPU simulations using Warp, with enhancements across JAX, Tile programming, and Arm support.\nSource",
      "publishedAt": "2025-11-13T00:07:29.000Z",
      "author": "Mohammad Mohajerani",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "0c49edfb32953e95a438bf52f9d7bc7e",
      "title": "Fusing Communication and Compute with New Device API and Copy Engine Collectives in NVIDIA NCCL 2.28",
      "url": "https://developer.nvidia.com/blog/fusing-communication-and-compute-with-new-device-api-and-copy-engine-collectives-in-nvidia-nccl-2-28/",
      "content": "<img width=\"624\" height=\"351\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-png.webp 624w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-196x110-png.webp 196w\" sizes=\"auto, (max-width: 624px) 100vw, 624px\" title=\"NVIDIA NCCL technical blog\" />The latest release of the NVIDIA Collective Communications Library (NCCL) introduces a groundbreaking fusion of communication and computation for higher...<img width=\"624\" height=\"351\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-png.webp 624w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/NVIDIA-NCCL-technical-blog-196x110-png.webp 196w\" sizes=\"auto, (max-width: 624px) 100vw, 624px\" title=\"NVIDIA NCCL technical blog\" /><p>The latest release of the NVIDIA Collective Communications Library (NCCL) introduces a groundbreaking fusion of communication and computation for higher throughput, reduced latency, and maximized GPU utilization across multi-GPU and multi-node systems. NCCL 2.28 focuses on GPU-initiated networking, device APIs for communication-compute fusion, copy-engine-based collectives, and new APIs for…</p>\n<p><a href=\"https://developer.nvidia.com/blog/fusing-communication-and-compute-with-new-device-api-and-copy-engine-collectives-in-nvidia-nccl-2-28/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "The latest release of the NVIDIA Collective Communications Library (NCCL) introduces a groundbreaking fusion of communication and computation for higher...\nThe latest release of the NVIDIA Collective Communications Library (NCCL) introduces a groundbreaking fusion of communication and computation for higher throughput, reduced latency, and maximized GPU utilization across multi-GPU and multi-node systems. NCCL 2.28 focuses on GPU-initiated networking, device APIs for communication-compute fusion, copy-engine-based collectives, and new APIs for…\nSource",
      "publishedAt": "2025-11-11T00:06:14.000Z",
      "author": "Sylvain Jeaugey",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "08910d5d49d25d915b4c6c4d61b9190e",
      "title": "Upcoming Livestream: Build Visual AI Agents with NVIDIA Cosmos Reason and Metropolis",
      "url": "https://www.addevent.com/event/kffjqsqb67nq#new_tab",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-png.webp 1600w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"robotics-vss-cosmos\" />On November 18, learn how to fine-tune the NVIDIA Cosmos Reason VLM with your own data to create visual AI agents.<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/robotics-vss-cosmos-png.webp 1600w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"robotics-vss-cosmos\" /><p>On November 18, learn how to fine-tune the NVIDIA Cosmos Reason VLM with your own data to create visual AI agents.</p>\n<p><a href=\"https://www.addevent.com/event/kffjqsqb67nq#new_tab\" rel=\"nofollow\" data-wpel-link=\"external\" target=\"_blank\">Source</a></p>",
      "summary": "On November 18, learn how to fine-tune the NVIDIA Cosmos Reason VLM with your own data to create visual AI agents.\nOn November 18, learn how to fine-tune the NVIDIA Cosmos Reason VLM with your own data to create visual AI agents.\nSource",
      "publishedAt": "2025-11-10T22:22:56.000Z",
      "author": "Tanya Lenz",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "e85980af4cc2cba690be2f53709c37f0",
      "title": "Building Scalable and Fault-Tolerant NCCL Applications",
      "url": "https://developer.nvidia.com/blog/building-scalable-and-fault-tolerant-nccl-applications/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-625x351-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-1536x863-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-362x203-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-png.webp 1918w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"neon-green-cube\" />The NVIDIA Collective Communications Library (NCCL) provides communication APIs for low-latency and high-bandwidth collectives, enabling AI workloads to scale...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-625x351-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-1536x863-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-362x203-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/neon-green-cube-png.webp 1918w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"neon-green-cube\" /><p>The NVIDIA Collective Communications Library (NCCL) provides communication APIs for low-latency and high-bandwidth collectives, enabling AI workloads to scale from just a few GPUs on a single host to thousands of GPUs in a data center. This post discusses NCCL features that support run-time rescaling for cost optimization, as well as minimizing service downtime from faults by dynamically removing…</p>\n<p><a href=\"https://developer.nvidia.com/blog/building-scalable-and-fault-tolerant-nccl-applications/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "The NVIDIA Collective Communications Library (NCCL) provides communication APIs for low-latency and high-bandwidth collectives, enabling AI workloads to scale...\nThe NVIDIA Collective Communications Library (NCCL) provides communication APIs for low-latency and high-bandwidth collectives, enabling AI workloads to scale from just a few GPUs on a single host to thousands of GPUs in a data center. This post discusses NCCL features that support run-time rescaling for cost optimization, as well as minimizing service downtime from faults by dynamically removing…\nSource",
      "publishedAt": "2025-11-10T21:29:37.000Z",
      "author": "Luke Robison",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "7c51dd062d058cc4324b33e5f63c5603",
      "title": "Training XGBoost Models with GPU-Accelerated Polars DataFrames",
      "url": "https://developer.nvidia.com/blog/training-xgboost-models-with-gpu-accelerated-polars-dataframes/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-png.webp 1999w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"xgboost-model-training\" />One of the many strengths of the PyData ecosystem is interoperability, which enables seamlessly moving data between libraries that specialize in exploratory...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/xgboost-model-training-png.webp 1999w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"xgboost-model-training\" /><p>One of the many strengths of the PyData ecosystem is interoperability, which enables seamlessly moving data between libraries that specialize in exploratory analysis, training, and inference. The latest release of XGBoost introduces exciting new capabilities, including a category re-coder and integration with Polars DataFrames. This provides a streamlined approach to data handling.</p>\n<p><a href=\"https://developer.nvidia.com/blog/training-xgboost-models-with-gpu-accelerated-polars-dataframes/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "One of the many strengths of the PyData ecosystem is interoperability, which enables seamlessly moving data between libraries that specialize in exploratory...\nOne of the many strengths of the PyData ecosystem is interoperability, which enables seamlessly moving data between libraries that specialize in exploratory analysis, training, and inference. The latest release of XGBoost introduces exciting new capabilities, including a category re-coder and integration with Polars DataFrames. This provides a streamlined approach to data handling.\nSource",
      "publishedAt": "2025-11-10T19:30:00.000Z",
      "author": "Jiaming Yuan",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "a919260a9c9feaed38ce1c36b85e2d3d",
      "title": "Gen AI Super-Resolution Accelerates Weather Prediction with Scalable, Low-Compute Models",
      "url": "https://developer.nvidia.com/blog/gen-ai-super-resolution-accelerates-weather-prediction-with-scalable-low-compute-models/",
      "content": "<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Earth2-CorDiff.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"Earth2-CorDiff\" />As AI weather and climate prediction models rapidly gain adoption, the NVIDIA Earth-2 platform provides libraries and tools for accelerating solutions using a...<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Earth2-CorDiff.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"Earth2-CorDiff\" /><p>As AI weather and climate prediction models rapidly gain adoption, the NVIDIA Earth-2 platform provides libraries and tools for accelerating solutions using a GPU-optimized software stack. Downscaling, which is the task of refining coarse-resolution (25km scale) weather data, enables national meteorological service (NMS) agencies to deliver high-resolution predictions for agriculture, energy…</p>\n<p><a href=\"https://developer.nvidia.com/blog/gen-ai-super-resolution-accelerates-weather-prediction-with-scalable-low-compute-models/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "As AI weather and climate prediction models rapidly gain adoption, the NVIDIA Earth-2 platform provides libraries and tools for accelerating solutions using a...\nAs AI weather and climate prediction models rapidly gain adoption, the NVIDIA Earth-2 platform provides libraries and tools for accelerating solutions using a GPU-optimized software stack. Downscaling, which is the task of refining coarse-resolution (25km scale) weather data, enables national meteorological service (NMS) agencies to deliver high-resolution predictions for agriculture, energy…\nSource",
      "publishedAt": "2025-11-10T19:29:53.000Z",
      "author": "Alicia Sui",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "d8b3190f9675aa9005768ef51bc3e56d",
      "title": "How to Achieve 4x Faster Inference for Math Problem Solving",
      "url": "https://developer.nvidia.com/blog/how-to-achieve-4x-faster-inference-for-math-problem-solving/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Decorative math image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-625x351-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-2048x1152-jpg.webp 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-960x540-jpg.webp 960w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Solving-Math\" />Large language models can solve challenging math problems. However, making them work efficiently at scale requires more than a strong checkpoint. You need the...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Decorative math image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-625x351-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-2048x1152-jpg.webp 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/Solving-Math-960x540-jpg.webp 960w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Solving-Math\" /><p>Large language models can solve challenging math problems. However, making them work efficiently at scale requires more than a strong checkpoint. You need the right serving stack, quantization strategy, and decoding methods—often spread across different tools that don’t work together cleanly. Teams end up juggling containers, conversion scripts, and ad‑hoc glue code to compare BF16 vs FP8 or to…</p>\n<p><a href=\"https://developer.nvidia.com/blog/how-to-achieve-4x-faster-inference-for-math-problem-solving/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Large language models can solve challenging math problems. However, making them work efficiently at scale requires more than a strong checkpoint. You need the...\nLarge language models can solve challenging math problems. However, making them work efficiently at scale requires more than a strong checkpoint. You need the right serving stack, quantization strategy, and decoding methods—often spread across different tools that don’t work together cleanly. Teams end up juggling containers, conversion scripts, and ad‑hoc glue code to compare BF16 vs FP8 or to…\nSource",
      "publishedAt": "2025-11-10T16:44:30.000Z",
      "author": "Igor Gitman",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "bafe3cd707309ad8bdb63058ad2d26c6",
      "title": "Streamline Complex AI Inference on Kubernetes with NVIDIA Grove",
      "url": "https://developer.nvidia.com/blog/streamline-complex-ai-inference-on-kubernetes-with-nvidia-grove/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-png.webp 1209w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"data-center\" />Over the past few years, AI inference has evolved from single-model, single-pod deployments into complex, multicomponent systems. A model deployment may now...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/data-center-png.webp 1209w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"data-center\" /><p>Over the past few years, AI inference has evolved from single-model, single-pod deployments into complex, multicomponent systems. A model deployment may now consist of several distinct components—prefill, decode, vision encoders, key value (KV) routers, and more. In addition, entire agentic pipelines are emerging, where multiple such model instances collaborate to perform reasoning, retrieval…</p>\n<p><a href=\"https://developer.nvidia.com/blog/streamline-complex-ai-inference-on-kubernetes-with-nvidia-grove/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Over the past few years, AI inference has evolved from single-model, single-pod deployments into complex, multicomponent systems. A model deployment may now...\nOver the past few years, AI inference has evolved from single-model, single-pod deployments into complex, multicomponent systems. A model deployment may now consist of several distinct components—prefill, decode, vision encoders, key value (KV) routers, and more. In addition, entire agentic pipelines are emerging, where multiple such model instances collaborate to perform reasoning, retrieval…\nSource",
      "publishedAt": "2025-11-10T14:00:00.000Z",
      "author": "Sanjay Chatterjee",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "5fa08b20e4277cb06c826285c815f897",
      "title": "Enabling Multi-Node NVLink on Kubernetes for NVIDIA GB200 NVL72 and Beyond",
      "url": "https://developer.nvidia.com/blog/enabling-multi-node-nvlink-on-kubernetes-for-gb200-and-beyond/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"runai-tech-blog-compute-domains-1920x1080-4504000\" />The NVIDIA GB200 NVL72 pushes AI infrastructure to new limits, enabling breakthroughs in training large-language models and running scalable, low-latency...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/runai-tech-blog-compute-domains-1920x1080-4504000-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"runai-tech-blog-compute-domains-1920x1080-4504000\" /><p>The NVIDIA GB200 NVL72 pushes AI infrastructure to new limits, enabling breakthroughs in training large-language models and running scalable, low-latency inference workloads. Increasingly, Kubernetes plays a central role for deploying and scaling these workloads efficiently whether on-premises or in the cloud. However, rapidly evolving AI workloads, infrastructure requirements…</p>\n<p><a href=\"https://developer.nvidia.com/blog/enabling-multi-node-nvlink-on-kubernetes-for-gb200-and-beyond/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "The NVIDIA GB200 NVL72 pushes AI infrastructure to new limits, enabling breakthroughs in training large-language models and running scalable, low-latency...\nThe NVIDIA GB200 NVL72 pushes AI infrastructure to new limits, enabling breakthroughs in training large-language models and running scalable, low-latency inference workloads. Increasingly, Kubernetes plays a central role for deploying and scaling these workloads efficiently whether on-premises or in the cloud. However, rapidly evolving AI workloads, infrastructure requirements…\nSource",
      "publishedAt": "2025-11-10T14:00:00.000Z",
      "author": "Kevin Klues",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "69e5a063c6eab7c6b4cc46e97a605918",
      "title": "Building an Interactive AI Agent for Lightning-Fast Machine Learning Tasks",
      "url": "https://developer.nvidia.com/blog/building-an-interactive-ai-agent-for-lightning-fast-machine-learning-tasks/",
      "content": "<img width=\"768\" height=\"433\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-768x433.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"An illustration of an AI agent.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-768x433.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-300x169.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-625x352.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-179x101.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-1536x865.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-645x363.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-500x282.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-160x90.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-362x204.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-195x110.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-1024x577.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-960x540.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429.webp 1562w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"ML-Agent\" />Data scientists spend a lot of time cleaning and preparing large, unstructured datasets before analysis can begin, often requiring strong programming and...<img width=\"768\" height=\"433\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-768x433.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"An illustration of an AI agent.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-768x433.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-300x169.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-625x352.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-179x101.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-1536x865.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-645x363.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-500x282.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-160x90.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-362x204.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-195x110.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-1024x577.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429-960x540.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/ML-Agent-e1762537462429.webp 1562w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"ML-Agent\" /><p>Data scientists spend a lot of time cleaning and preparing large, unstructured datasets before analysis can begin, often requiring strong programming and statistical expertise. Managing feature engineering, model tuning, and consistency across workflows is complex and error-prone. These challenges are amplified by the slow, sequential nature of CPU-based ML workflows…</p>\n<p><a href=\"https://developer.nvidia.com/blog/building-an-interactive-ai-agent-for-lightning-fast-machine-learning-tasks/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Data scientists spend a lot of time cleaning and preparing large, unstructured datasets before analysis can begin, often requiring strong programming and...\nData scientists spend a lot of time cleaning and preparing large, unstructured datasets before analysis can begin, often requiring strong programming and statistical expertise. Managing feature engineering, model tuning, and consistency across workflows is complex and error-prone. These challenges are amplified by the slow, sequential nature of CPU-based ML workflows…\nSource",
      "publishedAt": "2025-11-07T17:44:52.000Z",
      "author": "Allison Ding",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "b84b2bac130a7cac8d5a63951b5ea30d",
      "title": "Benchmarking LLMs on AI-Generated CUDA Code with ComputeEval 2025.2",
      "url": "https://developer.nvidia.com/blog/benchmarking-llms-on-ai-generated-cuda-code-with-computeeval-2025-2/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-768x432.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-768x432.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-300x169.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-625x352.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-179x101.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-1536x864.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-645x363.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-660x370.png 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-362x204.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-196x110.png 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-1024x576.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured.png 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"blackwell-cuda-12-9-family-specific-featured\" />Can AI coding assistants write efficient CUDA code? To help measure and improve their capabilities, we created ComputeEval, a robust, open source benchmark for...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-768x432.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-768x432.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-300x169.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-625x352.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-179x101.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-1536x864.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-645x363.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-660x370.png 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-362x204.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-196x110.png 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-1024x576.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured-960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/04/blackwell-cuda-12-9-family-specific-featured.png 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"blackwell-cuda-12-9-family-specific-featured\" /><p>Can AI coding assistants write efficient CUDA code? To help measure and improve their capabilities, we created ComputeEval, a robust, open source benchmark for evaluating AI models and agents on CUDA programming tasks. A few months ago, we announced the first release of ComputeEval and today, we’re introducing its first major expansion by adding more than 100 new CUDA challenges.</p>\n<p><a href=\"https://developer.nvidia.com/blog/benchmarking-llms-on-ai-generated-cuda-code-with-computeeval-2025-2/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Can AI coding assistants write efficient CUDA code? To help measure and improve their capabilities, we created ComputeEval, a robust, open source benchmark for...\nCan AI coding assistants write efficient CUDA code? To help measure and improve their capabilities, we created ComputeEval, a robust, open source benchmark for evaluating AI models and agents on CUDA programming tasks. A few months ago, we announced the first release of ComputeEval and today, we’re introducing its first major expansion by adding more than 100 new CUDA challenges.\nSource",
      "publishedAt": "2025-11-07T16:30:00.000Z",
      "author": "Daniel Rodriguez",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "d1f95440237b7ae6299fb1caea97854f",
      "title": "Enhancing GPU-Accelerated Vector Search in Faiss with NVIDIA cuVS",
      "url": "https://developer.nvidia.com/blog/enhancing-gpu-accelerated-vector-search-in-faiss-with-nvidia-cuvs/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"llm-visual-vector-search\" />As companies collect more unstructured data and increasingly use large language models (LLMs), they need faster and more scalable systems. Advanced tools for...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/07/llm-visual-vector-search-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"llm-visual-vector-search\" /><p>As companies collect more unstructured data and increasingly use large language models (LLMs), they need faster and more scalable systems. Advanced tools for finding information, such as retrieval-augmented generation (RAG), can take hours or even days to process massive amounts of data—sometimes at the scale of terabytes or petabytes. Meanwhile, online search applications like ad…</p>\n<p><a href=\"https://developer.nvidia.com/blog/enhancing-gpu-accelerated-vector-search-in-faiss-with-nvidia-cuvs/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "As companies collect more unstructured data and increasingly use large language models (LLMs), they need faster and more scalable systems. Advanced tools for...\nAs companies collect more unstructured data and increasingly use large language models (LLMs), they need faster and more scalable systems. Advanced tools for finding information, such as retrieval-augmented generation (RAG), can take hours or even days to process massive amounts of data—sometimes at the scale of terabytes or petabytes. Meanwhile, online search applications like ad…\nSource",
      "publishedAt": "2025-11-06T20:41:38.000Z",
      "author": "Tarang Jain",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "dc888489c997e6d4d6a075e67042ae9a",
      "title": "Accelerating Large-Scale Mixture-of-Experts Training in PyTorch",
      "url": "https://developer.nvidia.com/blog/accelerating-large-scale-mixture-of-experts-training-in-pytorch/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-195x110-jpg.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-jpg.webp 1208w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"image2\" />Training massive mixture-of-experts (MoE) models has long been the domain of a few advanced users with deep infrastructure and distributed-systems expertise....<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-195x110-jpg.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/11/image2-1-jpg.webp 1208w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"image2\" /><p>Training massive mixture-of-experts (MoE) models has long been the domain of a few advanced users with deep infrastructure and distributed-systems expertise. For most developers, the challenge wasn’t building smarter models—it was scaling them efficiently across hundreds or even thousands of GPUs without breaking the bank. With NVIDIA NeMo Automodel, an open-source library within NVIDIA NeMo…</p>\n<p><a href=\"https://developer.nvidia.com/blog/accelerating-large-scale-mixture-of-experts-training-in-pytorch/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Training massive mixture-of-experts (MoE) models has long been the domain of a few advanced users with deep infrastructure and distributed-systems expertise....\nTraining massive mixture-of-experts (MoE) models has long been the domain of a few advanced users with deep infrastructure and distributed-systems expertise. For most developers, the challenge wasn’t building smarter models—it was scaling them efficiently across hundreds or even thousands of GPUs without breaking the bank. With NVIDIA NeMo Automodel, an open-source library within NVIDIA NeMo…\nSource",
      "publishedAt": "2025-11-06T17:00:00.000Z",
      "author": "Hemil Desai",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "3b9bca0f56576760b8de7867ddf4bec8",
      "title": "Scale Biology Transformer Models with PyTorch and NVIDIA BioNeMo Recipes",
      "url": "https://developer.nvidia.com/blog/scale-biology-transformer-models-with-pytorch-and-nvidia-bionemo-recipes/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Decorative image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-png.webp 1999w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"BioNeMo-Recipes\" />Training models with billions or trillions of parameters demands advanced parallel computing. Researchers must decide how to combine parallelism strategies,...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Decorative image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/BioNeMo-Recipes-png.webp 1999w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"BioNeMo-Recipes\" /><p>Training models with billions or trillions of parameters demands advanced parallel computing. Researchers must decide how to combine parallelism strategies, select the most efficient accelerated libraries, and integrate low-precision formats such as FP8 and FP4—all without sacrificing speed or memory. There are accelerated frameworks that help, but adapting to these specific methodologies…</p>\n<p><a href=\"https://developer.nvidia.com/blog/scale-biology-transformer-models-with-pytorch-and-nvidia-bionemo-recipes/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Training models with billions or trillions of parameters demands advanced parallel computing. Researchers must decide how to combine parallelism strategies,...\nTraining models with billions or trillions of parameters demands advanced parallel computing. Researchers must decide how to combine parallelism strategies, select the most efficient accelerated libraries, and integrate low-precision formats such as FP8 and FP4—all without sacrificing speed or memory. There are accelerated frameworks that help, but adapting to these specific methodologies…\nSource",
      "publishedAt": "2025-11-05T16:00:00.000Z",
      "author": "Kyle Tretina",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "1c214b215865b873579146e5007b7e63",
      "title": "How to Predict Biomolecular Structures Using the OpenFold3 NIM",
      "url": "https://developer.nvidia.com/blog/how-to-predict-biomolecular-structures-using-the-openfold3-nim/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"biomolecular-structure\" />​​For decades, one of biology’s deepest mysteries was how a string of amino acids folds itself into the intricate architecture of life. Researchers built...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/biomolecular-structure-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"biomolecular-structure\" /><p>​​For decades, one of biology’s deepest mysteries was how a string of amino acids folds itself into the intricate architecture of life. Researchers built painstaking simulations and statistical models, inching toward an answer but never crossing the threshold of prediction at scale. Then, deep learning changed everything. By learning the language of evolution directly from sequence data…</p>\n<p><a href=\"https://developer.nvidia.com/blog/how-to-predict-biomolecular-structures-using-the-openfold3-nim/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "​​For decades, one of biology’s deepest mysteries was how a string of amino acids folds itself into the intricate architecture of life. Researchers built...\n​​For decades, one of biology’s deepest mysteries was how a string of amino acids folds itself into the intricate architecture of life. Researchers built painstaking simulations and statistical models, inching toward an answer but never crossing the threshold of prediction at scale. Then, deep learning changed everything. By learning the language of evolution directly from sequence data…\nSource",
      "publishedAt": "2025-11-04T18:00:00.000Z",
      "author": "Kyle Tretina",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "d360d23688156c7224da6b447f65912e",
      "title": "R²D²: Perception-Guided Task & Motion Planning for Long-Horizon Manipulation",
      "url": "https://developer.nvidia.com/blog/r2d2-perception-guided-task-amp-motion-planning-for-long-horizon-manipulation/",
      "content": "<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/2025_R2D2_RoboticManipulation.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"2025_R2D2_RoboticManipulation\" />Traditional task and motion planning (TAMP) systems for robot manipulation use cases operate on static models that often fail in new environments. Integrating...<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/2025_R2D2_RoboticManipulation.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"2025_R2D2_RoboticManipulation\" /><p>Traditional task and motion planning (TAMP) systems for robot manipulation use cases operate on static models that often fail in new environments. Integrating perception with manipulation is a solution to this challenge, enabling robots to update plans mid-execution and adapt to dynamic scenarios. In this edition of the NVIDIA Robotics Research and Development Digest (R²D²)…</p>\n<p><a href=\"https://developer.nvidia.com/blog/r2d2-perception-guided-task-amp-motion-planning-for-long-horizon-manipulation/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Traditional task and motion planning (TAMP) systems for robot manipulation use cases operate on static models that often fail in new environments. Integrating...\nTraditional task and motion planning (TAMP) systems for robot manipulation use cases operate on static models that often fail in new environments. Integrating perception with manipulation is a solution to this challenge, enabling robots to update plans mid-execution and adapt to dynamic scenarios. In this edition of the NVIDIA Robotics Research and Development Digest (R²D²)…\nSource",
      "publishedAt": "2025-11-04T17:00:00.000Z",
      "author": "Raffaello Bonghi",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "e656f4e111e487021153ca85a03dc987",
      "title": "Make Sense of Video Analytics by Integrating NVIDIA AI Blueprints",
      "url": "https://developer.nvidia.com/blog/make-sense-of-video-analytics-by-integrating-nvidia-ai-blueprints/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-768x432.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Decorative image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-768x432.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-300x169.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-625x351.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-179x101.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-1536x864.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-645x363.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-658x370.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-500x281.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-160x90.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-362x204.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-196x110.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-1024x576.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-960x540.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372.webp 1814w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"AI-Blueprint-Video\" />Organizations are increasingly seeking ways to extract insights from video, audio, and other complex data sources. Retrieval-augmented generation (RAG) enables...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-768x432.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Decorative image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-768x432.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-300x169.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-625x351.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-179x101.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-1536x864.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-645x363.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-658x370.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-500x281.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-160x90.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-362x204.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-196x110.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-1024x576.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372-960x540.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-Blueprint-Video-e1761771748372.webp 1814w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"AI-Blueprint-Video\" /><p>Organizations are increasingly seeking ways to extract insights from video, audio, and other complex data sources. Retrieval-augmented generation (RAG) enables generative AI systems to use proprietary enterprise data. However, incorporating video content into these workflows introduces new technical hurdles, such as efficient ingestion, indexing, and maintaining compliance across diverse sources.</p>\n<p><a href=\"https://developer.nvidia.com/blog/make-sense-of-video-analytics-by-integrating-nvidia-ai-blueprints/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Organizations are increasingly seeking ways to extract insights from video, audio, and other complex data sources. Retrieval-augmented generation (RAG) enables...\nOrganizations are increasingly seeking ways to extract insights from video, audio, and other complex data sources. Retrieval-augmented generation (RAG) enables generative AI systems to use proprietary enterprise data. However, incorporating video content into these workflows introduces new technical hurdles, such as efficient ingestion, indexing, and maintaining compliance across diverse sources.\nSource",
      "publishedAt": "2025-11-03T21:48:11.000Z",
      "author": "Ilyas Bankole-Hameed",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "941512f9f2dee821cce8e0ab3de13723",
      "title": "Join Us for the Blackwell NVFP4 Kernel Hackathon with NVIDIA and GPU MODE",
      "url": "https://luma.com/9n27uem4",
      "content": "<img width=\"768\" height=\"431\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-768x431-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-768x431-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-300x168-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-625x351-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-179x100-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-645x362-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-500x280-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-362x203-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-1024x574-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-960x538-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-png.webp 1480w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"grace hackathon\" />Join the Developer Kernel Hackathon, a four-part performance challenge hosted by NVIDIA in collaboration with GPU MODE and support from Dell and Sesterce. Push...<img width=\"768\" height=\"431\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-768x431-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-768x431-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-300x168-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-625x351-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-179x100-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-645x362-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-500x280-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-362x203-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-1024x574-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-960x538-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/grace-hackathon-png.webp 1480w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"grace hackathon\" /><p>Join the Developer Kernel Hackathon, a four-part performance challenge hosted by NVIDIA in collaboration with GPU MODE and support from Dell and Sesterce. Push the limits of GPU performance and optimize low-level kernels for maximum efficiency on NVIDIA hardware. Compete for the chance to win the latest hardware for accelerated computing.</p>\n<p><a href=\"https://luma.com/9n27uem4\" rel=\"nofollow\" data-wpel-link=\"external\" target=\"_blank\">Source</a></p>",
      "summary": "Join the Developer Kernel Hackathon, a four-part performance challenge hosted by NVIDIA in collaboration with GPU MODE and support from Dell and Sesterce. Push...\nJoin the Developer Kernel Hackathon, a four-part performance challenge hosted by NVIDIA in collaboration with GPU MODE and support from Dell and Sesterce. Push the limits of GPU performance and optimize low-level kernels for maximum efficiency on NVIDIA hardware. Compete for the chance to win the latest hardware for accelerated computing.\nSource",
      "publishedAt": "2025-11-03T20:00:00.000Z",
      "author": "Ayesha Asif",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "8e2b8570d1ec8dd7302916044fa5b803",
      "title": "Advancing Explainable AI in Radiology Research with NVIDIA Clara Reason",
      "url": "https://developer.nvidia.com/blog/advancing-explainable-ai-in-radiology-research-with-nvidia-clara-reason/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"clara-reason\" />Medical AI has reached an inflection point. While vision-language models (VLMs) have shown promise in medical imaging, they have lacked the systematic,...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/clara-reason-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"clara-reason\" /><p>Medical AI has reached an inflection point. While vision-language models (VLMs) have shown promise in medical imaging, they have lacked the systematic, transparent reasoning that clinicians need to trust AI-assisted diagnoses. Changing this is NVIDIA Clara, a family of models, tools, and recipes that are built for accelerating scientific discovery, analyzing medical images…</p>\n<p><a href=\"https://developer.nvidia.com/blog/advancing-explainable-ai-in-radiology-research-with-nvidia-clara-reason/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Medical AI has reached an inflection point. While vision-language models (VLMs) have shown promise in medical imaging, they have lacked the systematic,...\nMedical AI has reached an inflection point. While vision-language models (VLMs) have shown promise in medical imaging, they have lacked the systematic, transparent reasoning that clinicians need to trust AI-assisted diagnoses. Changing this is NVIDIA Clara, a family of models, tools, and recipes that are built for accelerating scientific discovery, analyzing medical images…\nSource",
      "publishedAt": "2025-11-03T18:02:51.000Z",
      "author": "Andriy Myronenko",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "bfe516199084aa1477d24bfcd36c9d1e",
      "title": "How Code Execution Drives Key Risks in Agentic AI Systems",
      "url": "https://developer.nvidia.com/blog/how-code-execution-drives-key-risks-in-agentic-ai-systems/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-768x432.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Conceptual cybersecurity image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-768x432.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-300x169.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-625x352.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-179x101.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-1536x864.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-645x363.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-658x370.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-500x281.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-160x90.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-362x204.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-196x110.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-1024x576.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-960x540.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Cybersecurity global encrypted cybersecurity network mobile data\" />AI-driven applications are evolving from passive tools to agentic systems that generate code, make decisions, and take autonomous actions. This shift introduces...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-768x432.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"Conceptual cybersecurity image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-768x432.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-300x169.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-625x352.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-179x101.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-1536x864.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-645x363.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-658x370.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-500x281.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-160x90.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-362x204.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-196x110.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-1024x576.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149-960x540.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Agentic-AI-Risks-e1761767452149.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Cybersecurity global encrypted cybersecurity network mobile data\" /><p>AI-driven applications are evolving from passive tools to agentic systems that generate code, make decisions, and take autonomous actions. This shift introduces a critical security challenge. When an AI system produces code, there must be strict controls on how and where that code is executed. Without these boundaries, an attacker can craft inputs that trick the AI into generating malicious code…</p>\n<p><a href=\"https://developer.nvidia.com/blog/how-code-execution-drives-key-risks-in-agentic-ai-systems/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "AI-driven applications are evolving from passive tools to agentic systems that generate code, make decisions, and take autonomous actions. This shift introduces...\nAI-driven applications are evolving from passive tools to agentic systems that generate code, make decisions, and take autonomous actions. This shift introduces a critical security challenge. When an AI system produces code, there must be strict controls on how and where that code is executed. Without these boundaries, an attacker can craft inputs that trick the AI into generating malicious code…\nSource",
      "publishedAt": "2025-11-03T17:54:01.000Z",
      "author": "John Irwin",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "65e345beb6795bc273301e07ac9e149c",
      "title": "Streamline AI Infrastructure with NVIDIA Run:ai on Microsoft Azure",
      "url": "https://developer.nvidia.com/blog/streamline-ai-infrastructure-with-nvidia-runai-on-microsoft-azure/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-png.webp 1600w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"runai azure\" />Modern AI workloads, ranging from large-scale training to real-time inference, demand dynamic access to powerful GPUs. However, Kubernetes environments have...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/runai-azure-png.webp 1600w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"runai azure\" /><p>Modern AI workloads, ranging from large-scale training to real-time inference, demand dynamic access to powerful GPUs. However, Kubernetes environments have limited native support for GPU management, which leads to challenges such as inefficient GPU utilization, lack of workload prioritization and preemption, limited visibility into GPU consumption, and difficulty enforcing governance and quota…</p>\n<p><a href=\"https://developer.nvidia.com/blog/streamline-ai-infrastructure-with-nvidia-runai-on-microsoft-azure/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Modern AI workloads, ranging from large-scale training to real-time inference, demand dynamic access to powerful GPUs. However, Kubernetes environments have...\nModern AI workloads, ranging from large-scale training to real-time inference, demand dynamic access to powerful GPUs. However, Kubernetes environments have limited native support for GPU management, which leads to challenges such as inefficient GPU utilization, lack of workload prioritization and preemption, limited visibility into GPU consumption, and difficulty enforcing governance and quota…\nSource",
      "publishedAt": "2025-10-30T17:10:00.000Z",
      "author": "Julie Adrounie",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "176c82540c04935897161f5b4971f3d8",
      "title": "Introducing the CodonFM Open Model for RNA Design and Analysis",
      "url": "https://developer.nvidia.com/blog/introducing-the-codonfm-open-model-for-rna-design-and-analysis/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-png.webp 1999w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"rna-analysis-design\" />Open research is critical for driving innovation, and many breakthroughs in AI and science are achieved through open collaboration. In the field of digital...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/rna-analysis-design-png.webp 1999w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"rna-analysis-design\" /><p>Open research is critical for driving innovation, and many breakthroughs in AI and science are achieved through open collaboration. In the field of digital biology research, NVIDIA Clara supports this open collaboration. Clara is an open source family of models, tools, and recipes for biology, chemistry, and human health. It includes models for use cases such as small-molecule generative…</p>\n<p><a href=\"https://developer.nvidia.com/blog/introducing-the-codonfm-open-model-for-rna-design-and-analysis/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Open research is critical for driving innovation, and many breakthroughs in AI and science are achieved through open collaboration. In the field of digital...\nOpen research is critical for driving innovation, and many breakthroughs in AI and science are achieved through open collaboration. In the field of digital biology research, NVIDIA Clara supports this open collaboration. Clara is an open source family of models, tools, and recipes for biology, chemistry, and human health. It includes models for use cases such as small-molecule generative…\nSource",
      "publishedAt": "2025-10-28T20:00:00.000Z",
      "author": "Kyle Gion",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "f9fc062d2027a4f50f647360eacac721",
      "title": "Accelerating AV Simulation with Neural Reconstruction and World Foundation Models",
      "url": "https://developer.nvidia.com/blog/accelerating-av-simulation-with-neural-reconstruction-and-world-foundation-models/",
      "content": "<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/06/ov-newsletter-gtc-paris-25av-sim-workflow-600x338-r7-1-1.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"ov-newsletter-gtc-paris-25av-sim-workflow-600x338-r7 (1)\" />Autonomous vehicle (AV) stacks are evolving from a hierarchy of discrete building blocks to end-to-end architectures built on foundation models. This transition...<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/06/ov-newsletter-gtc-paris-25av-sim-workflow-600x338-r7-1-1.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"ov-newsletter-gtc-paris-25av-sim-workflow-600x338-r7 (1)\" /><p>Autonomous vehicle (AV) stacks are evolving from a hierarchy of discrete building blocks to end-to-end architectures built on foundation models. This transition demands an AV data flywheel to generate synthetic data and augment sensor datasets, address coverage gaps and, and ultimately, build a validation toolchain to safely develop and deploy autonomous vehicles. In this blog post…</p>\n<p><a href=\"https://developer.nvidia.com/blog/accelerating-av-simulation-with-neural-reconstruction-and-world-foundation-models/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Autonomous vehicle (AV) stacks are evolving from a hierarchy of discrete building blocks to end-to-end architectures built on foundation models. This transition...\nAutonomous vehicle (AV) stacks are evolving from a hierarchy of discrete building blocks to end-to-end architectures built on foundation models. This transition demands an AV data flywheel to generate synthetic data and augment sensor datasets, address coverage gaps and, and ultimately, build a validation toolchain to safely develop and deploy autonomous vehicles. In this blog post…\nSource",
      "publishedAt": "2025-10-28T18:00:00.000Z",
      "author": "Gautham Sholingar",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "8ec1fb50d43f56ab059ddb58c89fb2bd",
      "title": "Powering AI-Native 6G Research with the NVIDIA Sionna Research Kit",
      "url": "https://developer.nvidia.com/blog/powering-ai-native-6g-research-with-the-nvidia-sionna-research-kit/",
      "content": "<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-RAN-Sionna.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"AI-RAN-Sionna\" />Wireless communication research is rich with brilliant ideas and computational power. Yet, there's a fundamental disconnect between what researchers can...<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/AI-RAN-Sionna.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"AI-RAN-Sionna\" /><p>Wireless communication research is rich with brilliant ideas and computational power. Yet, there’s a fundamental disconnect between what researchers can simulate and what they can ‌ build and test. Adjacent fields like machine learning (ML) have flourished with open frameworks and accelerated hardware. But many disruptive ideas never see the light of day due to the challenges of deployment in…</p>\n<p><a href=\"https://developer.nvidia.com/blog/powering-ai-native-6g-research-with-the-nvidia-sionna-research-kit/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Wireless communication research is rich with brilliant ideas and computational power. Yet, there's a fundamental disconnect between what researchers can...\nWireless communication research is rich with brilliant ideas and computational power. Yet, there’s a fundamental disconnect between what researchers can simulate and what they can ‌ build and test. Adjacent fields like machine learning (ML) have flourished with open frameworks and accelerated hardware. But many disruptive ideas never see the light of day due to the challenges of deployment in…\nSource",
      "publishedAt": "2025-10-28T17:51:58.000Z",
      "author": "Sebastian Cammerer",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "573d590a930193eaeb0afcda2e3be294",
      "title": "Develop Specialized AI Agents with New NVIDIA Nemotron Vision, RAG, and Guardrail Models ",
      "url": "https://developer.nvidia.com/blog/develop-specialized-ai-agents-with-new-nvidia-nemotron-vision-rag-and-guardrail-models/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"A decorative image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Nemotron-model-release\" />Agentic AI is an ecosystem where specialized language and vision models work together. They handle planning, reasoning, retrieval, and safety guardrailing....<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"A decorative image.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Nemotron-model-release-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Nemotron-model-release\" /><p>Agentic AI is an ecosystem where specialized language and vision models work together. They handle planning, reasoning, retrieval, and safety guardrailing. Developers need specialized AI agents for domain-specific workflows, real-world deployment, and compliance. Building specialized AI requires four critical ingredients: open models that can be fine-tuned, robust datasets…</p>\n<p><a href=\"https://developer.nvidia.com/blog/develop-specialized-ai-agents-with-new-nvidia-nemotron-vision-rag-and-guardrail-models/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Agentic AI is an ecosystem where specialized language and vision models work together. They handle planning, reasoning, retrieval, and safety guardrailing....\nAgentic AI is an ecosystem where specialized language and vision models work together. They handle planning, reasoning, retrieval, and safety guardrailing. Developers need specialized AI agents for domain-specific workflows, real-world deployment, and compliance. Building specialized AI requires four critical ingredients: open models that can be fine-tuned, robust datasets…\nSource",
      "publishedAt": "2025-10-28T17:30:45.000Z",
      "author": "Chris Alexiuk",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "7da531669a1c5cd33a3134db46070f31",
      "title": "Build Synthetic Data Pipelines to Train Smarter Robots with NVIDIA Isaac Sim ",
      "url": "https://developer.nvidia.com/blog/build-synthetic-data-pipelines-to-train-smarter-robots-with-nvidia-isaac-sim/",
      "content": "<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Robotics-warehouse.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"A GIF of a robot&#039;s view in a warehouse.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"Robotics-warehouse\" />As robots take on increasingly dynamic mobility tasks, developers need physics-accurate simulations that scale efficiently across environments and workloads....<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Robotics-warehouse.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"A GIF of a robot's view in a warehouse.\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"Robotics-warehouse\" /><p>As robots take on increasingly dynamic mobility tasks, developers need physics-accurate simulations that scale efficiently across environments and workloads. Training robot policies and models to do these tasks requires a lot of high-quality data, which is often expensive and time-consuming to collect in the physical world. Synthetic data, generated using simulated environments in NVIDIA…</p>\n<p><a href=\"https://developer.nvidia.com/blog/build-synthetic-data-pipelines-to-train-smarter-robots-with-nvidia-isaac-sim/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "As robots take on increasingly dynamic mobility tasks, developers need physics-accurate simulations that scale efficiently across environments and workloads....\nAs robots take on increasingly dynamic mobility tasks, developers need physics-accurate simulations that scale efficiently across environments and workloads. Training robot policies and models to do these tasks requires a lot of high-quality data, which is often expensive and time-consuming to collect in the physical world. Synthetic data, generated using simulated environments in NVIDIA…\nSource",
      "publishedAt": "2025-10-24T19:42:06.000Z",
      "author": "Asawaree Bhide",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "ef90d029abcf99bb07e6645b042457c1",
      "title": "Unlocking Tensor Core Performance with Floating Point Emulation in cuBLAS",
      "url": "https://developer.nvidia.com/blog/unlocking-tensor-core-performance-with-floating-point-emulation-in-cublas/",
      "content": "<img width=\"768\" height=\"431\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-768x431-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-768x431-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-300x168-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-625x351-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-179x100-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-1536x862-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-645x362-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-362x203-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-1024x575-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-png.webp 1837w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"floating-cubes\" />NVIDIA CUDA-X math libraries provide the fundamental numerical building blocks that enable developers to deploy accelerated applications across multiple...<img width=\"768\" height=\"431\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-768x431-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-768x431-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-300x168-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-625x351-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-179x100-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-1536x862-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-645x362-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-362x203-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-1024x575-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/floating-cubes-png.webp 1837w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"floating-cubes\" /><p>NVIDIA CUDA-X math libraries provide the fundamental numerical building blocks that enable developers to deploy accelerated applications across multiple high-performance domains, including AI and scientific computing. cuBLAS is a CUDA-X math library that consists of a highly optimized collection of basic linear algebra subroutines for matrix and vector operations that are specifically tuned…</p>\n<p><a href=\"https://developer.nvidia.com/blog/unlocking-tensor-core-performance-with-floating-point-emulation-in-cublas/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "NVIDIA CUDA-X math libraries provide the fundamental numerical building blocks that enable developers to deploy accelerated applications across multiple...\nNVIDIA CUDA-X math libraries provide the fundamental numerical building blocks that enable developers to deploy accelerated applications across multiple high-performance domains, including AI and scientific computing. cuBLAS is a CUDA-X math library that consists of a highly optimized collection of basic linear algebra subroutines for matrix and vector operations that are specifically tuned…\nSource",
      "publishedAt": "2025-10-24T16:21:14.000Z",
      "author": "Cole Brower",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "7decc55ed08767212ed675587532e22c",
      "title": "Solve Linear Programs Using the GPU-Accelerated Barrier Method in NVIDIA cuOpt",
      "url": "https://developer.nvidia.com/blog/solve-linear-programs-using-the-gpu-accelerated-barrier-method-in-nvidia-cuopt/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"3d-grid\" />How does the NFL schedule all its regular-season games while avoiding stadium conflicts with Beyoncé concerts?&nbsp;&nbsp; How can doctors use a single donated...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/3d-grid-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"3d-grid\" /><p>How does the NFL schedule all its regular-season games while avoiding stadium conflicts with Beyoncé concerts? How can doctors use a single donated kidney to trigger a chain of transplants, and how do they create the longest possible transplant chain to save the most patients? How do airlines plan flight crew schedules around rest requirements and crew locations while minimizing hotel…</p>\n<p><a href=\"https://developer.nvidia.com/blog/solve-linear-programs-using-the-gpu-accelerated-barrier-method-in-nvidia-cuopt/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "How does the NFL schedule all its regular-season games while avoiding stadium conflicts with Beyoncé concerts?   How can doctors use a single donated...\nHow does the NFL schedule all its regular-season games while avoiding stadium conflicts with Beyoncé concerts? How can doctors use a single donated kidney to trigger a chain of transplants, and how do they create the longest possible transplant chain to save the most patients? How do airlines plan flight crew schedules around rest requirements and crew locations while minimizing hotel…\nSource",
      "publishedAt": "2025-10-24T16:00:00.000Z",
      "author": "Christopher Maes",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "cbfa20ff88485d5d3ddc24210482c7cc",
      "title": "How NVIDIA DGX Spark’s Performance Enables Intensive AI Tasks",
      "url": "https://developer.nvidia.com/blog/how-nvidia-dgx-sparks-performance-enables-intensive-ai-tasks/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-png.webp 1600w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"DGX Spark resized\" />Today’s demanding AI developer workloads often need more memory than desktop systems provide or require access to software that laptops or PCs lack. This...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/DGX-Spark-resized-png.webp 1600w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"DGX Spark resized\" /><p>Today’s demanding AI developer workloads often need more memory than desktop systems provide or require access to software that laptops or PCs lack. This forces work to be moved to the cloud or data center. NVIDIA DGX Spark provides an alternative to cloud instances and data-center queues. The Blackwell-powered, compact supercomputer contains 1 petaflop of FP4 AI computer performance…</p>\n<p><a href=\"https://developer.nvidia.com/blog/how-nvidia-dgx-sparks-performance-enables-intensive-ai-tasks/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Today’s demanding AI developer workloads often need more memory than desktop systems provide or require access to software that laptops or PCs lack. This...\nToday’s demanding AI developer workloads often need more memory than desktop systems provide or require access to software that laptops or PCs lack. This forces work to be moved to the cloud or data center. NVIDIA DGX Spark provides an alternative to cloud instances and data-center queues. The Blackwell-powered, compact supercomputer contains 1 petaflop of FP4 AI computer performance…\nSource",
      "publishedAt": "2025-10-24T16:00:00.000Z",
      "author": "Allen Bourgoyne",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "8cb9fb859ce040d2fd8ca9ca4bc36efb",
      "title": "Reconstruct a Scene in NVIDIA Isaac Sim Using Only a Smartphone",
      "url": "https://developer.nvidia.com/blog/reconstruct-a-scene-in-nvidia-isaac-sim-using-only-a-smartphone/",
      "content": "<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/humanoid-robot-dancing-among-tables-chairs.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"humanoid-robot-dancing-among-tables-chairs\" />Building realistic 3D environments for robotics simulation can be a labor-intensive process. Now, with NVIDIA Omniverse NuRec, you can complete the entire...<img width=\"600\" height=\"338\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/humanoid-robot-dancing-among-tables-chairs.gif\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" title=\"humanoid-robot-dancing-among-tables-chairs\" /><p>Building realistic 3D environments for robotics simulation can be a labor-intensive process. Now, with NVIDIA Omniverse NuRec, you can complete the entire process using just a smartphone. This post walks you through each step—from capturing photos using an iPhone to rebuilding the scene in 3D using 3DGUT to loading it into NVIDIA Isaac Sim and inserting a robot. To skip the reconstruction (Steps 1…</p>\n<p><a href=\"https://developer.nvidia.com/blog/reconstruct-a-scene-in-nvidia-isaac-sim-using-only-a-smartphone/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Building realistic 3D environments for robotics simulation can be a labor-intensive process. Now, with NVIDIA Omniverse NuRec, you can complete the entire...\nBuilding realistic 3D environments for robotics simulation can be a labor-intensive process. Now, with NVIDIA Omniverse NuRec, you can complete the entire process using just a smartphone. This post walks you through each step—from capturing photos using an iPhone to rebuilding the scene in 3D using 3DGUT to loading it into NVIDIA Isaac Sim and inserting a robot. To skip the reconstruction (Steps 1…\nSource",
      "publishedAt": "2025-10-23T23:06:12.000Z",
      "author": "Wonsik Han",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "cbd62793e8c95fc5a782a7b801132b4d",
      "title": "Train an LLM on NVIDIA Blackwell with Unsloth—and Scale for Production",
      "url": "https://developer.nvidia.com/blog/train-an-llm-on-an-nvidia-blackwell-desktop-with-unsloth-and-scale-it/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-png.webp 1999w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"cloud-computing\" />Fine-tuning and reinforcement learning (RL) for large language models (LLMs) require advanced expertise and complex workflows, making them out of reach for...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-195x110-png.webp 195w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/cloud-computing-png.webp 1999w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"cloud-computing\" /><p>Fine-tuning and reinforcement learning (RL) for large language models (LLMs) require advanced expertise and complex workflows, making them out of reach for many. The open source Unsloth project changes that by streamlining the process, making it easier for individuals and small teams to explore LLM customization. When paired with the efficiency and throughput of the NVIDIA Blackwell GPUs…</p>\n<p><a href=\"https://developer.nvidia.com/blog/train-an-llm-on-an-nvidia-blackwell-desktop-with-unsloth-and-scale-it/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "Fine-tuning and reinforcement learning (RL) for large language models (LLMs) require advanced expertise and complex workflows, making them out of reach for...\nFine-tuning and reinforcement learning (RL) for large language models (LLMs) require advanced expertise and complex workflows, making them out of reach for many. The open source Unsloth project changes that by streamlining the process, making it easier for individuals and small teams to explore LLM customization. When paired with the efficiency and throughput of the NVIDIA Blackwell GPUs…\nSource",
      "publishedAt": "2025-10-23T17:51:24.000Z",
      "author": "Paul Abruzzo",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "e19f48d4a459edf35be77bbaf59c1168",
      "title": "Bring Your Circuits to CUDA-Q Using QGEAR",
      "url": "https://github.com/gzquse/qgear-lightning",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"quantum-computing-press-isc24-pr-2-1920x1080\" />Download NERSC’s QGEAR project to easily import Qiskit circuits into GPU-accelerated CUDA-Q kernels.<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-768x432-jpg.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-768x432-jpg.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-300x169-jpg.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-625x352-jpg.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-179x101-jpg.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-1536x864-jpg.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-645x363-jpg.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-660x370-jpg.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-500x281-jpg.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-160x90-jpg.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-362x204-jpg.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-196x110-jpg.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-1024x576-jpg.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-960x540-jpg.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/quantum-computing-press-isc24-pr-2-1920x1080-1-jpg.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"quantum-computing-press-isc24-pr-2-1920x1080\" /><p>Download NERSC’s QGEAR project to easily import Qiskit circuits into GPU-accelerated CUDA-Q kernels.</p>\n<p><a href=\"https://github.com/gzquse/qgear-lightning\" rel=\"nofollow\" data-wpel-link=\"external\" target=\"_blank\">Source</a></p>",
      "summary": "Download NERSC’s QGEAR project to easily import Qiskit circuits into GPU-accelerated CUDA-Q kernels.\nDownload NERSC’s QGEAR project to easily import Qiskit circuits into GPU-accelerated CUDA-Q kernels.\nSource",
      "publishedAt": "2025-10-23T16:55:33.000Z",
      "author": "Shara Tibken",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "f5edb0ec935038d8c15629b3d420a395",
      "title": "Create Your Own Bash Computer Use Agent with NVIDIA Nemotron in One Hour",
      "url": "https://developer.nvidia.com/blog/create-your-own-bash-computer-use-agent-with-nvidia-nemotron-in-one-hour/",
      "content": "<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Copy of genai-tech-blog-nemotron-1920x1080\" />What if you could talk to your computer and have it perform tasks through the Bash terminal, without you writing a single command? With NVIDIA Nemotron Nano v2,...<img width=\"768\" height=\"432\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-768x432-png.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"async\" loading=\"lazy\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-768x432-png.webp 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-300x169-png.webp 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-625x352-png.webp 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-179x101-png.webp 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-1536x864-png.webp 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-645x363-png.webp 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-660x370-png.webp 660w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-500x281-png.webp 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-160x90-png.webp 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-362x204-png.webp 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-196x110-png.webp 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-1024x576-png.webp 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-960x540-png.webp 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2025/10/Copy-of-genai-tech-blog-nemotron-1920x1080-1-png.webp 1920w\" sizes=\"auto, (max-width: 768px) 100vw, 768px\" title=\"Copy of genai-tech-blog-nemotron-1920x1080\" /><p>What if you could talk to your computer and have it perform tasks through the Bash terminal, without you writing a single command? With NVIDIA Nemotron Nano v2, you can easily build a natural language Bash agent from scratch, in under an hour, and with roughly 200 lines of Python code with minimal dependencies. This post will walk you through the core components and considerations step-by…</p>\n<p><a href=\"https://developer.nvidia.com/blog/create-your-own-bash-computer-use-agent-with-nvidia-nemotron-in-one-hour/\" rel=\"nofollow\" data-wpel-link=\"internal\">Source</a></p>",
      "summary": "What if you could talk to your computer and have it perform tasks through the Bash terminal, without you writing a single command? With NVIDIA Nemotron Nano v2,...\nWhat if you could talk to your computer and have it perform tasks through the Bash terminal, without you writing a single command? With NVIDIA Nemotron Nano v2, you can easily build a natural language Bash agent from scratch, in under an hour, and with roughly 200 lines of Python code with minimal dependencies. This post will walk you through the core components and considerations step-by…\nSource",
      "publishedAt": "2025-10-22T15:00:00.000Z",
      "author": "Mehran Maghoumi",
      "source": "rss",
      "feedName": "NVIDIA Technical Blog",
      "ingestedAt": "2025-11-21T02:45:16.043Z"
    },
    {
      "id": "4d6c298a97dc39c7c8ac85d557d60e3c",
      "title": "MMCTAgent: Enabling multimodal reasoning over large video and image collections",
      "url": "https://www.microsoft.com/en-us/research/blog/mmctagent-enabling-multimodal-reasoning-over-large-video-and-image-collections/",
      "content": "<p>MMCTAgent enables dynamic multimodal reasoning with iterative planning and reflection. Built on Microsoft’s AutoGen framework, it integrates language, vision, and temporal understanding for complex tasks like long video and image analysis.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/research/blog/mmctagent-enabling-multimodal-reasoning-over-large-video-and-image-collections/\">MMCTAgent: Enabling multimodal reasoning over large video and image collections</a> appeared first on <a href=\"https://www.microsoft.com/en-us/research\">Microsoft Research</a>.</p>\n",
      "summary": "MMCTAgent enables dynamic multimodal reasoning with iterative planning and reflection. Built on Microsoft’s AutoGen framework, it integrates language, vision, and temporal understanding for complex tasks like long video and image analysis.\nThe post MMCTAgent: Enabling multimodal reasoning over large video and image collections appeared first on Microsoft Research.",
      "publishedAt": "2025-11-12T12:00:20.000Z",
      "author": "Akshay Nambi, Kavyansh Chourasia, Tanuja Ganu",
      "source": "rss",
      "feedName": "Microsoft Research",
      "ingestedAt": "2025-11-21T02:45:16.642Z",
      "tags": [
        "Research Blog"
      ]
    },
    {
      "id": "e1538e7bb48330e25154b09b08d7ed03",
      "title": "BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI",
      "url": "https://www.microsoft.com/en-us/research/blog/bluecodeagent-a-blue-teaming-agent-enabled-by-automated-red-teaming-for-codegen-ai/",
      "content": "<p>BlueCodeAgent is an end-to-end blue-teaming framework built to boost code security using automated red-teaming processes, data, and safety rules to guide LLMs’ defensive decisions. Dynamic testing reduces false positives in vulnerability detection.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/research/blog/bluecodeagent-a-blue-teaming-agent-enabled-by-automated-red-teaming-for-codegen-ai/\">BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI</a> appeared first on <a href=\"https://www.microsoft.com/en-us/research\">Microsoft Research</a>.</p>\n",
      "summary": "BlueCodeAgent is an end-to-end blue-teaming framework built to boost code security using automated red-teaming processes, data, and safety rules to guide LLMs’ defensive decisions. Dynamic testing reduces false positives in vulnerability detection.\nThe post BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI appeared first on Microsoft Research.",
      "publishedAt": "2025-11-11T17:00:00.000Z",
      "author": "Chengquan Guo , Yuzhou  Nie, Chulin Xie, Zinan Lin, Wenbo Guo, Bo Li",
      "source": "rss",
      "feedName": "Microsoft Research",
      "ingestedAt": "2025-11-21T02:45:16.643Z",
      "tags": [
        "Research Blog"
      ]
    },
    {
      "id": "8b5864e7f9e9f47e4f38934f260f4276",
      "title": "When industry knowledge meets PIKE-RAG: The innovation behind Signify’s customer service boost",
      "url": "https://www.microsoft.com/en-us/research/blog/when-industry-knowledge-meets-pike-rag-the-innovation-behind-signifys-customer-service-boost/",
      "content": "<p>A collaboration between Signify and Microsoft Research shows how PIKE-RAG improves enterprise knowledge systems, delivering a 12% increase in accuracy and faster, more reliable answers.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/research/blog/when-industry-knowledge-meets-pike-rag-the-innovation-behind-signifys-customer-service-boost/\">When industry knowledge meets PIKE-RAG: The innovation behind Signify’s customer service boost</a> appeared first on <a href=\"https://www.microsoft.com/en-us/research\">Microsoft Research</a>.</p>\n",
      "summary": "A collaboration between Signify and Microsoft Research shows how PIKE-RAG improves enterprise knowledge systems, delivering a 12% increase in accuracy and faster, more reliable answers.\nThe post When industry knowledge meets PIKE-RAG: The innovation behind Signify’s customer service boost appeared first on Microsoft Research.",
      "publishedAt": "2025-11-06T13:00:00.000Z",
      "author": "Industry  Innovation Center",
      "source": "rss",
      "feedName": "Microsoft Research",
      "ingestedAt": "2025-11-21T02:45:16.643Z",
      "tags": [
        "Research Blog"
      ]
    },
    {
      "id": "d37feea1b20226380a6f777c4aa24b4b",
      "title": "Magentic Marketplace: an open-source simulation environment for studying agentic markets",
      "url": "https://www.microsoft.com/en-us/research/blog/magentic-marketplace-an-open-source-simulation-environment-for-studying-agentic-markets/",
      "content": "<p>AI agents are poised to transform digital marketplaces. To explore what can happen when AI agents interact and transact at scale, we built Magentic Marketplace, an open-source simulation environment for studying agentic market designs.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/research/blog/magentic-marketplace-an-open-source-simulation-environment-for-studying-agentic-markets/\">Magentic Marketplace: an open-source simulation environment for studying agentic markets</a> appeared first on <a href=\"https://www.microsoft.com/en-us/research\">Microsoft Research</a>.</p>\n",
      "summary": "AI agents are poised to transform digital marketplaces. To explore what can happen when AI agents interact and transact at scale, we built Magentic Marketplace, an open-source simulation environment for studying agentic market designs.\nThe post Magentic Marketplace: an open-source simulation environment for studying agentic markets appeared first on Microsoft Research.",
      "publishedAt": "2025-11-05T17:00:00.000Z",
      "author": "Gagan Bansal, Wenyue Hua, Zachary Huang, Adam Fourney, Amanda Swearngin, Chinmay Singh, Brendan Lucier, Jake Hofman, Markus Mobius, Will Epperson, Tyler Payne, Akshay Nambi, Archana Yadav, Maya Murad, Matthew Vogel, Alex Slivkins, Dan Goldstein, David Rothschild, Hussein Mozannar, Nicole Immorlica, Eric Horvitz, Saleema Amershi",
      "source": "rss",
      "feedName": "Microsoft Research",
      "ingestedAt": "2025-11-21T02:45:16.643Z",
      "tags": [
        "Research Blog"
      ]
    },
    {
      "id": "2e88d1228c67793327b8a378f2e8fde2",
      "title": "RedCodeAgent: Automatic red-teaming agent against diverse code agents",
      "url": "https://www.microsoft.com/en-us/research/blog/redcodeagent-automatic-red-teaming-agent-against-diverse-code-agents/",
      "content": "<p>Code agents help streamline software development workflows, but may also introduce critical security risks. Learn how RedCodeAgent automates and improves “red-teaming” attack simulations to help uncover real-world threats that other methods overlook.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/research/blog/redcodeagent-automatic-red-teaming-agent-against-diverse-code-agents/\">RedCodeAgent: Automatic red-teaming agent against diverse code agents</a> appeared first on <a href=\"https://www.microsoft.com/en-us/research\">Microsoft Research</a>.</p>\n",
      "summary": "Code agents help streamline software development workflows, but may also introduce critical security risks. Learn how RedCodeAgent automates and improves “red-teaming” attack simulations to help uncover real-world threats that other methods overlook.\nThe post RedCodeAgent: Automatic red-teaming agent against diverse code agents appeared first on Microsoft Research.",
      "publishedAt": "2025-11-04T17:00:00.000Z",
      "author": "Chengquan Guo , Chulin Xie, Yu Yang, Zhaorun Chen, Zinan Lin, Xander Davies, Yarin Gal, Dawn Song, Bo Li",
      "source": "rss",
      "feedName": "Microsoft Research",
      "ingestedAt": "2025-11-21T02:45:16.643Z",
      "tags": [
        "Research Blog"
      ]
    },
    {
      "id": "d0e47e1fa6f211a165f23b45cebc2168",
      "title": "Introducing AnyLanguageModel: One API for Local and Remote LLMs on Apple Platforms",
      "url": "https://huggingface.co/blog/anylanguagemodel",
      "publishedAt": "2025-11-20T00:00:00.000Z",
      "source": "rss",
      "feedName": "Hugging Face Blog",
      "ingestedAt": "2025-11-21T02:45:16.786Z"
    },
    {
      "id": "4208ed9a10c0db9eb4b7913070de773e",
      "title": "Easily Build and Share ROCm Kernels with Hugging Face",
      "url": "https://huggingface.co/blog/build-rocm-kernels",
      "publishedAt": "2025-11-17T00:00:00.000Z",
      "source": "rss",
      "feedName": "Hugging Face Blog",
      "ingestedAt": "2025-11-21T02:45:16.786Z"
    },
    {
      "id": "4dd439ce56d1a4a91ec4dd87d24d0ad0",
      "title": "Building for an Open Future - our new partnership with Google Cloud",
      "url": "https://huggingface.co/blog/google-cloud",
      "publishedAt": "2025-11-13T00:00:00.000Z",
      "source": "rss",
      "feedName": "Hugging Face Blog",
      "ingestedAt": "2025-11-21T02:45:16.786Z"
    },
    {
      "id": "c18db287fabe639c5d40e9ff0c8cc7a7",
      "title": "Building a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac",
      "url": "https://huggingface.co/blog/lerobotxnvidia-healthcare",
      "publishedAt": "2025-10-29T00:00:00.000Z",
      "source": "rss",
      "feedName": "Hugging Face Blog",
      "ingestedAt": "2025-11-21T02:45:16.786Z"
    },
    {
      "id": "e4cbf13488696e0deed63f3dc509d03e",
      "title": "Voice Cloning with Consent",
      "url": "https://huggingface.co/blog/voice-consent-gate",
      "publishedAt": "2025-10-28T00:00:00.000Z",
      "source": "rss",
      "feedName": "Hugging Face Blog",
      "ingestedAt": "2025-11-21T02:45:16.786Z"
    },
    {
      "id": "69efa858b7d4dad088b218d0fe4cf6d8",
      "title": "Streaming datasets: 100x More Efficient",
      "url": "https://huggingface.co/blog/streaming-datasets",
      "publishedAt": "2025-10-27T00:00:00.000Z",
      "source": "rss",
      "feedName": "Hugging Face Blog",
      "ingestedAt": "2025-11-21T02:45:16.786Z"
    },
    {
      "id": "10e206b36474a5194b9af21801258cd1",
      "title": "huggingface_hub v1.0: Five Years of Building the Foundation of Open Machine Learning",
      "url": "https://huggingface.co/blog/huggingface-hub-v1",
      "publishedAt": "2025-10-27T00:00:00.000Z",
      "source": "rss",
      "feedName": "Hugging Face Blog",
      "ingestedAt": "2025-11-21T02:45:16.786Z"
    },
    {
      "id": "9d667127d13fe08e8c0932e589340ee1",
      "title": "LeRobot v0.4.0: Supercharging OSS Robot Learning",
      "url": "https://huggingface.co/blog/lerobot-release-v040",
      "publishedAt": "2025-10-24T00:00:00.000Z",
      "source": "rss",
      "feedName": "Hugging Face Blog",
      "ingestedAt": "2025-11-21T02:45:16.786Z"
    },
    {
      "id": "26941504a00a135727f10c7d37321ecf",
      "title": "Building the Open Agent Ecosystem Together: Introducing OpenEnv",
      "url": "https://huggingface.co/blog/openenv",
      "publishedAt": "2025-10-23T00:00:00.000Z",
      "source": "rss",
      "feedName": "Hugging Face Blog",
      "ingestedAt": "2025-11-21T02:45:16.786Z"
    },
    {
      "id": "1e802ce4ceb9c901e8602ad55232d70d",
      "title": "Bringing RAG to Life with Dify and Weaviate",
      "url": "https://weaviate.io/blog/dify-and-weaviate",
      "content": "Learn how to use the Dify and Weaviate integration to build RAG applications.",
      "summary": "Learn how to use the Dify and Weaviate integration to build RAG applications.",
      "publishedAt": "2025-11-20T00:00:00.000Z",
      "source": "rss",
      "feedName": "Weaviate Blog",
      "ingestedAt": "2025-11-21T02:45:17.322Z",
      "tags": [
        "integrations"
      ]
    },
    {
      "id": "e3af55eae5673c9951805a293075367c",
      "title": "Weaviate 1.34 Release",
      "url": "https://weaviate.io/blog/weaviate-1-34-release",
      "content": "1.34 introduces flat index support with RQ quantization, server-side batching improvements, new client libraries, Contextual AI integration and much more.",
      "summary": "1.34 introduces flat index support with RQ quantization, server-side batching improvements, new client libraries, Contextual AI integration and much more.",
      "publishedAt": "2025-11-11T00:00:00.000Z",
      "source": "rss",
      "feedName": "Weaviate Blog",
      "ingestedAt": "2025-11-21T02:45:17.322Z",
      "tags": [
        "release",
        "engineering"
      ]
    },
    {
      "id": "f62804b712d1ada5001e8a9a1f688921",
      "title": "Weaviate security release - Medium and High severity fixes for CVEs",
      "url": "https://weaviate.io/blog/weaviate-security-release-november-2025",
      "content": "Weaviate announces two CVEs that are fixed in updated versions of our product.",
      "summary": "Weaviate announces two CVEs that are fixed in updated versions of our product.",
      "publishedAt": "2025-11-07T00:00:00.000Z",
      "source": "rss",
      "feedName": "Weaviate Blog",
      "ingestedAt": "2025-11-21T02:45:17.322Z",
      "tags": [
        "security"
      ]
    },
    {
      "id": "ec6048630c0893f3c102e80046236cb0",
      "title": "From Kitchen Experiments to Five Star Service: The Weaviate Development Journey",
      "url": "https://weaviate.io/blog/day0-day1-day2-operations",
      "content": "What building AI apps with Weaviate and cooking have in common? Let’s find out!",
      "summary": "What building AI apps with Weaviate and cooking have in common? Let’s find out!",
      "publishedAt": "2025-11-06T00:00:00.000Z",
      "source": "rss",
      "feedName": "Weaviate Blog",
      "ingestedAt": "2025-11-21T02:45:17.323Z"
    },
    {
      "id": "c0b8796e8d8ada550a22d3b93c07d6a9",
      "title": "Evals and Guardrails in Enterprise workflows (Part 3)",
      "url": "https://weaviate.io/blog/evals-enterprise-workflows-3",
      "content": "Hands-on patterns: Design pattern for gen-AI enterprise applications, with Arize AI.",
      "summary": "Hands-on patterns: Design pattern for gen-AI enterprise applications, with Arize AI.",
      "publishedAt": "2025-11-04T00:00:00.000Z",
      "source": "rss",
      "feedName": "Weaviate Blog",
      "ingestedAt": "2025-11-21T02:45:17.323Z",
      "tags": [
        "concepts",
        "Agents",
        "How-To",
        "Engineering"
      ]
    },
    {
      "id": "e2aa7c1c97c1a9a707d2755b8a58267e",
      "title": "Unleash Real-Time Agentic AI with Streaming Agents on Confluent Cloud and Weaviate",
      "url": "https://weaviate.io/blog/confluent-streaming-agents-and-weaviate",
      "content": "Learn how Confluent’s Streaming Agents and Weaviate combine real-time context with semantic understanding for agentic AI.",
      "summary": "Learn how Confluent’s Streaming Agents and Weaviate combine real-time context with semantic understanding for agentic AI.",
      "publishedAt": "2025-10-30T00:00:00.000Z",
      "source": "rss",
      "feedName": "Weaviate Blog",
      "ingestedAt": "2025-11-21T02:45:17.323Z",
      "tags": [
        "partnerships"
      ]
    },
    {
      "id": "cfad02c62500a1043203f07f108506a9",
      "title": "A Simpler, More Transparent Pricing Model for Weaviate Cloud",
      "url": "https://weaviate.io/blog/weaviate-cloud-pricing-update",
      "content": "Weaviate Cloud gets an updated pricing model.",
      "summary": "Weaviate Cloud gets an updated pricing model.",
      "publishedAt": "2025-10-28T00:00:00.000Z",
      "source": "rss",
      "feedName": "Weaviate Blog",
      "ingestedAt": "2025-11-21T02:45:17.323Z",
      "tags": [
        "release"
      ]
    },
    {
      "id": "c6c36d19bd8a791c8f3ef1931c1b1c82",
      "title": "GitLab 18.6: From configuration to control",
      "url": "https://about.gitlab.com/blog/gitlab-18-6-from-configuration-to-control/",
      "content": "<p>With <a href=\"https://about.gitlab.com/releases/2025/11/20/gitlab-18-6-released/\">GitLab 18.6</a>, we’re continuing to advance how AI integrates into everyday software development with enhancements that give teams greater choice and control. GitLab 18.6 will help plan, build, and secure software more intelligently across the entire software lifecycle.\nTeams now have greater flexibility to select the right models for their workflows, extend AI into secure and self-managed environments, and strengthen visibility and governance across every stage of development.</p>\n<h2>AI that adapts to you</h2>\n<p>With 18.6, GitLab’s AI becomes more adaptable to real-world workflows. GitLab Duo Agents now plan with greater context, work seamlessly across IDEs and self-managed instances, and offer new open-source model options — helping teams accelerate delivery without compromising compliance or control.</p>\n<p><strong>GitLab Duo Planner and Security Analyst agent enhancements</strong></p>\n<p>In 18.6, <a href=\"https://about.gitlab.com/blog/ace-your-planning-without-the-context-switching/\">GitLab Duo Planner</a> and <a href=\"https://docs.gitlab.com/user/duo_agent_platform/agents/foundational_agents/security_analyst_agent/\">GitLab Duo Security Analyst</a> are now available by default in the Agentic Chat dropdown — no configuration or setup required. Both agents can be used immediately across projects and groups, giving teams built-in assistance for planning, issue refinement, and security analysis.</p>\n<p>GitLab Duo Planner agent now works at the group level with awareness of the epic being viewed and supports milestone and iteration workflows. Security Analyst agent provides automated vulnerability review, context interpretation, and guided remediation suggestions. Both agents are also available to self-managed customers.</p>\n<p>For a full list of what these agents can do, see the <a href=\"https://docs.gitlab.com/user/duo_agent_platform/agents/foundational_agents/\">documentation</a>.</p>\n<p><strong>gpt-oss-120b model support for GitLab Duo Agent Platform</strong></p>\n<p>GitLab Duo Self-Hosted customers can now deploy the <a href=\"https://platform.openai.com/docs/models/gpt-oss-120b\"><strong>gpt-oss-120b</strong></a> model within the GitLab Duo Agent Platform — a high-performance, fully open-source model optimized for agentic workflows. This addition enables teams to execute complex tasks and reasoning-driven processes while maintaining control over model transparency and infrastructure. For organizations that require open, auditable models to address compliance or data sovereignty requirements, gpt-oss-120b provides a reliable alternative to proprietary models without sacrificing performance.</p>\n<p>For more information on supported models, please see our <a href=\"https://docs.gitlab.com/administration/gitlab_duo_self_hosted/supported_models_and_hardware_requirements/#supported-models\">documentation</a>.</p>\n<p><strong>End-user model selection for cloud-connected self-managed instances (GA)</strong></p>\n<p>Cloud-connected self-managed end users can now choose which AI model powers their GitLab Duo Agentic Chat experience directly from the GitLab UI. This gives administrators and end users more control over how conversations perform and how costs and governance requirements are managed.</p>\n<p>No matter the deployment environment — on-premises, private cloud, or public cloud —  teams can select regionally compliant or in-house models to help satisfy data residency needs and compare model quality for speed or accuracy. This flexibility ensures that every organization can tailor Agentic Chat to its operational priorities.</p>\n<p>For full details on how to select a model in Agentic Chat, see the model selection section of the GitLab <a href=\"https://docs.gitlab.com/user/gitlab_duo_chat/agentic_chat/#select-a-model\">documentation</a>.</p>\n<p><strong>Web IDE support for air-gapped deployments</strong></p>\n<p>Air-gapped or tightly controlled environments — such as public sector organizations, defense agencies, and regulated enterprises — can now run the Web IDE with full functionality even without internet access. By allowing administrators to configure their own Web IDE extension host domain, GitLab enables markdown preview, code editing, and GitLab Duo Chat capabilities in isolated or offline systems. This makes it possible for development teams in secure or restricted networks to benefit from modern IDE workflows without sacrificing security and compliance.</p>\n<p><strong>Modern interface now default for self-managed instances</strong></p>\n<p>Self-managed GitLab instances now default to the modern interface in 18.6, bringing the same streamlined experience already available on GitLab.com to on-premises deployments. The updated layout improves navigation consistency and makes core workflows more intuitive across the platform. Administrators maintain full flexibility with opt-out controls via feature flag or user-level toggling if needed. This update ensures self-managed customers benefit from GitLab's latest interface improvements while maintaining the control and customization options enterprise environments require.</p>\n<h2>Platform security with awareness and authority</h2>\n<p>GitLab 18.6 strengthens platform security with deeper context and clearer control, helping security teams focus on the risks that matter most while maintaining governance across every project.</p>\n<p><strong>Security attributes and context filtering</strong></p>\n<p>Security teams can now apply custom business context labels to projects and groups, transforming raw scan results into prioritized, risk-based insights. Instead of viewing vulnerabilities in isolation, teams can tag projects by business unit, application type, or criticality — then filter and sort security data by impact. This allows organizations to focus remediation on the areas of greatest business risk, helping to accelerate time to resolution for the issues that matter most.</p>\n<p><strong>Security Manager default role</strong></p>\n<p>To simplify access control and onboarding for security professionals, GitLab introduces a new Security Manager role. This role provides comprehensive permissions across vulnerability management, policy configuration, and compliance features — while maintaining separation of duties by restricting administrative and code modification rights. Security teams gain the access they need from day one, along with governance, consistency, and accountability across the platform.</p>\n<h2>AI that adapts to your workflow</h2>\n<p>This release represents more than new capabilities — it's about how GitLab Duo Agent Platform is becoming an embedded part of everyday software development workflows. Watch a walkthrough video that shows how a member of your software development team can start on a new project using GitLab Duo Agent Platform:</p>\n<p>&lt;div style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/1138657697?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share&quot; referrerpolicy=&quot;strict-origin-when-cross-origin&quot; style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot; title=&quot;18.6 Demo (TO BE UPDATED)&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;script src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;</p>\n<h2>Get started today</h2>\n<p>GitLab Premium and Ultimate users can start using these capabilities today on <a href=\"https://GitLab.com\">GitLab.com</a> and self-managed environments, with availability for GitLab Dedicated customers planned for next month.</p>\n<p>New to GitLab? <a href=\"https://about.gitlab.com/free-trial/devsecops/\">Start your free trial</a> and see why the future of development is AI-powered, secure, and orchestrated through the world’s most comprehensive DevSecOps platform.</p>\n<p><em><strong>Note:</strong> GitLab Duo Agent Platform is currently in beta. Platform capabilities that are in beta are available as part of the GitLab Beta program. They are free to use during the beta period, and when generally available, they are planned to be made available with a paid add-on option for GitLab Duo Agent Platform.</em></p>\n<h3>Stay up to date with GitLab</h3>\n<p>To make sure you’re getting the latest features, security updates, and performance improvements, we recommend keeping your GitLab instance up to date. The following resources can help you plan and complete your upgrade:</p>\n<ul>\n<li>\n<p><a href=\"https://gitlab-com.gitlab.io/support/toolbox/upgrade-path/\">Upgrade Path Tool</a> — enter your current version and see the exact upgrade steps for your instance</p>\n</li>\n<li>\n<p><a href=\"https://docs.gitlab.com/update/upgrade_paths/\">Upgrade Documentation</a> — detailed guides for each supported version, including requirements, step-by-step instructions, and best practices</p>\n</li>\n</ul>\n<p>By upgrading regularly, you’ll ensure your team benefits from the newest GitLab capabilities and remains secure and supported.</p>\n<p>For organizations that want a hands-off approach, consider <a href=\"https://content.gitlab.com/viewer/d1fe944dddb06394e6187f0028f010ad#1\">GitLab’s Managed Maintenance service</a>. With Managed Maintenance, your team stays focused on innovation while GitLab experts keep your Self-Managed instance reliably upgraded, secure, and ready to lead in DevSecOps. Ask your account manager for more information.</p>\n<p><em>This blog post contains &quot;forward‑looking statements&quot; within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934. Although we believe that the expectations reflected in these statements are reasonable, they are subject to known and unknown risks, uncertainties, assumptions and other factors that may cause actual results or outcomes to differ materially. Further information on these risks and other factors is included under the caption &quot;Risk Factors&quot; in our filings with the SEC. We do not undertake any obligation to update or revise these statements after the date of this blog post, except as required by law.</em></p>\n",
      "summary": "With GitLab 18.6, we’re continuing to advance how AI integrates into everyday software development with enhancements that give teams greater choice and control. GitLab 18.6 will help plan, build, and secure software more intelligently across the entire software lifecycle.\nTeams now have greater flexibility to select the right models for their workflows, extend AI into secure and self-managed environments, and strengthen visibility and governance across every stage of development.\nAI that adapts to you\nWith 18.6, GitLab’s AI becomes more adaptable to real-world workflows. GitLab Duo Agents now plan with greater context, work seamlessly across IDEs and self-managed instances, and offer new open-source model options — helping teams accelerate delivery without compromising compliance or control.\nGitLab Duo Planner and Security Analyst agent enhancements\nIn 18.6, GitLab Duo Planner and GitLab Duo Security Analyst are now available by default in the Agentic Chat dropdown — no configuration or setup required. Both agents can be used immediately across projects and groups, giving teams built-in assistance for planning, issue refinement, and security analysis.\nGitLab Duo Planner agent now works at the group level with awareness of the epic being viewed and supports milestone and iteration workflows. Security Analyst agent provides automated vulnerability review, context interpretation, and guided remediation suggestions. Both agents are also available to self-managed customers.\nFor a full list of what these agents can do, see the documentation.\ngpt-oss-120b model support for GitLab Duo Agent Platform\nGitLab Duo Self-Hosted customers can now deploy the gpt-oss-120b model within the GitLab Duo Agent Platform — a high-performance, fully open-source model optimized for agentic workflows. This addition enables teams to execute complex tasks and reasoning-driven processes while maintaining control over model transparency and infrastructure. For organizations that require open, auditable models to address compliance or data sovereignty requirements, gpt-oss-120b provides a reliable alternative to proprietary models without sacrificing performance.\nFor more information on supported models, please see our documentation.\nEnd-user model selection for cloud-connected self-managed instances (GA)\nCloud-connected self-managed end users can now choose which AI model powers their GitLab Duo Agentic Chat experience directly from the GitLab UI. This gives administrators and end users more control over how conversations perform and how costs and governance requirements are managed.\nNo matter the deployment environment — on-premises, private cloud, or public cloud —  teams can select regionally compliant or in-house models to help satisfy data residency needs and compare model quality for speed or accuracy. This flexibility ensures that every organization can tailor Agentic Chat to its operational priorities.\nFor full details on how to select a model in Agentic Chat, see the model selection section of the GitLab documentation.\nWeb IDE support for air-gapped deployments\nAir-gapped or tightly controlled environments — such as public sector organizations, defense agencies, and regulated enterprises — can now run the Web IDE with full functionality even without internet access. By allowing administrators to configure their own Web IDE extension host domain, GitLab enables markdown preview, code editing, and GitLab Duo Chat capabilities in isolated or offline systems. This makes it possible for development teams in secure or restricted networks to benefit from modern IDE workflows without sacrificing security and compliance.\nModern interface now default for self-managed instances\nSelf-managed GitLab instances now default to the modern interface in 18.6, bringing the same streamlined experience already available on GitLab.com to on-premises deployments. The updated layout improves navigation consistency and makes core workflows more intuitive across the platform. Administrators maintain full flexibility with opt-out controls via feature flag or user-level toggling if needed. This update ensures self-managed customers benefit from GitLab's latest interface improvements while maintaining the control and customization options enterprise environments require.\nPlatform security with awareness and authority\nGitLab 18.6 strengthens platform security with deeper context and clearer control, helping security teams focus on the risks that matter most while maintaining governance across every project.\nSecurity attributes and context filtering\nSecurity teams can now apply custom business context labels to projects and groups, transforming raw scan results into prioritized, risk-based insights. Instead of viewing vulnerabilities in isolation, teams can tag projects by business unit, application type, or criticality — then filter and sort security data by impact. This allows organizations to focus remediation on the areas of greatest business risk, helping to accelerate time to resolution for the issues that matter most.\nSecurity Manager default role\nTo simplify access control and onboarding for security professionals, GitLab introduces a new Security Manager role. This role provides comprehensive permissions across vulnerability management, policy configuration, and compliance features — while maintaining separation of duties by restricting administrative and code modification rights. Security teams gain the access they need from day one, along with governance, consistency, and accountability across the platform.\nAI that adapts to your workflow\nThis release represents more than new capabilities — it's about how GitLab Duo Agent Platform is becoming an embedded part of everyday software development workflows. Watch a walkthrough video that shows how a member of your software development team can start on a new project using GitLab Duo Agent Platform:\n<div style=\"padding:56.25% 0 0 0;position:relative;\"><iframe src=\"https://player.vimeo.com/video/1138657697?badge=0&autopause=0&player_id=0&app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"18.6 Demo (TO BE UPDATED)\"></iframe></div><script src=\"https://player.vimeo.com/api/player.js\"></script>\nGet started today\nGitLab Premium and Ultimate users can start using these capabilities today on GitLab.com and self-managed environments, with availability for GitLab Dedicated customers planned for next month.\nNew to GitLab? Start your free trial and see why the future of development is AI-powered, secure, and orchestrated through the world’s most comprehensive DevSecOps platform.\nNote: GitLab Duo Agent Platform is currently in beta. Platform capabilities that are in beta are available as part of the GitLab Beta program. They are free to use during the beta period, and when generally available, they are planned to be made available with a paid add-on option for GitLab Duo Agent Platform.\nStay up to date with GitLab\nTo make sure you’re getting the latest features, security updates, and performance improvements, we recommend keeping your GitLab instance up to date. The following resources can help you plan and complete your upgrade:\nUpgrade Path Tool — enter your current version and see the exact upgrade steps for your instance\nUpgrade Documentation — detailed guides for each supported version, including requirements, step-by-step instructions, and best practices\nBy upgrading regularly, you’ll ensure your team benefits from the newest GitLab capabilities and remains secure and supported.\nFor organizations that want a hands-off approach, consider GitLab’s Managed Maintenance service. With Managed Maintenance, your team stays focused on innovation while GitLab experts keep your Self-Managed instance reliably upgraded, secure, and ready to lead in DevSecOps. Ask your account manager for more information.\nThis blog post contains \"forward‑looking statements\" within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934. Although we believe that the expectations reflected in these statements are reasonable, they are subject to known and unknown risks, uncertainties, assumptions and other factors that may cause actual results or outcomes to differ materially. Further information on these risks and other factors is included under the caption \"Risk Factors\" in our filings with the SEC. We do not undertake any obligation to update or revise these statements after the date of this blog post, except as required by law.",
      "publishedAt": "2025-11-20T00:00:00.000Z",
      "author": "Bill Staples",
      "source": "rss",
      "feedName": "GitLab Engineering",
      "ingestedAt": "2025-11-21T02:45:17.559Z"
    },
    {
      "id": "e1a987b4ca19fee90af038f7a93e15f0",
      "title": "GitLab engineer: How I improved my onboarding experience with AI",
      "url": "https://about.gitlab.com/blog/gitlab-engineer-how-i-improved-my-onboarding-experience-with-ai/",
      "content": "<p>Starting a new job is exciting, and overwhelming. New teammates, new tools, and, in GitLab’s case, a lot of documentation. Six weeks ago, I joined GitLab’s Growth team as a fullstack engineer. Anyone who has gone through <a href=\"https://about.gitlab.com/the-source/platform/how-to-accelerate-developer-onboarding-and-why-it-matters/\">onboarding at GitLab</a> knows it’s transparent, extensive, and thorough.</p>\n<p>GitLab's onboarding process includes a lot of docs, videos, and trainings that will bring you up to speed. Also, in line with GitLab's values, my team encouraged me to start contributing right away. I quickly realized that onboarding here is both diligent and intense. Luckily, I had a secret helper: <a href=\"https://about.gitlab.com/gitlab-duo/\">GitLab Duo</a>.</p>\n<h2>My main use cases</h2>\n<p>I’ve found GitLab Duo's AI assistance, available throughout the software development lifecycle, useful in three key areas: exploration, reviewing, and debugging. With GitLab Duo, I was able to get my first tiny MR deployed to production in the first week and actively contribute to <a href=\"https://about.gitlab.com/releases/2025/10/16/gitlab-18-5-released/#pick-up-where-you-left-off-on-the-new-personal-homepage\">the personal homepage</a> in GitLab 18.5 in the weeks after.</p>\n<h3>Exploration</h3>\n<p>Early in onboarding, I often remembered reading something but couldn’t recall where. GitLab has a <a href=\"https://handbook.gitlab.com/\">public-facing handbook</a>, an internal handbook, and <a href=\"https://docs.gitlab.com/\">GitLab Docs</a>. It can be difficult to search across all of them efficiently.</p>\n<p>GitLab Duo simplifies this task: I can describe what I’m looking for in natural language via <a href=\"https://docs.gitlab.com/user/gitlab_duo_chat/\">GitLab Duo Chat</a> and search across all resources at once.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>I remember reading about how RSpec tests are done at GitLab. Can you find relevant documentation across the Handbook, the internal handbook and the GitLab Docs?</p>\n</blockquote>\n<p>Before starting work on an issue, I use GitLab Duo to identify edge cases and hidden dependencies. GitLab Duo will relate the requirements of the issue against the whole GitLab codebase, assess similar features, and prepare all the findings. Based on its output I am able to refine the issue with my product manager and designer, and make sure my implementation covers all edge cases or define future iterations.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>Analyze this issue in the context of its epic and identify:</p>\n<ul>\n<li>Implementation questions to ask PM/design before coding</li>\n<li>Edge cases not covered in requirements</li>\n<li>Cross-feature dependencies that might be affected</li>\n<li>Missing acceptance criteria</li>\n</ul>\n</blockquote>\n<p>I also check that my planned solution follows GitLab best practices and common patterns.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>I want to implement XZY behavior — how is this usually done at GitLab, and what other options do I have?</p>\n</blockquote>\n<h3>Reviewing</h3>\n<p>I always <a href=\"https://docs.gitlab.com/user/project/merge_requests/duo_in_merge_requests/#have-gitlab-duo-review-your-code\">let GitLab Duo review my merge requests</a> before assigning human reviewers. It often catches small mistakes, suggests improvements, and highlights edge cases I missed. This shortens the review cycle and helps my teammates focus on more complex and bigger-picture feedback.</p>\n<p>Since I’m still new to GitLab’s codebase and coding practices, some review comments are hard to interpret. In those cases, GitLab Duo helps me understand what a reviewer means and how it relates to my code.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>I don’t understand the comment on this MR about following the user instead of testing component internals, what does it mean and how does it relate to my implementation?</p>\n</blockquote>\n<h3>Debugging</h3>\n<p>Sometimes pipeline tests on my merge requests failed unexpectedly. If I can’t tell whether my changes are the cause, GitLab Duo helps me investigate and fix the failures. Using <a href=\"https://docs.gitlab.com/user/gitlab_duo_chat/agentic_chat/\">GitLab Duo Agentic Chat</a>, Duo can apply changes to debug the failing job.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>The pipeline job “rspec system pg16 12/32” is failing, but I don’t know whether that relates to my changes. Can you check, if my changes are causing the pipeline failure and, if so, guide me through the steps of fixing it.</p>\n</blockquote>\n<h2>How Duo aligns with GitLab’s values</h2>\n<p>Using GitLab Duo doesn’t just help me, it also supports <a href=\"https://handbook.gitlab.com/handbook/values/\">GitLab’s CREDIT values</a>:</p>\n<ul>\n<li>\n<p><strong>Collaboration:</strong> I ask teammates fewer basic questions. And when I do ask questions, they’re more thoughtful and informed. This respects their time.</p>\n</li>\n<li>\n<p><strong>Results for customers:</strong> By identifying edge cases early and improving code quality, GitLab Duo helps me deliver better outcomes for customers.</p>\n</li>\n<li>\n<p><strong>Efficiency:</strong> Streamlined preparation, faster reviews, and improved debugging make me more efficient.</p>\n</li>\n<li>\n<p><strong>Diversity, inclusion &amp; belonging:</strong> AI guidance might mitigate misunderstandings and different barriers to entry based on differing backgrounds and abilities.</p>\n</li>\n<li>\n<p><strong>Iteration:</strong> The ability to try ideas faster and identify potential improvements, enables faster iteration.</p>\n</li>\n<li>\n<p><strong>Transparency:</strong> GitLab Duo makes the already transparent documentation at GitLab more accessible.</p>\n</li>\n</ul>\n<h2>Staying cautious with AI</h2>\n<p>It never has been as easy and difficult to be competent as in the days of AI. It can be a powerful tool, but AI does get things wrong. Therefore, I avoid <a href=\"https://link.springer.com/article/10.1007/s00146-025-02422-7\">automation bias</a> by always validating AI's outputs. If I don’t understand the output, I don’t use it.\nI’m also cautious of over-reliance. Studies suggest that heavy AI use can lead to <a href=\"https://www.mdpi.com/2075-4698/15/1/6\">cognitive offloading</a> and worse outcomes in the long run. One study shows that users of AI <a href=\"https://arxiv.org/abs/2404.19699?utm_source=chatgpt.com\">perform worse in exams</a>. To avoid negatively affecting my skills, I use AI as a discussion partner rather than just implementing the code it generates.</p>\n<h2>Summary</h2>\n<p>Onboarding is always a stressful time, but using GitLab Duo made mine smoother and less overwhelming. I learned more about GitLab’s codebase, culture, and best practices than I could have managed on my own.</p>\n<blockquote>\n<p>Want to make GitLab Duo part of your onboarding experience? Sign up for <a href=\"https://about.gitlab.com/gitlab-duo/\">a free trial</a> today.</p>\n</blockquote>\n<h2>Resources</h2>\n<ul>\n<li><a href=\"https://docs.gitlab.com/user/get_started/getting_started_gitlab_duo/\">Getting started with GitLab Duo</a></li>\n<li><a href=\"https://about.gitlab.com/blog/get-started-with-gitlab-duo-agentic-chat-in-the-web-ui/\">Get started with GitLab Duo Agentic Chat in the web UI</a></li>\n<li><a href=\"https://about.gitlab.com/blog/10-best-practices-for-using-ai-powered-gitlab-duo-chat/\">10 best practices for using AI-powered GitLab Duo Chat</a></li>\n</ul>\n",
      "summary": "Starting a new job is exciting, and overwhelming. New teammates, new tools, and, in GitLab’s case, a lot of documentation. Six weeks ago, I joined GitLab’s Growth team as a fullstack engineer. Anyone who has gone through onboarding at GitLab knows it’s transparent, extensive, and thorough.\nGitLab's onboarding process includes a lot of docs, videos, and trainings that will bring you up to speed. Also, in line with GitLab's values, my team encouraged me to start contributing right away. I quickly realized that onboarding here is both diligent and intense. Luckily, I had a secret helper: GitLab Duo.\nMy main use cases\nI’ve found GitLab Duo's AI assistance, available throughout the software development lifecycle, useful in three key areas: exploration, reviewing, and debugging. With GitLab Duo, I was able to get my first tiny MR deployed to production in the first week and actively contribute to the personal homepage in GitLab 18.5 in the weeks after.\nExploration\nEarly in onboarding, I often remembered reading something but couldn’t recall where. GitLab has a public-facing handbook, an internal handbook, and GitLab Docs. It can be difficult to search across all of them efficiently.\nGitLab Duo simplifies this task: I can describe what I’m looking for in natural language via GitLab Duo Chat and search across all resources at once.\nExample prompt:\nI remember reading about how RSpec tests are done at GitLab. Can you find relevant documentation across the Handbook, the internal handbook and the GitLab Docs?\nBefore starting work on an issue, I use GitLab Duo to identify edge cases and hidden dependencies. GitLab Duo will relate the requirements of the issue against the whole GitLab codebase, assess similar features, and prepare all the findings. Based on its output I am able to refine the issue with my product manager and designer, and make sure my implementation covers all edge cases or define future iterations.\nExample prompt:\nAnalyze this issue in the context of its epic and identify:\nImplementation questions to ask PM/design before coding\nEdge cases not covered in requirements\nCross-feature dependencies that might be affected\nMissing acceptance criteria\nI also check that my planned solution follows GitLab best practices and common patterns.\nExample prompt:\nI want to implement XZY behavior — how is this usually done at GitLab, and what other options do I have?\nReviewing\nI always let GitLab Duo review my merge requests before assigning human reviewers. It often catches small mistakes, suggests improvements, and highlights edge cases I missed. This shortens the review cycle and helps my teammates focus on more complex and bigger-picture feedback.\nSince I’m still new to GitLab’s codebase and coding practices, some review comments are hard to interpret. In those cases, GitLab Duo helps me understand what a reviewer means and how it relates to my code.\nExample prompt:\nI don’t understand the comment on this MR about following the user instead of testing component internals, what does it mean and how does it relate to my implementation?\nDebugging\nSometimes pipeline tests on my merge requests failed unexpectedly. If I can’t tell whether my changes are the cause, GitLab Duo helps me investigate and fix the failures. Using GitLab Duo Agentic Chat, Duo can apply changes to debug the failing job.\nExample prompt:\nThe pipeline job “rspec system pg16 12/32” is failing, but I don’t know whether that relates to my changes. Can you check, if my changes are causing the pipeline failure and, if so, guide me through the steps of fixing it.\nHow Duo aligns with GitLab’s values\nUsing GitLab Duo doesn’t just help me, it also supports GitLab’s CREDIT values:\nCollaboration: I ask teammates fewer basic questions. And when I do ask questions, they’re more thoughtful and informed. This respects their time.\nResults for customers: By identifying edge cases early and improving code quality, GitLab Duo helps me deliver better outcomes for customers.\nEfficiency: Streamlined preparation, faster reviews, and improved debugging make me more efficient.\nDiversity, inclusion & belonging: AI guidance might mitigate misunderstandings and different barriers to entry based on differing backgrounds and abilities.\nIteration: The ability to try ideas faster and identify potential improvements, enables faster iteration.\nTransparency: GitLab Duo makes the already transparent documentation at GitLab more accessible.\nStaying cautious with AI\nIt never has been as easy and difficult to be competent as in the days of AI. It can be a powerful tool, but AI does get things wrong. Therefore, I avoid automation bias by always validating AI's outputs. If I don’t understand the output, I don’t use it.\nI’m also cautious of over-reliance. Studies suggest that heavy AI use can lead to cognitive offloading and worse outcomes in the long run. One study shows that users of AI perform worse in exams. To avoid negatively affecting my skills, I use AI as a discussion partner rather than just implementing the code it generates.\nSummary\nOnboarding is always a stressful time, but using GitLab Duo made mine smoother and less overwhelming. I learned more about GitLab’s codebase, culture, and best practices than I could have managed on my own.\nWant to make GitLab Duo part of your onboarding experience? Sign up for a free trial today.\nResources\nGetting started with GitLab Duo\nGet started with GitLab Duo Agentic Chat in the web UI\n10 best practices for using AI-powered GitLab Duo Chat",
      "publishedAt": "2025-11-17T00:00:00.000Z",
      "author": "Konstantin Greif",
      "source": "rss",
      "feedName": "GitLab Engineering",
      "ingestedAt": "2025-11-21T02:45:17.559Z"
    },
    {
      "id": "b33941af2e8b543ac60d0bed12fca5d3",
      "title": "Achieve CMMC Level 2 with GitLab Dedicated for Government",
      "url": "https://about.gitlab.com/blog/achieve-cmmc-level-2-fast-with-gitlab-dedicated-for-government/",
      "content": "<p>For Defense Industrial Base (DIB) companies, the U.S. Department of Defense's release of the Cybersecurity Maturity Model Certification (CMMC) <a href=\"https://www.federalregister.gov/documents/2025/09/10/2025-17359/defense-federal-acquisition-regulation-supplement-assessing-contractor-implementation-of_\">Final Rule</a> and new guidance on “FedRAMP equivalency” has dramatically increased the cost of compliance and fundamentally changed the way in which they drive their risk management programs. Gone is the era of “self-attestation” of security programs; DIB companies are required to strictly apply NIST 800-171 to their environments that handle Controlled Unclassified Information (CUI), and have their security controls audited by a Third-Party Assessment Organization (3PAO) every three years.</p>\n<p>DIB companies are engineering focused, not compliance driven, and formal audits get pricey quickly. These changes add significant complications for companies focused on supporting the warfighter. The good news? <a href=\"https://about.gitlab.com/press/releases/2025-05-19-gitlab-announces-gitlab-achieves-fedramp-moderate-authorization/\">GitLab Dedicated for Government's FedRAMP Moderate Authorization</a> means DIB companies can directly use GitLab Dedicated for Government with no additional audits or authorizations, which reduces the impact and cost of compliance.</p>\n<h2>The foundational rule: FedRAMP Moderate Equivalency</h2>\n<p>The protection of Controlled Unclassified Information (CUI) within the DIB is driven by a foundational legal and contractual mandate: the Defense Federal Acquisition Regulation Supplement (DFARS) <a href=\"https://www.acquisition.gov/dfars/252.204-7012-safeguarding-covered-defense-information-and-cyber-incident-reporting.\">Clause 252.204-7012</a>. This clause specifically states that if a contractor uses an external cloud service provider to &quot;store, process, or transmit any covered defense information,&quot; that provider must meet security requirements &quot;equivalent to those established by the Government for the FedRAMP Moderate baseline.&quot;</p>\n<p>The DOD's January 2, 2024, memorandum, &quot;<a href=\"https://dodcio.defense.gov/Portals/0/Documents/Library/FEDRAMP-EquivalencyCloudServiceProviders.pdf\">Federal Risk and Authorization Management Program (FedRAMP) Moderate Equivalency for Cloud Service Provider's (CSPs) Cloud Service Offerings</a>&quot; defines “FedRAMP Moderate Equivalency,” and also directly specifies that FedRAMP Moderate Cloud Service Offerings (CSOs) can be used without any additional assessment, such as individual CMMC assessment, to meet equivalency requirements:</p>\n<p>“This memorandum does not apply to CSOs that are FedRAMP Moderate Authorized under the existing FedRAMP process. <strong>FedRAMP Moderate Authorized CSOs identified in the FedRAMP Marketplace</strong> provide the required security to store, process or transmit CDI in accordance with Defense Federal Acquisition Regulations Supplement (DFARS) Clause 252.204-7012, &quot;Safeguarding Covered Defense Information and Cyber Incident Reporting&quot; and <strong>can be leveraged without further assessment to meet the equivalency requirements</strong>.”</p>\n<h2>The GitLab platform: A proven path to compliance</h2>\n<p>GitLab's GovCloud Offering, GitLab Dedicated for Government, <a href=\"https://marketplace.fedramp.gov/products/FR2411959145\">has achieved FedRAMP Moderate Authorization</a>. This means that DIB companies can leverage GitLab Dedicated for Government as their DevSecOps platform immediately and without any additional audits or compliance checks. DIB companies leveraging GitLab Dedicated for Government inherit all of our security controls and our Body of Evidence, shifting the risk and cost of compliance away from themselves and allowing them to focus on their mission.</p>\n<h2>The Shared Responsibility Matrix: Your role as a DIB contractor</h2>\n<p>While a FedRAMP-authorized solution significantly reduces your compliance burden, compliance is a joint effort. You are responsible for the security controls that fall under your purview. This is where the Shared Responsibility Matrix (SRM), also called the Customer Responsibility Matrix (CRM), comes in.</p>\n<p>When you adopt GitLab Dedicated for Government, you will receive a comprehensive SRM that clearly delineates which security controls are managed by GitLab and which are your responsibility as the customer. Your CMMC C3PAO will use this document to ensure you have implemented the necessary controls on your end. By leveraging GitLab's FedRAMP-authorized platform, you can confidently address your CMMC Level 2 compliance requirements, focusing on your mission while trusting that GitLab has you covered.</p>\n<blockquote>\n<p>To learn more about GitLab Dedicated for Government, visit our <a href=\"https://about.gitlab.com/solutions/public-sector/\">GitLab for Public Sector</a> page. Interested in a demo? Contact Sales for more information at <a href=\"mailto:sales-pubsec@gitlab.com\">sales-pubsec@gitlab.com</a>.</p>\n</blockquote>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://www.federalregister.gov/documents/2025/09/10/2025-17359/defense-federal-acquisition-regulation-supplement-assessing-contractor-implementation-of\">CMMC “Final Rule” DFARS Supplement</a></li>\n<li><a href=\"https://dodcio.defense.gov/Portals/0/Documents/Library/FEDRAMP-EquivalencyCloudServiceProviders.pdf\">DOD-CIO “FedRAMP Moderate Equivalency” Memo</a></li>\n<li><a href=\"https://marketplace.fedramp.gov/products/FR2411959145\">GitLab Dedicated for Government FedRAMP Marketplace Listing</a></li>\n</ul>\n",
      "summary": "For Defense Industrial Base (DIB) companies, the U.S. Department of Defense's release of the Cybersecurity Maturity Model Certification (CMMC) Final Rule and new guidance on “FedRAMP equivalency” has dramatically increased the cost of compliance and fundamentally changed the way in which they drive their risk management programs. Gone is the era of “self-attestation” of security programs; DIB companies are required to strictly apply NIST 800-171 to their environments that handle Controlled Unclassified Information (CUI), and have their security controls audited by a Third-Party Assessment Organization (3PAO) every three years.\nDIB companies are engineering focused, not compliance driven, and formal audits get pricey quickly. These changes add significant complications for companies focused on supporting the warfighter. The good news? GitLab Dedicated for Government's FedRAMP Moderate Authorization means DIB companies can directly use GitLab Dedicated for Government with no additional audits or authorizations, which reduces the impact and cost of compliance.\nThe foundational rule: FedRAMP Moderate Equivalency\nThe protection of Controlled Unclassified Information (CUI) within the DIB is driven by a foundational legal and contractual mandate: the Defense Federal Acquisition Regulation Supplement (DFARS) Clause 252.204-7012. This clause specifically states that if a contractor uses an external cloud service provider to \"store, process, or transmit any covered defense information,\" that provider must meet security requirements \"equivalent to those established by the Government for the FedRAMP Moderate baseline.\"\nThe DOD's January 2, 2024, memorandum, \"Federal Risk and Authorization Management Program (FedRAMP) Moderate Equivalency for Cloud Service Provider's (CSPs) Cloud Service Offerings\" defines “FedRAMP Moderate Equivalency,” and also directly specifies that FedRAMP Moderate Cloud Service Offerings (CSOs) can be used without any additional assessment, such as individual CMMC assessment, to meet equivalency requirements:\n“This memorandum does not apply to CSOs that are FedRAMP Moderate Authorized under the existing FedRAMP process. FedRAMP Moderate Authorized CSOs identified in the FedRAMP Marketplace provide the required security to store, process or transmit CDI in accordance with Defense Federal Acquisition Regulations Supplement (DFARS) Clause 252.204-7012, \"Safeguarding Covered Defense Information and Cyber Incident Reporting\" and can be leveraged without further assessment to meet the equivalency requirements.”\nThe GitLab platform: A proven path to compliance\nGitLab's GovCloud Offering, GitLab Dedicated for Government, has achieved FedRAMP Moderate Authorization. This means that DIB companies can leverage GitLab Dedicated for Government as their DevSecOps platform immediately and without any additional audits or compliance checks. DIB companies leveraging GitLab Dedicated for Government inherit all of our security controls and our Body of Evidence, shifting the risk and cost of compliance away from themselves and allowing them to focus on their mission.\nThe Shared Responsibility Matrix: Your role as a DIB contractor\nWhile a FedRAMP-authorized solution significantly reduces your compliance burden, compliance is a joint effort. You are responsible for the security controls that fall under your purview. This is where the Shared Responsibility Matrix (SRM), also called the Customer Responsibility Matrix (CRM), comes in.\nWhen you adopt GitLab Dedicated for Government, you will receive a comprehensive SRM that clearly delineates which security controls are managed by GitLab and which are your responsibility as the customer. Your CMMC C3PAO will use this document to ensure you have implemented the necessary controls on your end. By leveraging GitLab's FedRAMP-authorized platform, you can confidently address your CMMC Level 2 compliance requirements, focusing on your mission while trusting that GitLab has you covered.\nTo learn more about GitLab Dedicated for Government, visit our GitLab for Public Sector page. Interested in a demo? Contact Sales for more information at sales-pubsec@gitlab.com.\nReferences\nCMMC “Final Rule” DFARS Supplement\nDOD-CIO “FedRAMP Moderate Equivalency” Memo\nGitLab Dedicated for Government FedRAMP Marketplace Listing",
      "publishedAt": "2025-11-12T00:00:00.000Z",
      "author": "Drew Wilmoth",
      "source": "rss",
      "feedName": "GitLab Engineering",
      "ingestedAt": "2025-11-21T02:45:17.559Z"
    },
    {
      "id": "fb31a67a2b8db1c5c327d58bb2b8e97e",
      "title": "Secure AI agent deployment to GKE",
      "url": "https://about.gitlab.com/blog/secure-ai-agent-deployment-to-gke/",
      "content": "<p>Building <a href=\"https://about.gitlab.com/gitlab-duo/agent-platform/\">AI agents</a> is</p>\n<p>exciting, but deploying them securely to production shouldn't be</p>\n<p>complicated. In this tutorial, you will learn how GitLab's <a href=\"https://cloud.google.com/blog/topics/partners/understand-the-google-cloud-gitlab-integration\">native Google Cloud integration</a> makes it straightforward to deploy AI agents to Google Kubernetes Engine (GKE) — with built-in scanning and zero service account keys.</p>\n<h2>Why choose GKE to deploy your AI agents?</h2>\n<p>GKE provides enterprise-grade orchestration that connects seamlessly with GitLab CI/CD pipelines through OIDC authentication. Your development team can deploy AI agents while maintaining complete visibility, compliance, and control over your cloud infrastructure. This guide uses Google's Agent Development Kit (<a href=\"https://developers.googleblog.com/en/agent-development-kit-easy-to-build-multi-agent-applications/\">ADK</a>) to build the app, so you can expect increased seamlessness as this is deployed using GitLab.</p>\n<p>Three key advantages to this approach:</p>\n<p><strong>Full infrastructure control</strong> - Your data, your rules, your environment. You maintain complete control over where your AI agents run and how they're configured.</p>\n<p><strong>Native GitLab integration</strong> - No complex workarounds. Your existing pipelines work right out of the box thanks to GitLab's native integration with Google Cloud.</p>\n<p><strong>Production-grade scaling</strong> - GKE automatically handles the heavy lifting of scaling and internal orchestration as your AI workloads grow.</p>\n<p>The key point is that GitLab with GKE provides the enterprise reliability your AI deployments demand without sacrificing the developer experience your teams expect.</p>\n<h2>Prerequisites</h2>\n<p>Before you start, make sure you have these APIs enabled:</p>\n<ul>\n<li>\n<p>GKE API</p>\n</li>\n<li>\n<p>Artifact Registry API</p>\n</li>\n<li>\n<p>Vertex AI API</p>\n</li>\n</ul>\n<p>Also make sure you have:</p>\n<ul>\n<li>\n<p>GitLab project created</p>\n</li>\n<li>\n<p>GKE cluster provisioned</p>\n</li>\n<li>\n<p>Artifact Registry repository created</p>\n</li>\n</ul>\n<h2>The deployment process</h2>\n<h3>1. Set up IAM and permissions on GitLab</h3>\n<p>Navigate to your GitLab integrations to configure Google Cloud authentication (IAM).</p>\n<p>Go to <strong>Settings &gt; Integrations</strong> and configure the Google Cloud integration. If you're using a group-level integration, notice that default settings are already inherited by projects. This means you configure once at the group level, and all projects benefit and inherit this setting.</p>\n<p>To set this up from scratch, provide:</p>\n<ul>\n<li>\n<p>Project ID</p>\n</li>\n<li>\n<p>Project Number</p>\n</li>\n<li>\n<p>Workload Identity Pool ID</p>\n</li>\n<li>\n<p>Provider ID</p>\n</li>\n</ul>\n<p>Once configured, GitLab provides a script to run in Google Cloud Console, via Cloud Shell. The outcome of running this script is a Workload Identity Federation pool with the necessary service principal to enable the proper access.</p>\n<h3>2. Configure Artifact Registry integration</h3>\n<p>Still in GitLab's integration settings, configure Artifact Management:</p>\n<ol>\n<li>\n<p>Click <strong>Artifact Management</strong>.</p>\n</li>\n<li>\n<p>Select <strong>Google Artifact Registry</strong>.</p>\n</li>\n<li>\n<p>Provide:</p>\n<ul>\n<li>Project ID</li>\n<li>Repository Name (created beforehand)</li>\n<li>Repository Location</li>\n</ul>\n</li>\n</ol>\n<p>GitLab provides another script to run in Google Cloud Console.</p>\n<p><strong>Important:</strong> Before proceeding, add these extra roles to the Workload Identity Federation pool:</p>\n<ul>\n<li>\n<p>Service Account User</p>\n</li>\n<li>\n<p>Kubernetes Developer</p>\n</li>\n<li>\n<p>Kubernetes Cluster Viewer</p>\n</li>\n</ul>\n<p>These permissions allow GitLab to deploy to GKE in subsequent steps.</p>\n<h3>3. Create the CI/CD pipeline</h3>\n<p>Now for the key part — creating the CI/CD pipeline for deployment.</p>\n<p>Head to <strong>Build &gt; Pipeline Editor</strong> and define your pipeline with four stages:</p>\n<ul>\n<li>\n<p><strong>Build</strong> - Docker creates the container image.</p>\n</li>\n<li>\n<p><strong>Test</strong> - GitLab Auto DevOps provides built-in security scans to ensure there are no vulnerabilities.</p>\n</li>\n<li>\n<p><strong>Upload</strong> - Uses GitLab's built-in CI/CD component to push to Google Artifact Registry.</p>\n</li>\n<li>\n<p><strong>Deploy</strong> - Uses Kubernetes configuration to deploy to GKE.</p>\n</li>\n</ul>\n<p>Here's the complete <code>.gitlab-ci.yml</code>:</p>\n<pre><code class=\"language-yaml\">\n\ndefault:\n  tags: [ saas-linux-2xlarge-amd64 ]\n\nstages:\n  - build\n  - test\n  - upload\n  - deploy\n\nvariables:\n  GITLAB_IMAGE: $CI_REGISTRY_IMAGE/main:$CI_COMMIT_SHORT_SHA\n  AR_IMAGE: $GOOGLE_ARTIFACT_REGISTRY_REPOSITORY_LOCATION-docker.pkg.dev/$GOOGLE_ARTIFACT_REGISTRY_PROJECT_ID/$GOOGLE_ARTIFACT_REGISTRY_REPOSITORY_NAME/main:$CI_COMMIT_SHORT_SHA\n  GCP_PROJECT_ID: &quot;your-project-id&quot;\n  GKE_CLUSTER: &quot;your-cluster&quot;\n  GKE_REGION: &quot;us-central1&quot;\n  KSA_NAME: &quot;ai-agent-ksa&quot;\n\nbuild:\n  image: docker:24.0.5\n  stage: build\n  services:\n    - docker:24.0.5-dind\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  script:\n    - docker build -t $GITLAB_IMAGE .\n    - docker push $GITLAB_IMAGE\n\ninclude:\n  - template: Jobs/Dependency-Scanning.gitlab-ci.yml\n  - template: Jobs/Container-Scanning.gitlab-ci.yml\n  - template: Jobs/Secret-Detection.gitlab-ci.yml\n  - component: gitlab.com/google-gitlab-components/artifact-registry/upload-artifact-registry@main\n    inputs:\n      stage: upload\n      source: $GITLAB_IMAGE\n      target: $AR_IMAGE\n\ndeploy:\n  stage: deploy\n  image: google/cloud-sdk:slim\n  identity: google_cloud\n  before_script:\n    - apt-get update &amp;&amp; apt-get install -y kubectl google-cloud-sdk-gke-gcloud-auth-plugin\n    - gcloud container clusters get-credentials $GKE_CLUSTER --region $GKE_REGION --project $GCP_PROJECT_ID\n  script:\n    - |\n      kubectl apply -f - &lt;&lt;EOF\n      apiVersion: apps/v1\n      kind: Deployment\n      metadata:\n        name: ai-agent\n        namespace: default\n      spec:\n        replicas: 2\n        selector:\n          matchLabels:\n            app: ai-agent\n        template:\n          metadata:\n            labels:\n              app: ai-agent\n          spec:\n            serviceAccountName: $KSA_NAME\n            containers:\n            - name: ai-agent\n              image: $AR_IMAGE\n              ports:\n              - containerPort: 8080\n              resources:\n                requests: {cpu: 500m, memory: 1Gi}\n                limits: {cpu: 2000m, memory: 4Gi}\n              livenessProbe:\n                httpGet: {path: /health, port: 8080}\n                initialDelaySeconds: 60\n              readinessProbe:\n                httpGet: {path: /health, port: 8080}\n                initialDelaySeconds: 30\n      ---\n      apiVersion: v1\n      kind: Service\n      metadata:\n        name: ai-agent-service\n        namespace: default\n      spec:\n        type: LoadBalancer\n        ports:\n        - port: 80\n          targetPort: 8080\n        selector:\n          app: ai-agent\n      ---\n      apiVersion: autoscaling/v2\n      kind: HorizontalPodAutoscaler\n      metadata:\n        name: ai-agent-hpa\n        namespace: default\n      spec:\n        scaleTargetRef:\n          apiVersion: apps/v1\n          kind: Deployment\n          name: ai-agent\n        minReplicas: 2\n        maxReplicas: 10\n        metrics:\n        - type: Resource\n          resource:\n            name: cpu\n            target: {type: Utilization, averageUtilization: 70}\n      EOF\n      \n      kubectl rollout status deployment/ai-agent -n default --timeout=5m\n      EXTERNAL_IP=$(kubectl get service ai-agent-service -n default -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n      echo &quot;Deployed at: http://$EXTERNAL_IP&quot;\n  only:\n    - main\n</code></pre>\n<h4>The critical configuration for GKE</h4>\n<p>What makes this work — and why we need this extra configuration for GKE— is that we must have a Kubernetes Service Account in the cluster that can work with Vertex AI. We need that service account to be permitted to access the AI capabilities of Google Cloud.</p>\n<p>Without this, we can deploy the application, but the AI agent won't work. We need to create a Kubernetes Service Account that can access Vertex AI.</p>\n<p>Run this one-time setup:</p>\n<pre><code class=\"language-bash\">\n\n#!/bin/bash\n\n\nPROJECT_ID=&quot;your-project-id&quot;\n\n\nGSA_NAME=&quot;ai-agent-vertex&quot;\n\n\nGSA_EMAIL=&quot;${GSA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com&quot;\n\n\nKSA_NAME=&quot;ai-agent-ksa&quot;\n\n\nCLUSTER_NAME=&quot;your-cluster&quot;\n\n\nREGION=&quot;us-central1&quot;\n\n\n\n# Create GCP Service Account\n\n\ngcloud iam service-accounts create $GSA_NAME \\\n    --display-name=&quot;AI Agent Vertex AI&quot; \\\n    --project=$PROJECT_ID\n\n# Grant Vertex AI permissions\n\n\ngcloud projects add-iam-policy-binding $PROJECT_ID \\\n    --member=&quot;serviceAccount:${GSA_EMAIL}&quot; \\\n    --role=&quot;roles/aiplatform.user&quot;\n\n# Get cluster credentials\n\n\ngcloud container clusters get-credentials $CLUSTER_NAME \\\n    --region $REGION --project $PROJECT_ID\n\n# Create Kubernetes Service Account\n\n\nkubectl create serviceaccount $KSA_NAME -n default\n\n\n\n# Link accounts\n\n\nkubectl annotate serviceaccount $KSA_NAME -n default \\\n    iam.gke.io/gcp-service-account=${GSA_EMAIL}\n\ngcloud iam service-accounts add-iam-policy-binding ${GSA_EMAIL} \\\n    --role=roles/iam.workloadIdentityUser \\\n    --member=&quot;serviceAccount:${PROJECT_ID}.svc.id.goog[default/${KSA_NAME}]&quot; \\\n    --project=$PROJECT_ID\n</code></pre>\n<h3>4. Deploy to GKE</h3>\n<p>Once you're done, push this change to the pipeline and you're good to go.</p>\n<p>You can see the pipeline has just deployed. Go to <strong>CI/CD &gt; Pipelines</strong> and you'll see the four stages:</p>\n<ul>\n<li>\n<p>Build</p>\n</li>\n<li>\n<p>Test (with all defined security scans)</p>\n</li>\n<li>\n<p>Upload to Artifact Registry (successful)</p>\n</li>\n<li>\n<p>Deploy to Kubernetes in GKE (success)</p>\n</li>\n</ul>\n<h2>Summary</h2>\n<p>With GitLab and Google Cloud together, you're able to deploy your AI agent to GKE with ease and security. We didn't have to go through a lot of steps — we were able to do that thanks to GitLab's native integration with Google Cloud.</p>\n<p>Watch this demo:</p>\n<p>&lt;!-- blank line --&gt;</p>\n<p>&lt;figure class=&quot;video_container&quot;&gt;\n&lt;iframe src=&quot;https://www.youtube.com/embed/mc2pCL5Qjus?si=QoH02lvz5KH5Ku9O&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt; &lt;/iframe&gt;\n&lt;/figure&gt;</p>\n<p>&lt;!-- blank line --&gt;</p>\n<blockquote>\n<p>Use this tutorial's <a href=\"https://gitlab.com/gitlab-partners-public/google-cloud/demos/gke-ai-agent\">complete code example</a> to get started now. Not a GitLab customer yet? Explore the DevSecOps platform with <a href=\"https://about.gitlab.com/free-trial/\">a free trial</a>. Startups hosted on Google Cloud have a <a href=\"https://about.gitlab.com/solutions/startups/google-cloud/\">special perk to try and use GitLab</a>.</p>\n</blockquote>\n",
      "summary": "Building AI agents is\nexciting, but deploying them securely to production shouldn't be\ncomplicated. In this tutorial, you will learn how GitLab's native Google Cloud integration makes it straightforward to deploy AI agents to Google Kubernetes Engine (GKE) — with built-in scanning and zero service account keys.\nWhy choose GKE to deploy your AI agents?\nGKE provides enterprise-grade orchestration that connects seamlessly with GitLab CI/CD pipelines through OIDC authentication. Your development team can deploy AI agents while maintaining complete visibility, compliance, and control over your cloud infrastructure. This guide uses Google's Agent Development Kit (ADK) to build the app, so you can expect increased seamlessness as this is deployed using GitLab.\nThree key advantages to this approach:\nFull infrastructure control - Your data, your rules, your environment. You maintain complete control over where your AI agents run and how they're configured.\nNative GitLab integration - No complex workarounds. Your existing pipelines work right out of the box thanks to GitLab's native integration with Google Cloud.\nProduction-grade scaling - GKE automatically handles the heavy lifting of scaling and internal orchestration as your AI workloads grow.\nThe key point is that GitLab with GKE provides the enterprise reliability your AI deployments demand without sacrificing the developer experience your teams expect.\nPrerequisites\nBefore you start, make sure you have these APIs enabled:\nGKE API\nArtifact Registry API\nVertex AI API\nAlso make sure you have:\nGitLab project created\nGKE cluster provisioned\nArtifact Registry repository created\nThe deployment process\n1. Set up IAM and permissions on GitLab\nNavigate to your GitLab integrations to configure Google Cloud authentication (IAM).\nGo to Settings > Integrations and configure the Google Cloud integration. If you're using a group-level integration, notice that default settings are already inherited by projects. This means you configure once at the group level, and all projects benefit and inherit this setting.\nTo set this up from scratch, provide:\nProject ID\nProject Number\nWorkload Identity Pool ID\nProvider ID\nOnce configured, GitLab provides a script to run in Google Cloud Console, via Cloud Shell. The outcome of running this script is a Workload Identity Federation pool with the necessary service principal to enable the proper access.\n2. Configure Artifact Registry integration\nStill in GitLab's integration settings, configure Artifact Management:\nClick Artifact Management.\nSelect Google Artifact Registry.\nProvide:\nProject ID\nRepository Name (created beforehand)\nRepository Location\nGitLab provides another script to run in Google Cloud Console.\nImportant: Before proceeding, add these extra roles to the Workload Identity Federation pool:\nService Account User\nKubernetes Developer\nKubernetes Cluster Viewer\nThese permissions allow GitLab to deploy to GKE in subsequent steps.\n3. Create the CI/CD pipeline\nNow for the key part — creating the CI/CD pipeline for deployment.\nHead to Build > Pipeline Editor and define your pipeline with four stages:\nBuild - Docker creates the container image.\nTest - GitLab Auto DevOps provides built-in security scans to ensure there are no vulnerabilities.\nUpload - Uses GitLab's built-in CI/CD component to push to Google Artifact Registry.\nDeploy - Uses Kubernetes configuration to deploy to GKE.\nHere's the complete .gitlab-ci.yml:\n\n\ndefault:\n  tags: [ saas-linux-2xlarge-amd64 ]\n\nstages:\n  - build\n  - test\n  - upload\n  - deploy\n\nvariables:\n  GITLAB_IMAGE: $CI_REGISTRY_IMAGE/main:$CI_COMMIT_SHORT_SHA\n  AR_IMAGE: $GOOGLE_ARTIFACT_REGISTRY_REPOSITORY_LOCATION-docker.pkg.dev/$GOOGLE_ARTIFACT_REGISTRY_PROJECT_ID/$GOOGLE_ARTIFACT_REGISTRY_REPOSITORY_NAME/main:$CI_COMMIT_SHORT_SHA\n  GCP_PROJECT_ID: \"your-project-id\"\n  GKE_CLUSTER: \"your-cluster\"\n  GKE_REGION: \"us-central1\"\n  KSA_NAME: \"ai-agent-ksa\"\n\nbuild:\n  image: docker:24.0.5\n  stage: build\n  services:\n    - docker:24.0.5-dind\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  script:\n    - docker build -t $GITLAB_IMAGE .\n    - docker push $GITLAB_IMAGE\n\ninclude:\n  - template: Jobs/Dependency-Scanning.gitlab-ci.yml\n  - template: Jobs/Container-Scanning.gitlab-ci.yml\n  - template: Jobs/Secret-Detection.gitlab-ci.yml\n  - component: gitlab.com/google-gitlab-components/artifact-registry/upload-artifact-registry@main\n    inputs:\n      stage: upload\n      source: $GITLAB_IMAGE\n      target: $AR_IMAGE\n\ndeploy:\n  stage: deploy\n  image: google/cloud-sdk:slim\n  identity: google_cloud\n  before_script:\n    - apt-get update && apt-get install -y kubectl google-cloud-sdk-gke-gcloud-auth-plugin\n    - gcloud container clusters get-credentials $GKE_CLUSTER --region $GKE_REGION --project $GCP_PROJECT_ID\n  script:\n    - |\n      kubectl apply -f - <<EOF\n      apiVersion: apps/v1\n      kind: Deployment\n      metadata:\n        name: ai-agent\n        namespace: default\n      spec:\n        replicas: 2\n        selector:\n          matchLabels:\n            app: ai-agent\n        template:\n          metadata:\n            labels:\n              app: ai-agent\n          spec:\n            serviceAccountName: $KSA_NAME\n            containers:\n            - name: ai-agent\n              image: $AR_IMAGE\n              ports:\n              - containerPort: 8080\n              resources:\n                requests: {cpu: 500m, memory: 1Gi}\n                limits: {cpu: 2000m, memory: 4Gi}\n              livenessProbe:\n                httpGet: {path: /health, port: 8080}\n                initialDelaySeconds: 60\n              readinessProbe:\n                httpGet: {path: /health, port: 8080}\n                initialDelaySeconds: 30\n      ---\n      apiVersion: v1\n      kind: Service\n      metadata:\n        name: ai-agent-service\n        namespace: default\n      spec:\n        type: LoadBalancer\n        ports:\n        - port: 80\n          targetPort: 8080\n        selector:\n          app: ai-agent\n      ---\n      apiVersion: autoscaling/v2\n      kind: HorizontalPodAutoscaler\n      metadata:\n        name: ai-agent-hpa\n        namespace: default\n      spec:\n        scaleTargetRef:\n          apiVersion: apps/v1\n          kind: Deployment\n          name: ai-agent\n        minReplicas: 2\n        maxReplicas: 10\n        metrics:\n        - type: Resource\n          resource:\n            name: cpu\n            target: {type: Utilization, averageUtilization: 70}\n      EOF\n      \n      kubectl rollout status deployment/ai-agent -n default --timeout=5m\n      EXTERNAL_IP=$(kubectl get service ai-agent-service -n default -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n      echo \"Deployed at: http://$EXTERNAL_IP\"\n  only:\n    - main\n\nThe critical configuration for GKE\nWhat makes this work — and why we need this extra configuration for GKE— is that we must have a Kubernetes Service Account in the cluster that can work with Vertex AI. We need that service account to be permitted to access the AI capabilities of Google Cloud.\nWithout this, we can deploy the application, but the AI agent won't work. We need to create a Kubernetes Service Account that can access Vertex AI.\nRun this one-time setup:\n\n\n#!/bin/bash\n\n\nPROJECT_ID=\"your-project-id\"\n\n\nGSA_NAME=\"ai-agent-vertex\"\n\n\nGSA_EMAIL=\"${GSA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com\"\n\n\nKSA_NAME=\"ai-agent-ksa\"\n\n\nCLUSTER_NAME=\"your-cluster\"\n\n\nREGION=\"us-central1\"\n\n\n\n# Create GCP Service Account\n\n\ngcloud iam service-accounts create $GSA_NAME \\\n    --display-name=\"AI Agent Vertex AI\" \\\n    --project=$PROJECT_ID\n\n# Grant Vertex AI permissions\n\n\ngcloud projects add-iam-policy-binding $PROJECT_ID \\\n    --member=\"serviceAccount:${GSA_EMAIL}\" \\\n    --role=\"roles/aiplatform.user\"\n\n# Get cluster credentials\n\n\ngcloud container clusters get-credentials $CLUSTER_NAME \\\n    --region $REGION --project $PROJECT_ID\n\n# Create Kubernetes Service Account\n\n\nkubectl create serviceaccount $KSA_NAME -n default\n\n\n\n# Link accounts\n\n\nkubectl annotate serviceaccount $KSA_NAME -n default \\\n    iam.gke.io/gcp-service-account=${GSA_EMAIL}\n\ngcloud iam service-accounts add-iam-policy-binding ${GSA_EMAIL} \\\n    --role=roles/iam.workloadIdentityUser \\\n    --member=\"serviceAccount:${PROJECT_ID}.svc.id.goog[default/${KSA_NAME}]\" \\\n    --project=$PROJECT_ID\n\n4. Deploy to GKE\nOnce you're done, push this change to the pipeline and you're good to go.\nYou can see the pipeline has just deployed. Go to CI/CD > Pipelines and you'll see the four stages:\nBuild\nTest (with all defined security scans)\nUpload to Artifact Registry (successful)\nDeploy to Kubernetes in GKE (success)\nSummary\nWith GitLab and Google Cloud together, you're able to deploy your AI agent to GKE with ease and security. We didn't have to go through a lot of steps — we were able to do that thanks to GitLab's native integration with Google Cloud.\nWatch this demo:\n<!-- blank line -->\n<figure class=\"video_container\">\n<iframe src=\"https://www.youtube.com/embed/mc2pCL5Qjus?si=QoH02lvz5KH5Ku9O\" frameborder=\"0\" allowfullscreen=\"true\"> </iframe>\n</figure>\n<!-- blank line -->\nUse this tutorial's complete code example to get started now. Not a GitLab customer yet? Explore the DevSecOps platform with a free trial. Startups hosted on Google Cloud have a special perk to try and use GitLab.",
      "publishedAt": "2025-11-10T00:00:00.000Z",
      "author": "Regnard Raquedan",
      "source": "rss",
      "feedName": "GitLab Engineering",
      "ingestedAt": "2025-11-21T02:45:17.559Z"
    },
    {
      "id": "0182663030237ca91d898d4b555ce5e6",
      "title": "Migrate from pipeline variables to pipeline inputs for better security",
      "url": "https://about.gitlab.com/blog/migrate-from-pipeline-variables-to-pipeline-inputs-for-better-security/",
      "content": "<p><a href=\"https://docs.gitlab.com/ci/variables/#use-pipeline-variables\">Pipeline\nvariables</a>\nhave long been a convenient way to customize GitLab CI/CD pipelines at\nruntime. However, as CI/CD security best practices have evolved, we've\nrecognized the need for stronger controls around pipeline customization.\nUnrestricted pipeline variables allow any users with pipeline trigger\npermissions to override values without validation or type checking.</p>\n<p>Beyond security considerations, pipeline variables lack proper documentation and explicit declaration, making it difficult to understand what inputs are expected and how they're used throughout your pipeline. This can lead to maintenance challenges and make it harder to establish proper governance over your <a href=\"https://about.gitlab.com/topics/ci-cd/\">CI/CD</a> processes.</p>\n<h2>Enter pipeline inputs</h2>\n<p>Instead of relying on pipeline variables, we strongly recommend using GitLab's <a href=\"https://docs.gitlab.com/ci/inputs/#for-a-pipeline\">pipeline inputs</a> feature. Pipeline inputs provide:</p>\n<ul>\n<li>\n<p><strong>Explicit declaration</strong>: Inputs must be explicitly declared in your <code>.gitlab-ci.yml</code> and are self-documented.</p>\n</li>\n<li>\n<p><strong>Type safety</strong>: Support for different input types (string, boolean, number, array)</p>\n</li>\n<li>\n<p><strong>Built-in validation</strong>: Automatic validation of input values</p>\n</li>\n<li>\n<p><strong>Better security</strong>: No risk of variable injection attacks — only the declared inputs can be passed from the outside</p>\n</li>\n</ul>\n<h3>Basic example</h3>\n<pre><code>\nspec:\n  inputs:\n    deployment_env:\n      description: &quot;Target deployment environment&quot;\n      type: string\n      options: [&quot;staging&quot;, &quot;production&quot;]\n      default: &quot;staging&quot;\n    enable_tests:\n      description: &quot;Run test suite&quot;\n      type: boolean\n      default: true\n\ntest:\n  script:\n    - echo &quot;Running tests&quot;\n  rules:\n    - if: $[[ inputs.enable_tests ]] == true\n\ndeploy:\n  script:\n    - echo &quot;Deploying to $[[ inputs.deployment_env ]]&quot;\n</code></pre>\n<p>Learn more about how CI/CD inputs provide type-safe parameter passing with validation in this <a href=\"https://about.gitlab.com/blog/ci-cd-inputs-secure-and-preferred-method-to-pass-parameters-to-a-pipeline/\">tutorial</a>.</p>\n<h2>Restrict pipeline variables</h2>\n<p>To effectively move to pipeline inputs and away from pipeline variables, you should configure the <a href=\"https://docs.gitlab.com/ci/variables/#restrict-pipeline-variables\">&quot;Minimum role to use pipeline variables&quot;</a> setting. This setting provides fine-grained control over which role can use pipeline variables when triggering pipelines.</p>\n<p><strong>At the project level:</strong> Navigate to your project's <strong>Settings &gt; CI/CD &gt; Variables &gt; Minimum role to use pipeline variables</strong> to configure the setting.</p>\n<p>Available options are:</p>\n<ul>\n<li>\n<p><strong>No one allowed</strong> (<code>no_one_allowed</code>) - Recommended and most secure option. Prevents all variable overrides.</p>\n</li>\n<li>\n<p><strong>Developer</strong> (<code>developer</code>) - Allows developers and above to override variables</p>\n</li>\n<li>\n<p><strong>Maintainer</strong> (<code>maintainer</code>) - Requires maintainer role or higher</p>\n</li>\n<li>\n<p><strong>Owner</strong> (<code>owner</code>) - Only project owners can override variables</p>\n</li>\n</ul>\n<p><strong>At the group level:</strong> Group maintainers can go to <strong>Settings &gt; CI/CD &gt; Variables &gt; Default role to use pipeline variables</strong> to establish secure defaults for all new projects within their group, ensuring consistent security policies across your organization. Here we recommend again to use <strong>No one allowed</strong> as default value — this way, new projects in this group are created with a secure default setting. Note that this still allows project owners to change the setting.</p>\n<p>When pipeline variables are restricted completely (with “No one allowed”), the <a href=\"https://docs.gitlab.com/ci/pipelines/#prefill-variables-in-manual-pipelines\">prefilled variables</a> won’t appear in the &quot;New Pipeline UI&quot; form.</p>\n<h2>How to migrate from pipeline variables</h2>\n<h3>Close the gaps</h3>\n<p>Your group may have projects that have pipeline variables enabled by default despite never having used them when triggering a pipeline. These projects can be migrated to the more secure setting without a risk of interruption. GitLab <a href=\"https://docs.gitlab.com/ci/variables/#enable-pipeline-variable-restriction-for-multiple-projects\">provides migration functionality</a> via group settings:</p>\n<ul>\n<li>\n<p>Go to <strong>Settings &gt; CI/CD &gt; Variables</strong></p>\n</li>\n<li>\n<p>In <strong>Disable pipeline variables in projects that don’t use them,</strong> select <strong>Start migration</strong>.</p>\n</li>\n</ul>\n<p>This migration is a background job that safely disables pipeline variables via project settings for all projects that historically have not used them.</p>\n<h3>Convert pipeline variables to inputs</h3>\n<p>For each identified pipeline variable, create a corresponding pipeline input.</p>\n<p><strong>Before (using pipeline variables)</strong></p>\n<pre><code>\nvariables:\n  DEPLOY_ENV:\n    description: &quot;Deployment environment&quot;\n    value: &quot;staging&quot;\n  ENABLE_CACHE:\n    description: &quot;Enable deployment cache&quot;\n    value: &quot;true&quot;\n  VERSION:\n    description: &quot;Application version&quot;\n    value: &quot;1.0.0&quot;\n\ndeploy:\n  script:\n    - echo &quot;Deploying version $VERSION to $DEPLOY_ENV&quot;\n    - |\n      if [ &quot;$ENABLE_CACHE&quot; = &quot;true&quot; ]; then\n        echo &quot;Cache enabled&quot;\n      fi\n</code></pre>\n<p><strong>After (using pipeline inputs)</strong></p>\n<pre><code>\nspec:\n  inputs:\n    deploy_env:\n      description: &quot;Deployment environment&quot;\n      type: string\n      default: &quot;staging&quot;\n      options: [&quot;dev&quot;, &quot;staging&quot;, &quot;production&quot;]\n\n    enable_cache:\n      description: &quot;Enable deployment cache&quot;\n      type: boolean\n      default: true\n    \n    version:\n      description: &quot;Application version&quot;\n      type: string\n      default: &quot;1.0.0&quot;\n      regex: '^[0-9]+\\.[0-9]+\\.[0-9]+$'\n\ndeploy:\n  script:\n    - echo &quot;Deploying version $[[ inputs.version ]] to $[[ inputs.deploy_env ]]&quot;\n    - |\n      if [ &quot;$[[ inputs.enable_cache ]]&quot; = &quot;true&quot; ]; then\n        echo &quot;Cache enabled&quot;\n      fi\n</code></pre>\n<h3>Migrate trigger jobs</h3>\n<p>If you use trigger jobs with the <code>trigger</code> keyword, ensure they don't define job-level <code>variables</code> or disable inheriting variables from top-level <code>variables</code>, <code>extends</code>, or <code>include</code>, because variables could implicitly be passed downstream as pipeline variables. If pipeline variables are restricted on the downstream project, pipeline creation will fail.</p>\n<p>Consider updating your CI configuration to use pipeline inputs instead of pipeline variables.</p>\n<pre><code>\nvariables:\n  FOO: bar\n\ndeploy-staging:\n  inherit:\n    variables: false # otherwise FOO would be sent downstream as a pipeline variable\n  trigger:\n    project: myorg/deployer\n    inputs:\n      deployment_env: staging\n      enable_tests: true\n</code></pre>\n<h2>Summary</h2>\n<p>Migrating from pipeline variables to pipeline inputs is a security enhancement that protects your CI/CD infrastructure from variable injection while providing better documentation, type safety, and validation. By implementing these restrictions and adopting pipeline inputs, you're not just improving security, you're also making your pipelines more maintainable, self-documenting, and resilient.</p>\n<p>The transition requires some initial effort, but the long-term benefits far outweigh the migration costs. Start by restricting pipeline variables at the group level for new projects, then systematically migrate existing pipelines using the step-by-step approach outlined above.</p>\n<p>Security is not a destination but a journey. Pipeline inputs are one important step in creating a more secure CI/CD environment, complementing other GitLab security features like protected branches, job token allowlists, and container registry protections.</p>\n<blockquote>\n<p>To get started with pipeline inputs, <a href=\"https://about.gitlab.com/free-trial/devsecops/\">sign up for a free trial of GitLab Ultimate today</a>.</p>\n</blockquote>\n",
      "summary": "Pipeline\nvariables\nhave long been a convenient way to customize GitLab CI/CD pipelines at\nruntime. However, as CI/CD security best practices have evolved, we've\nrecognized the need for stronger controls around pipeline customization.\nUnrestricted pipeline variables allow any users with pipeline trigger\npermissions to override values without validation or type checking.\nBeyond security considerations, pipeline variables lack proper documentation and explicit declaration, making it difficult to understand what inputs are expected and how they're used throughout your pipeline. This can lead to maintenance challenges and make it harder to establish proper governance over your CI/CD processes.\nEnter pipeline inputs\nInstead of relying on pipeline variables, we strongly recommend using GitLab's pipeline inputs feature. Pipeline inputs provide:\nExplicit declaration: Inputs must be explicitly declared in your .gitlab-ci.yml and are self-documented.\nType safety: Support for different input types (string, boolean, number, array)\nBuilt-in validation: Automatic validation of input values\nBetter security: No risk of variable injection attacks — only the declared inputs can be passed from the outside\nBasic example\n\nspec:\n  inputs:\n    deployment_env:\n      description: \"Target deployment environment\"\n      type: string\n      options: [\"staging\", \"production\"]\n      default: \"staging\"\n    enable_tests:\n      description: \"Run test suite\"\n      type: boolean\n      default: true\n\ntest:\n  script:\n    - echo \"Running tests\"\n  rules:\n    - if: $[[ inputs.enable_tests ]] == true\n\ndeploy:\n  script:\n    - echo \"Deploying to $[[ inputs.deployment_env ]]\"\n\nLearn more about how CI/CD inputs provide type-safe parameter passing with validation in this tutorial.\nRestrict pipeline variables\nTo effectively move to pipeline inputs and away from pipeline variables, you should configure the \"Minimum role to use pipeline variables\" setting. This setting provides fine-grained control over which role can use pipeline variables when triggering pipelines.\nAt the project level: Navigate to your project's Settings > CI/CD > Variables > Minimum role to use pipeline variables to configure the setting.\nAvailable options are:\nNo one allowed (no_one_allowed) - Recommended and most secure option. Prevents all variable overrides.\nDeveloper (developer) - Allows developers and above to override variables\nMaintainer (maintainer) - Requires maintainer role or higher\nOwner (owner) - Only project owners can override variables\nAt the group level: Group maintainers can go to Settings > CI/CD > Variables > Default role to use pipeline variables to establish secure defaults for all new projects within their group, ensuring consistent security policies across your organization. Here we recommend again to use No one allowed as default value — this way, new projects in this group are created with a secure default setting. Note that this still allows project owners to change the setting.\nWhen pipeline variables are restricted completely (with “No one allowed”), the prefilled variables won’t appear in the \"New Pipeline UI\" form.\nHow to migrate from pipeline variables\nClose the gaps\nYour group may have projects that have pipeline variables enabled by default despite never having used them when triggering a pipeline. These projects can be migrated to the more secure setting without a risk of interruption. GitLab provides migration functionality via group settings:\nGo to Settings > CI/CD > Variables\nIn Disable pipeline variables in projects that don’t use them, select Start migration.\nThis migration is a background job that safely disables pipeline variables via project settings for all projects that historically have not used them.\nConvert pipeline variables to inputs\nFor each identified pipeline variable, create a corresponding pipeline input.\nBefore (using pipeline variables)\n\nvariables:\n  DEPLOY_ENV:\n    description: \"Deployment environment\"\n    value: \"staging\"\n  ENABLE_CACHE:\n    description: \"Enable deployment cache\"\n    value: \"true\"\n  VERSION:\n    description: \"Application version\"\n    value: \"1.0.0\"\n\ndeploy:\n  script:\n    - echo \"Deploying version $VERSION to $DEPLOY_ENV\"\n    - |\n      if [ \"$ENABLE_CACHE\" = \"true\" ]; then\n        echo \"Cache enabled\"\n      fi\n\nAfter (using pipeline inputs)\n\nspec:\n  inputs:\n    deploy_env:\n      description: \"Deployment environment\"\n      type: string\n      default: \"staging\"\n      options: [\"dev\", \"staging\", \"production\"]\n\n    enable_cache:\n      description: \"Enable deployment cache\"\n      type: boolean\n      default: true\n    \n    version:\n      description: \"Application version\"\n      type: string\n      default: \"1.0.0\"\n      regex: '^[0-9]+\\.[0-9]+\\.[0-9]+$'\n\ndeploy:\n  script:\n    - echo \"Deploying version $[[ inputs.version ]] to $[[ inputs.deploy_env ]]\"\n    - |\n      if [ \"$[[ inputs.enable_cache ]]\" = \"true\" ]; then\n        echo \"Cache enabled\"\n      fi\n\nMigrate trigger jobs\nIf you use trigger jobs with the trigger keyword, ensure they don't define job-level variables or disable inheriting variables from top-level variables, extends, or include, because variables could implicitly be passed downstream as pipeline variables. If pipeline variables are restricted on the downstream project, pipeline creation will fail.\nConsider updating your CI configuration to use pipeline inputs instead of pipeline variables.\n\nvariables:\n  FOO: bar\n\ndeploy-staging:\n  inherit:\n    variables: false # otherwise FOO would be sent downstream as a pipeline variable\n  trigger:\n    project: myorg/deployer\n    inputs:\n      deployment_env: staging\n      enable_tests: true\n\nSummary\nMigrating from pipeline variables to pipeline inputs is a security enhancement that protects your CI/CD infrastructure from variable injection while providing better documentation, type safety, and validation. By implementing these restrictions and adopting pipeline inputs, you're not just improving security, you're also making your pipelines more maintainable, self-documenting, and resilient.\nThe transition requires some initial effort, but the long-term benefits far outweigh the migration costs. Start by restricting pipeline variables at the group level for new projects, then systematically migrate existing pipelines using the step-by-step approach outlined above.\nSecurity is not a destination but a journey. Pipeline inputs are one important step in creating a more secure CI/CD environment, complementing other GitLab security features like protected branches, job token allowlists, and container registry protections.\nTo get started with pipeline inputs, sign up for a free trial of GitLab Ultimate today.",
      "publishedAt": "2025-11-04T00:00:00.000Z",
      "author": "Fabio Pitino",
      "source": "rss",
      "feedName": "GitLab Engineering",
      "ingestedAt": "2025-11-21T02:45:17.559Z"
    },
    {
      "id": "987224a4de1728719ce2b7ab59e361a6",
      "title": "Claude Sonnet 3.7 deprecation notice for GitLab Duo",
      "url": "https://about.gitlab.com/blog/claude-sonnet-3-7-deprecation-notice-for-gitlab-duo/",
      "content": "<p>Anthropic has announced the <a href=\"https://docs.claude.com/en/docs/about-claude/model-deprecations\">deprecation of Claude Sonnet 3.7</a>. To ensure continued service and access to the latest AI capabilities, GitLab will be removing Claude Sonnet 3.7 support from GitLab Duo features in GitLab 18.8 (which is planned for January 15, 2026).</p>\n<h2>Timeline</h2>\n<ul>\n<li><strong>Now:</strong> Claude Sonnet 3.7 is still available in GitLab Duo</li>\n<li><strong>GitLab 18.8:</strong> GitLab will remove Claude Sonnet 3.7 support from GitLab Duo features</li>\n<li><strong>Recommended action:</strong> Migrate to Claude 4.0+ models immediately</li>\n</ul>\n<h2>Additional resources</h2>\n<ul>\n<li><a href=\"https://docs.claude.com/en/docs/about-claude/model-deprecations\">Anthropic Model Deprecations</a></li>\n<li><a href=\"https://docs.gitlab.com/user/gitlab_duo/model_selection/\">GitLab Duo model selection</a></li>\n</ul>\n<p>If you have questions about this change or need assistance with migration, please reach out to <a href=\"https://support.gitlab.com/\">GitLab Support</a>.</p>\n",
      "summary": "Anthropic has announced the deprecation of Claude Sonnet 3.7. To ensure continued service and access to the latest AI capabilities, GitLab will be removing Claude Sonnet 3.7 support from GitLab Duo features in GitLab 18.8 (which is planned for January 15, 2026).\nTimeline\nNow: Claude Sonnet 3.7 is still available in GitLab Duo\nGitLab 18.8: GitLab will remove Claude Sonnet 3.7 support from GitLab Duo features\nRecommended action: Migrate to Claude 4.0+ models immediately\nAdditional resources\nAnthropic Model Deprecations\nGitLab Duo model selection\nIf you have questions about this change or need assistance with migration, please reach out to GitLab Support.",
      "publishedAt": "2025-10-31T00:00:00.000Z",
      "author": "Karishma Kumar",
      "source": "rss",
      "feedName": "GitLab Engineering",
      "ingestedAt": "2025-11-21T02:45:17.559Z"
    },
    {
      "id": "9e4661e93751ad1ca497a29d0e37c189",
      "title": "Ace your planning without the context-switching",
      "url": "https://about.gitlab.com/blog/ace-your-planning-without-the-context-switching/",
      "content": "<p>Software development teams face a challenging balancing act: dozens of tasks, limited time, and constant pressure to pick the right thing to work on next.</p>\n<p>The planning overhead of structuring requirements, managing backlogs, tracking delivery, and writing status updates steals hours from strategic thinking.</p>\n<p>The result? Less time for the high-value decisions that actually drive products forward.</p>\n<p>That’s why we developed <a href=\"https://docs.gitlab.com/user/duo_agent_platform/agents/foundational_agents/planner/\">GitLab Duo Planner</a>, an AI agent built on <a href=\"https://about.gitlab.com/gitlab-duo/agent-platform/\">GitLab Duo Agent Platform</a> to support product managers directly within GitLab.</p>\n<p>GitLab Duo Planner isn't another generic AI assistant. GitLab's product and engineering teams, who live these challenges daily like many of our customers, purpose-built GitLab Duo Planner to orchestrate planning workflows and reduce overhead while improving alignment and predictability.</p>\n<h2>Your new planning teammate</h2>\n<p>Today’s planning workflows face three major problems:</p>\n<ol>\n<li>Prone to drift -  Unplanned and orphaned work reduce trust in the plan.</li>\n<li>Disruptive to developers - Constant interruptions for status updates break flow.</li>\n<li>Opaque - Hidden risks surface too late to course-correct.</li>\n</ol>\n<p>Transforming the way teams work, GitLab Duo Planner turns manual overhead like vague ideas into structured requirements in minutes. Surface hidden backlog problems before they derail sprints. Apply RICE and MoSCoW frameworks instantly to make confident prioritization decisions. With awareness of GitLab context across the platform, every interaction with GitLab Duo Planner saves time and improves decision quality. This is possible because of the foundational agent architecture, bringing deep domain expertise and context awareness specific to GitLab.</p>\n<h2>Built for teams</h2>\n<p>GitLab Duo Planner leverages work items (epics, issues, tasks) and understands the nuances of work breakdown structures, dependency analysis, and effort estimation, making it well positioned to improve visibility, alignment, and confidence in delivery.</p>\n<ul>\n<li>\n<p>Platform approach - Unlike point solutions, Duo Planner orchestrates across your entire GitLab platform, from planning through development and testing, driving visibility across teams and workflows.</p>\n</li>\n<li>\n<p>Embedded in the flow - No more context-switching between tools or diving deep into GitLab to retrieve information. Duo Planner enables contributions, collaboration, and transparency from users across the software development lifecycle.</p>\n</li>\n<li>\n<p>Saves time and effort - Use Duo Planner to free your teams from repetitive coordination work, improving delivery predictability, reducing missed commitments while bringing in focus on what actually moves the needle.</p>\n</li>\n</ul>\n<h2>From chaos to clarity</h2>\n<p>GitLab Duo Planner can help at different stages of software planning and delivery while operating within the planning scope, providing a safe, bounded environment with project visibility.</p>\n<p>The agent can help with six flows:</p>\n<ul>\n<li>\n<p>Prioritization - Apply frameworks like RICE, MoSCoW, or WSJF to rank work items intelligently</p>\n</li>\n<li>\n<p>Work breakdown - Decompose initiatives into epics, features, and user stories to structure requirements</p>\n</li>\n<li>\n<p>Dependency analysis - Identify blocked work and understand relationships between items to maintain velocity</p>\n</li>\n<li>\n<p>Planning -  Organize sprints, milestones, or quarterly planning</p>\n</li>\n<li>\n<p>Status reporting -  Generate summaries of project progress, risks, and blockers to track delivery</p>\n</li>\n<li>\n<p>Backlog management -  Identify stale issues, duplicates, or items needing refinement to improve data hygiene</p>\n</li>\n</ul>\n<p>Here is an example how GitLab Duo Planner can check the status of an initiative:</p>\n<p>&lt;div style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/1131065078?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share&quot; referrerpolicy=&quot;strict-origin-when-cross-origin&quot; style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot; title=&quot;GitLab Duo Planner Agent&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;script src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;</p>\n<p>&lt;p&gt;&lt;/p&gt;</p>\n<p>Duo Planner is available as a custom agent in the Duo Chat side panel, with the current page context.</p>\n<p>&lt;p&gt;&lt;/p&gt;</p>\n<p><img src=\"https://res.cloudinary.com/about-gitlab-com/image/upload/v1761323689/ener1mkyj9shg6zvtp4f.png\" alt=\"Duo Planner as a custom agent in the Duo Chat side panel\"></p>\n<p>&lt;p&gt;&lt;/p&gt;</p>\n<p>Let’s ask Duo Planner about the status of an initiative by providing the epic link:</p>\n<p><img src=\"https://res.cloudinary.com/about-gitlab-com/image/upload/v1761323689/gzv2xudegtjhtesz1oaz.png\" alt=\"Asking Duo Planner about the status of an initiative by providing the epic link\"></p>\n<p>&lt;p&gt;&lt;/p&gt;</p>\n<p>We receive a structured summary with an overview, current status of milestones, in-progress items, dependencies, and blockers, along with actionable recommendations.</p>\n<p><img src=\"https://res.cloudinary.com/about-gitlab-com/image/upload/v1761323690/guoyqe1b9bstmbjzunez.png\" alt=\"Structured summary\"></p>\n<p>&lt;p&gt;&lt;/p&gt;</p>\n<p>Next, let’s ask for an executive summary to share with stakeholders:\nGitLab Duo Planner eliminates hours of manual analysis and reporting effort, helping to make decisions faster and keep all stakeholders updated.</p>\n<p><img src=\"https://res.cloudinary.com/about-gitlab-com/image/upload/v1761323689/xs9zxawqrytfu54ejx2b.png\" alt=\"Ask for executive summary\"></p>\n<p>&lt;p&gt;&lt;/p&gt;</p>\n<p><img src=\"https://res.cloudinary.com/about-gitlab-com/image/upload/v1761323690/bsbpvjaqnymobzg4knhu.png\" alt=\"Output of executive summary\"></p>\n<p>&lt;p&gt;&lt;/p&gt;</p>\n<p>Here are a few more prompts you can try with GitLab Duo Planner:</p>\n<ul>\n<li>“Which of the bugs with a “boards” label should we fix first, considering user impact?”</li>\n<li>“Rank these epics by strategic value for Q1.”</li>\n<li>“Help me prioritize technical debt against new features.”</li>\n<li>“What tasks are needed to implement this user story?”</li>\n<li>“Suggest a phased approach for this project: (insert URL).”</li>\n</ul>\n<h2>What's next</h2>\n<p>GitLab Duo Planner focuses intentionally on product managers and engineering managers working in Agile environments. Why? Because specificity drives performance. By training Duo Planner deeply on GitLab's planning workflows and Agile frameworks, we deliver reliable, actionable insights rather than generic suggestions.</p>\n<p>As we evolve the platform, we envision a family of specialized agents, each optimized for specific workflows while contributing to a unified intelligence layer. Today's planner for software teams is just the beginning of how AI will transform work prioritization across all teams.</p>\n<blockquote>\n<p>If you’re an existing GitLab customer and would like to try GitLab Duo Planner with a prompt of your own, visit our <a href=\"https://docs.gitlab.com/user/duo_agent_platform/agents/foundational_agents/planner/\">documentation</a> where we cover prerequisites, use cases, and more.</p>\n</blockquote>\n",
      "summary": "Software development teams face a challenging balancing act: dozens of tasks, limited time, and constant pressure to pick the right thing to work on next.\nThe planning overhead of structuring requirements, managing backlogs, tracking delivery, and writing status updates steals hours from strategic thinking.\nThe result? Less time for the high-value decisions that actually drive products forward.\nThat’s why we developed GitLab Duo Planner, an AI agent built on GitLab Duo Agent Platform to support product managers directly within GitLab.\nGitLab Duo Planner isn't another generic AI assistant. GitLab's product and engineering teams, who live these challenges daily like many of our customers, purpose-built GitLab Duo Planner to orchestrate planning workflows and reduce overhead while improving alignment and predictability.\nYour new planning teammate\nToday’s planning workflows face three major problems:\nProne to drift -  Unplanned and orphaned work reduce trust in the plan.\nDisruptive to developers - Constant interruptions for status updates break flow.\nOpaque - Hidden risks surface too late to course-correct.\nTransforming the way teams work, GitLab Duo Planner turns manual overhead like vague ideas into structured requirements in minutes. Surface hidden backlog problems before they derail sprints. Apply RICE and MoSCoW frameworks instantly to make confident prioritization decisions. With awareness of GitLab context across the platform, every interaction with GitLab Duo Planner saves time and improves decision quality. This is possible because of the foundational agent architecture, bringing deep domain expertise and context awareness specific to GitLab.\nBuilt for teams\nGitLab Duo Planner leverages work items (epics, issues, tasks) and understands the nuances of work breakdown structures, dependency analysis, and effort estimation, making it well positioned to improve visibility, alignment, and confidence in delivery.\nPlatform approach - Unlike point solutions, Duo Planner orchestrates across your entire GitLab platform, from planning through development and testing, driving visibility across teams and workflows.\nEmbedded in the flow - No more context-switching between tools or diving deep into GitLab to retrieve information. Duo Planner enables contributions, collaboration, and transparency from users across the software development lifecycle.\nSaves time and effort - Use Duo Planner to free your teams from repetitive coordination work, improving delivery predictability, reducing missed commitments while bringing in focus on what actually moves the needle.\nFrom chaos to clarity\nGitLab Duo Planner can help at different stages of software planning and delivery while operating within the planning scope, providing a safe, bounded environment with project visibility.\nThe agent can help with six flows:\nPrioritization - Apply frameworks like RICE, MoSCoW, or WSJF to rank work items intelligently\nWork breakdown - Decompose initiatives into epics, features, and user stories to structure requirements\nDependency analysis - Identify blocked work and understand relationships between items to maintain velocity\nPlanning -  Organize sprints, milestones, or quarterly planning\nStatus reporting -  Generate summaries of project progress, risks, and blockers to track delivery\nBacklog management -  Identify stale issues, duplicates, or items needing refinement to improve data hygiene\nHere is an example how GitLab Duo Planner can check the status of an initiative:\n<div style=\"padding:56.25% 0 0 0;position:relative;\"><iframe src=\"https://player.vimeo.com/video/1131065078?badge=0&autopause=0&player_id=0&app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"GitLab Duo Planner Agent\"></iframe></div><script src=\"https://player.vimeo.com/api/player.js\"></script>\n<p></p>\nDuo Planner is available as a custom agent in the Duo Chat side panel, with the current page context.\n<p></p>\n\n<p></p>\nLet’s ask Duo Planner about the status of an initiative by providing the epic link:\n\n<p></p>\nWe receive a structured summary with an overview, current status of milestones, in-progress items, dependencies, and blockers, along with actionable recommendations.\n\n<p></p>\nNext, let’s ask for an executive summary to share with stakeholders:\nGitLab Duo Planner eliminates hours of manual analysis and reporting effort, helping to make decisions faster and keep all stakeholders updated.\n\n<p></p>\n\n<p></p>\nHere are a few more prompts you can try with GitLab Duo Planner:\n“Which of the bugs with a “boards” label should we fix first, considering user impact?”\n“Rank these epics by strategic value for Q1.”\n“Help me prioritize technical debt against new features.”\n“What tasks are needed to implement this user story?”\n“Suggest a phased approach for this project: (insert URL).”\nWhat's next\nGitLab Duo Planner focuses intentionally on product managers and engineering managers working in Agile environments. Why? Because specificity drives performance. By training Duo Planner deeply on GitLab's planning workflows and Agile frameworks, we deliver reliable, actionable insights rather than generic suggestions.\nAs we evolve the platform, we envision a family of specialized agents, each optimized for specific workflows while contributing to a unified intelligence layer. Today's planner for software teams is just the beginning of how AI will transform work prioritization across all teams.\nIf you’re an existing GitLab customer and would like to try GitLab Duo Planner with a prompt of your own, visit our documentation where we cover prerequisites, use cases, and more.",
      "publishedAt": "2025-10-28T00:00:00.000Z",
      "author": "Aathira Nair",
      "source": "rss",
      "feedName": "GitLab Engineering",
      "ingestedAt": "2025-11-21T02:45:17.559Z"
    },
    {
      "id": "985131f8ceb79cd47bb3ef57884a8bfb",
      "title": "How Jimdo empower solopreneurs with AI-powered business assistance",
      "url": "https://blog.langchain.com/customers-jimdo/",
      "content": "See how Jimdo uses LangChain.js, LangGraph.js, and LangSmith to deliver personalized business insights that drive 50% more first customer contacts and 40% more overall customer activity.",
      "summary": "See how Jimdo uses LangChain.js, LangGraph.js, and LangSmith to deliver personalized business insights that drive 50% more first customer contacts and 40% more overall customer activity.",
      "publishedAt": "2025-11-20T01:47:31.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z",
      "tags": [
        "Case Studies"
      ]
    },
    {
      "id": "b27ae2bc05a737f23fcecb6269b3a5da",
      "title": "How ServiceNow uses LangSmith to get visibility into its customer success agents",
      "url": "https://blog.langchain.com/customers-servicenow/",
      "content": "<p><strong>Authors: </strong><em>Ganesh Srinivasan (ServiceNow), Linda Ye (LangChain), and Jake Broekhuizen (LangChain)</em></p><p>ServiceNow is a leading digital workflow platform that helps enterprises transform service management across IT, customer service, and other departments. To improve their internal sales and customer success operations, ServiceNow&apos;s AI team is using LangSmith and LangGraph</p>",
      "summary": "Authors: Ganesh Srinivasan (ServiceNow), Linda Ye (LangChain), and Jake Broekhuizen (LangChain)\nServiceNow is a leading digital workflow platform that helps enterprises transform service management across IT, customer service, and other departments. To improve their internal sales and customer success operations, ServiceNow's AI team is using LangSmith and LangGraph",
      "publishedAt": "2025-11-17T22:42:50.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z",
      "tags": [
        "Case Studies"
      ]
    },
    {
      "id": "8f5798e972d05abecb217992caf57325",
      "title": "Execute Code with Sandboxes for DeepAgents",
      "url": "https://blog.langchain.com/execute-code-with-sandboxes-for-deepagents/",
      "content": "<p>By Vivek Trivedy</p><p>Today we&apos;re excited to launch Sandboxes for DeepAgents, a new set of integrations that allow you to safely execute arbitrary DeepAgent code in remote sandboxes. We currently support sandboxes from 3 of our partners: <a href=\"https://www.runloop.ai/?ref=blog.langchain.com\">Runloop</a>, <a href=\"https://www.daytona.io/?ref=blog.langchain.com\">Daytona</a>, and <a href=\"https://modal.com/?ref=blog.langchain.com\">Modal</a>. Below, we dive into what you can</p>",
      "summary": "By Vivek Trivedy\nToday we're excited to launch Sandboxes for DeepAgents, a new set of integrations that allow you to safely execute arbitrary DeepAgent code in remote sandboxes. We currently support sandboxes from 3 of our partners: Runloop, Daytona, and Modal. Below, we dive into what you can",
      "publishedAt": "2025-11-13T16:22:20.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z"
    },
    {
      "id": "bfe9dd799455d3b59dc1944a15f55f52",
      "title": "Join LangChain at AWS re:Invent 2025",
      "url": "https://blog.langchain.com/join-langchain-at-aws-re-invent-2025/",
      "content": "<p>If you&apos;re attending AWS re:Invent in Las Vegas this year and working on agent development, here&apos;s what we have planned:</p><h2 id=\"visit-us-at-booth-524\">Visit Us at Booth #524</h2><p>We&apos;ll be at Booth #524 in the Venetian Expo Center, next to the Industry Pavilion, December 1-4. Our</p>",
      "summary": "If you're attending AWS re:Invent in Las Vegas this year and working on agent development, here's what we have planned:\nVisit Us at Booth #524\nWe'll be at Booth #524 in the Venetian Expo Center, next to the Industry Pavilion, December 1-4. Our",
      "publishedAt": "2025-11-11T00:58:44.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z"
    },
    {
      "id": "35bf5cf8090b5db4f59fdb81c62895a6",
      "title": "Why We Rebuilt LangChain’s Chatbot and What We Learned",
      "url": "https://blog.langchain.com/rebuilding-chat-langchain/",
      "content": "<p><em>By Liam Bush</em></p><h2 id=\"background\">Background</h2><p>Every successful platform needs reliable support, but we realized our own team was spending hours tracking down answers to technical questions. This friction wasn&apos;t just slowing down our engineers&#x2014;it was a critical <strong>bottleneck</strong> for our users.</p><p>We set out to solve this</p>",
      "summary": "By Liam Bush\nBackground\nEvery successful platform needs reliable support, but we realized our own team was spending hours tracking down answers to technical questions. This friction wasn't just slowing down our engineers—it was a critical bottleneck for our users.\nWe set out to solve this",
      "publishedAt": "2025-11-05T16:28:53.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z"
    },
    {
      "id": "fe24922605f234a8b32ff9e8ee404b05",
      "title": "Introducing DeepAgents CLI",
      "url": "https://blog.langchain.com/introducing-deepagents-cli/",
      "content": "<p><em>By </em><a href=\"https://www.linkedin.com/in/vivek-trivedy-433509134/?ref=blog.langchain.com\"><em>Vivek Trivedy</em></a></p><p>We&apos;re excited to introduce <strong>DeepAgents CLI</strong> for coding, research, and building agents with persistent memory. Now you can easily create and run custom DeepAgents directly from the terminal. It supports:</p><ul><li><strong>Read, write, and edit files</strong> in your project</li><li><strong>Execute shell commands</strong> with human approval</li><li><strong>Search</strong></li></ul>",
      "summary": "By Vivek Trivedy\nWe're excited to introduce DeepAgents CLI for coding, research, and building agents with persistent memory. Now you can easily create and run custom DeepAgents directly from the terminal. It supports:\n\nRead, write, and edit files in your project\nExecute shell commands with human approval\nSearch",
      "publishedAt": "2025-10-30T16:55:35.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z"
    },
    {
      "id": "6be2480ae9b32bf3b491c4e502760868",
      "title": "Introducing LangSmith’s No Code Agent Builder",
      "url": "https://blog.langchain.com/langsmith-agent-builder/",
      "content": "<p><em>By Brace Sproul and Sam Crowder</em></p><p>Today, we&#x2019;re expanding who can build agents beyond developers. While a lot of the highest volume, customer-facing agents will be built by technical teams, nearly every business user has use cases for agentic applications in their daily routines. Our new <strong>LangSmith Agent</strong></p>",
      "summary": "By Brace Sproul and Sam Crowder\nToday, we’re expanding who can build agents beyond developers. While a lot of the highest volume, customer-facing agents will be built by technical teams, nearly every business user has use cases for agentic applications in their daily routines. Our new LangSmith Agent",
      "publishedAt": "2025-10-29T14:38:43.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z"
    },
    {
      "id": "b7a1c14ff5fb54ec9b794f1291406698",
      "title": "Doubling down on DeepAgents",
      "url": "https://blog.langchain.com/doubling-down-on-deepagents/",
      "content": "<p>Two months ago <a href=\"https://blog.langchain.com/deep-agents/\">we wrote about Deep Agents</a> - a term we coined for agents that are able to do complex, open ended tasks over longer time horizons. We hypothesized that there were four key elements to those agents: a planning tool, access to a filesystem, subagents, and detailed prompts.</p>",
      "summary": "Two months ago we wrote about Deep Agents - a term we coined for agents that are able to do complex, open ended tasks over longer time horizons. We hypothesized that there were four key elements to those agents: a planning tool, access to a filesystem, subagents, and detailed prompts.",
      "publishedAt": "2025-10-28T17:02:22.000Z",
      "author": "LangChain Accounts",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z"
    },
    {
      "id": "35f5e149ddd7b981222eeccafddaca18",
      "title": "Agent Frameworks, Runtimes, and Harnesses- oh my!",
      "url": "https://blog.langchain.com/agent-frameworks-runtimes-and-harnesses-oh-my/",
      "content": "<p>There are few different open source packages we maintain: <a href=\"https://docs.langchain.com/oss/python/langchain/quickstart?ref=blog.langchain.com\">LangChain</a> and <a href=\"https://docs.langchain.com/oss/python/langgraph/overview?ref=blog.langchain.com\">LangGraph</a> being the biggest ones, but <a href=\"https://docs.langchain.com/oss/python/deepagents/overview?ref=blog.langchain.com\">DeepAgents</a> being an increasingly popular one. I&#x2019;ve started using different terms to describe them: LangChain is an agent framework, LangGraph is an agent runtime, DeepAgents is an <a href=\"https://www.vtrivedy.com/posts/claude-code-sdk-haas-harness-as-a-service?ref=blog.langchain.com\">agent harness</a>. Other folks</p>",
      "summary": "There are few different open source packages we maintain: LangChain and LangGraph being the biggest ones, but DeepAgents being an increasingly popular one. I’ve started using different terms to describe them: LangChain is an agent framework, LangGraph is an agent runtime, DeepAgents is an agent harness. Other folks",
      "publishedAt": "2025-10-25T16:14:35.000Z",
      "author": "LangChain Accounts",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z",
      "tags": [
        "In the Loop"
      ]
    },
    {
      "id": "6a3e63855e3e53cf75d5700936c60023",
      "title": "Improve agent quality with Insights Agent and Multi-turn Evals, now in LangSmith",
      "url": "https://blog.langchain.com/insights-agent-multiturn-evals-langsmith/",
      "content": "LangSmith's new Insights Agent and Multi-turn Evals help you understand what your agents are doing in production and whether they're accomplishing user goals.",
      "summary": "LangSmith's new Insights Agent and Multi-turn Evals help you understand what your agents are doing in production and whether they're accomplishing user goals.",
      "publishedAt": "2025-10-23T14:23:55.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z"
    },
    {
      "id": "1befb3ac924097b0b30e6945eeb84153",
      "title": "LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones",
      "url": "https://blog.langchain.com/langchain-langgraph-1dot0/",
      "content": "<p><em>By Sydney Runkle and the LangChain OSS team </em></p><p>We&apos;re releasing LangChain 1.0 and LangGraph 1.0 &#x2014; our first major versions of our open source frameworks! After years of feedback, we&apos;ve updated <code>langchain</code> to focus on the core agent loop, provide flexibility with a new</p>",
      "summary": "By Sydney Runkle and the LangChain OSS team \nWe're releasing LangChain 1.0 and LangGraph 1.0 — our first major versions of our open source frameworks! After years of feedback, we've updated langchain to focus on the core agent loop, provide flexibility with a new",
      "publishedAt": "2025-10-22T14:58:46.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "ingestedAt": "2025-11-21T02:45:17.693Z"
    },
    {
      "id": "5271fc17f5fd1afc838f339dfe9d99c9",
      "title": "Cloudflare outage on November 18, 2025",
      "url": "https://blog.cloudflare.com/18-november-2025-outage/",
      "content": " Cloudflare suffered a service outage on November 18, 2025. The outage was triggered by a bug in generation logic for a Bot Management feature file causing many Cloudflare services to be affected. \n ",
      "summary": "Cloudflare suffered a service outage on November 18, 2025. The outage was triggered by a bug in generation logic for a Bot Management feature file causing many Cloudflare services to be affected.",
      "publishedAt": "2025-11-18T00:00:00.000Z",
      "author": "Matthew Prince",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Outage",
        "Post Mortem",
        "Bot Management"
      ]
    },
    {
      "id": "5be5f110acef8d468cf32c58394ecd31",
      "title": "Replicate is joining Cloudflare",
      "url": "https://blog.cloudflare.com/replicate-joins-cloudflare/",
      "content": " Bringing Replicate’s tools into Cloudflare will continue to make our Workers Platform the best place on the Internet to build and deploy any AI or agentic workflow.\n ",
      "summary": "Bringing Replicate’s tools into Cloudflare will continue to make our Workers Platform the best place on the Internet to build and deploy any AI or agentic workflow.",
      "publishedAt": "2025-11-17T14:00:00.000Z",
      "author": "Rita Kozlov",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Acquisitions",
        "Developer Platform",
        "Developers",
        "AI"
      ]
    },
    {
      "id": "1bd9bdd958ac7cba223bcc6389abda47",
      "title": "Finding the grain of sand in a heap of Salt",
      "url": "https://blog.cloudflare.com/finding-the-grain-of-sand-in-a-heap-of-salt/",
      "content": " We explore the fundamentals of Saltstack and how we use it at Cloudflare. We also explain how we built the infrastructure to reduce release delays due to Salt failures on the edge by over 5%.  ",
      "summary": "We explore the fundamentals of Saltstack and how we use it at Cloudflare. We also explain how we built the infrastructure to reduce release delays due to Salt failures on the edge by over 5%.",
      "publishedAt": "2025-11-13T14:00:00.000Z",
      "author": "Opeyemi Onikute",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Salt",
        "Engineering",
        "Configuration Management",
        "SRE"
      ]
    },
    {
      "id": "b2d2e8963cbc60f63decca7820a3ef18",
      "title": "Connecting to production: the architecture of remote bindings",
      "url": "https://blog.cloudflare.com/connecting-to-production-the-architecture-of-remote-bindings/",
      "content": " Remote bindings allow you to connect your local Worker code to deployed Cloudflare resources like R2 and D1. Come along on the technical journey of how we built this feature to create a seamless local development experience. ",
      "summary": "Remote bindings allow you to connect your local Worker code to deployed Cloudflare resources like R2 and D1. Come along on the technical journey of how we built this feature to create a seamless local development experience.",
      "publishedAt": "2025-11-12T14:00:00.000Z",
      "author": "Samuel Macleod",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Cloudflare Workers",
        "R2",
        "D1"
      ]
    },
    {
      "id": "f289a9e6d3293037e2f25e5965a97fd1",
      "title": "A closer look at Python Workflows, now in beta",
      "url": "https://blog.cloudflare.com/python-workflows/",
      "content": " Cloudflare Workflows, our durable execution engine for running multi-step applications, now supports Python. That means less friction, more possibilities, and another reason to build on Cloudflare. ",
      "summary": "Cloudflare Workflows, our durable execution engine for running multi-step applications, now supports Python. That means less friction, more possibilities, and another reason to build on Cloudflare.",
      "publishedAt": "2025-11-10T14:00:00.000Z",
      "author": "Caio Nogueira",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Workflows",
        "Cloudflare Workers",
        "Python"
      ]
    },
    {
      "id": "103754bca8bab2ed1d218ecfd2f2c658",
      "title": "DIY BYOIP: a new way to Bring Your Own IP prefixes to Cloudflare",
      "url": "https://blog.cloudflare.com/diy-byoip/",
      "content": " Announcing a new self-serve API for Bring Your Own IP (BYOIP), giving customers unprecedented control and flexibility to onboard, manage, and use their own IP prefixes with Cloudflare's services. ",
      "summary": "Announcing a new self-serve API for Bring Your Own IP (BYOIP), giving customers unprecedented control and flexibility to onboard, manage, and use their own IP prefixes with Cloudflare's services.",
      "publishedAt": "2025-11-07T14:00:00.000Z",
      "author": "Ash Pallarito",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "API",
        "Addressing",
        "BYOIP",
        "IPv4",
        "IPv6",
        "Spectrum",
        "CDN",
        "Magic Transit",
        "Egress",
        "Cloudflare Gateway",
        "RPKI",
        "Aegis",
        "Smart Shield"
      ]
    },
    {
      "id": "335d577c6a9a76dfda90aebd91bb9862",
      "title": "Async QUIC and HTTP/3 made easy: tokio-quiche is now open-source",
      "url": "https://blog.cloudflare.com/async-quic-and-http-3-made-easy-tokio-quiche-is-now-open-source/",
      "content": " We’re excited to announce the open sourcing of tokio-quiche, our async QUIC library built on quiche and tokio. Relied upon in our services such as iCloud Private Relay and our next-generation Oxy-based proxies, tokio-quiche handles millions of HTTP/3 requests per second with low latency and high throughput.  ",
      "summary": "We’re excited to announce the open sourcing of tokio-quiche, our async QUIC library built on quiche and tokio. Relied upon in our services such as iCloud Private Relay and our next-generation Oxy-based proxies, tokio-quiche handles millions of HTTP/3 requests per second with low latency and high throughput.",
      "publishedAt": "2025-11-06T14:00:00.000Z",
      "author": "Mendes",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Protocols",
        "QUICHE",
        "Privacy"
      ]
    },
    {
      "id": "5db95dfc802481130a34824aea8499b1",
      "title": "Extract audio from your videos with Cloudflare Stream",
      "url": "https://blog.cloudflare.com/extract-audio-from-your-videos-with-cloudflare-stream/",
      "content": " Cloudflare Stream provides a unified platform for video storage, encoding, and delivery. We are now enabling developers to seamlessly extract audio from videos. ",
      "summary": "Cloudflare Stream provides a unified platform for video storage, encoding, and delivery. We are now enabling developers to seamlessly extract audio from videos.",
      "publishedAt": "2025-11-06T14:00:00.000Z",
      "author": "Pakhi Sinha",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Internship Experience",
        "Product News",
        "Cloudflare Stream"
      ]
    },
    {
      "id": "c8f2aecb23fe18c4d230191cc6917784",
      "title": "How Workers VPC Services connects to your regional private networks from anywhere in the world",
      "url": "https://blog.cloudflare.com/workers-vpc-open-beta/",
      "content": " Workers VPC Services enter open beta today. We look under the hood to see how Workers VPC connects your globally-deployed Workers to your regional private networks by using Cloudflare's global network, while abstracting cross-cloud networking complexity. ",
      "summary": "Workers VPC Services enter open beta today. We look under the hood to see how Workers VPC connects your globally-deployed Workers to your regional private networks by using Cloudflare's global network, while abstracting cross-cloud networking complexity.",
      "publishedAt": "2025-11-05T14:00:00.000Z",
      "author": "Thomas Gauvin",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Cloudflare Workers",
        "Workers VPC",
        "Cloudflare Tunnel",
        "Network",
        "Hybrid Cloud",
        "Security",
        "VPC",
        "Private Network"
      ]
    },
    {
      "id": "53bb55f0776e595d4e5898aa91f212c0",
      "title": "Building a better testing experience for Workflows, our durable execution engine for multi-step applications",
      "url": "https://blog.cloudflare.com/better-testing-for-workflows/",
      "content": " End-to-end testing for Cloudflare Workflows was challenging. We're introducing first-class support for Workflows in cloudflare:test, enabling full introspection, mocking, and isolated, reliable tests for your most complex applications. ",
      "summary": "End-to-end testing for Cloudflare Workflows was challenging. We're introducing first-class support for Workflows in cloudflare:test, enabling full introspection, mocking, and isolated, reliable tests for your most complex applications.",
      "publishedAt": "2025-11-04T14:00:00.000Z",
      "author": "Olga Silva",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Developers",
        "Internship Experience",
        "Product News",
        "Developer Platform",
        "Cloudflare Workers",
        "Workflows"
      ]
    },
    {
      "id": "d3dd3bc4a95b20d28af8ad6dd786793d",
      "title": "Fresh insights from old data: corroborating reports of Turkmenistan IP unblocking and firewall testing",
      "url": "https://blog.cloudflare.com/fresh-insights-from-old-data-corroborating-reports-of-turkmenistan-ip/",
      "content": " Cloudflare used historical data to investigate reports of potential new firewall tests in Turkmenistan. Shifts in TCP resets/timeouts across ASNs corroborate large-scale network control system changes.\n ",
      "summary": "Cloudflare used historical data to investigate reports of potential new firewall tests in Turkmenistan. Shifts in TCP resets/timeouts across ASNs corroborate large-scale network control system changes.",
      "publishedAt": "2025-11-03T13:00:00.000Z",
      "author": "Luke Valenta",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Radar",
        "Research",
        "Internet Shutdown",
        "Internet Trends",
        "Trends",
        "Consumer Services"
      ]
    },
    {
      "id": "9f337f6fda7ddfd53bcdfd19521b2caa",
      "title": "BGP zombies and excessive path hunting",
      "url": "https://blog.cloudflare.com/going-bgp-zombie-hunting/",
      "content": " A BGP “zombie” is essentially a route that has become stuck in the Default-Free Zone (DFZ) of the Internet, potentially due to a missed or lost prefix withdrawal. We’ll walk through some situations where BGP zombies are more likely to rise from the dead and wreak havoc.\n ",
      "summary": "A BGP “zombie” is essentially a route that has become stuck in the Default-Free Zone (DFZ) of the Internet, potentially due to a missed or lost prefix withdrawal. We’ll walk through some situations where BGP zombies are more likely to rise from the dead and wreak havoc.",
      "publishedAt": "2025-10-31T15:30:00.000Z",
      "author": "Bryton Herdes",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "BGP",
        "Routing",
        "Network",
        "BYOIP"
      ]
    },
    {
      "id": "0c66130efec05071e4c863a625fc2522",
      "title": "Go and enhance your calm: demolishing an HTTP/2 interop problem",
      "url": "https://blog.cloudflare.com/go-and-enhance-your-calm/",
      "content": " HTTP/2 implementations often respond to suspected attacks by closing the connection with an ENHANCE_YOUR_CALM error code. Learn how a common pattern of using Go's HTTP/2 client can lead to unintended errors and the solution to avoiding them. ",
      "summary": "HTTP/2 implementations often respond to suspected attacks by closing the connection with an ENHANCE_YOUR_CALM error code. Learn how a common pattern of using Go's HTTP/2 client can lead to unintended errors and the solution to avoiding them.",
      "publishedAt": "2025-10-31T13:00:00.000Z",
      "author": "Lucas Pardue",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "HTTP2",
        "Go",
        "DDoS"
      ]
    },
    {
      "id": "d0a69ee2abbd29efe33326bb7f90f12e",
      "title": "Anonymous credentials: rate-limiting bots and agents without compromising privacy",
      "url": "https://blog.cloudflare.com/private-rate-limiting/",
      "content": " As AI agents change how the Internet is used, they create a challenge for security. We explore how Anonymous Credentials can rate limit agent traffic and block abuse without tracking users or compromising their privacy. ",
      "summary": "As AI agents change how the Internet is used, they create a challenge for security. We explore how Anonymous Credentials can rate limit agent traffic and block abuse without tracking users or compromising their privacy.",
      "publishedAt": "2025-10-30T13:00:00.000Z",
      "author": "Thibault Meunier",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Research",
        "Rate Limiting"
      ]
    },
    {
      "id": "8947b815149bb2bb498494c5c2cba74d",
      "title": "Measuring characteristics of TCP connections at Internet scale",
      "url": "https://blog.cloudflare.com/measuring-network-connections-at-scale/",
      "content": " Researchers and practitioners have been studying connections almost as long as the Internet that supports them. Today, Cloudflare’s global network receives millions of connections per second. We explore various characteristics of TCP connections, including lifetimes, sizes, and more. ",
      "summary": "Researchers and practitioners have been studying connections almost as long as the Internet that supports them. Today, Cloudflare’s global network receives millions of connections per second. We explore various characteristics of TCP connections, including lifetimes, sizes, and more.",
      "publishedAt": "2025-10-29T13:00:00.000Z",
      "author": "Suleman Ahmad",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Research",
        "Better Internet",
        "Insights",
        "TCP"
      ]
    },
    {
      "id": "41c37e1223ae1a73ddf18fac9ae5cabf",
      "title": "One IP address, many users: detecting CGNAT to reduce collateral effects",
      "url": "https://blog.cloudflare.com/detecting-cgn-to-reduce-collateral-damage/",
      "content": " IPv4 scarcity drives widespread use of Carrier-Grade Network Address Translation, a practice in ISPs and mobile networks that places many users behind each IP address, along with their collected activity and volumes of traffic. We introduce the method we’ve developed to detect large-scale IP sharing globally and mitigate the issues that result.  ",
      "summary": "IPv4 scarcity drives widespread use of Carrier-Grade Network Address Translation, a practice in ISPs and mobile networks that places many users behind each IP address, along with their collected activity and volumes of traffic. We introduce the method we’ve developed to detect large-scale IP sharing globally and mitigate the issues that result.",
      "publishedAt": "2025-10-29T13:00:00.000Z",
      "author": "Vasilis Giotsas",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Research",
        "WAF",
        "Web Application Firewall",
        "Better Internet",
        "Security",
        "Bots",
        "IPv4",
        "Network Services"
      ]
    },
    {
      "id": "ac9be51bad539591d589c8d93312adf0",
      "title": "How to build your own VPN, or: the history of WARP",
      "url": "https://blog.cloudflare.com/how-to-build-your-own-vpn-or-the-history-of-warp/",
      "content": " WARP’s initial implementation resembled a VPN that allows Internet access through it. Here’s how we built it – and how you can, too.  ",
      "summary": "WARP’s initial implementation resembled a VPN that allows Internet access through it. Here’s how we built it – and how you can, too.",
      "publishedAt": "2025-10-29T13:00:00.000Z",
      "author": "Chris Branch",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Research",
        "WARP",
        "Linux"
      ]
    },
    {
      "id": "eb9379188ab9e2eea9017aa597b55f27",
      "title": "Defending QUIC from acknowledgement-based DDoS attacks",
      "url": "https://blog.cloudflare.com/defending-quic-from-acknowledgement-based-ddos-attacks/",
      "content": " We identified and patched two DDoS vulnerabilities in our QUIC implementation related to packet acknowledgements. Cloudflare customers were not affected. We examine the \"Optimistic ACK\" attack vector and our solution, which dynamically skips packet numbers to validate client behavior.  ",
      "summary": "We identified and patched two DDoS vulnerabilities in our QUIC implementation related to packet acknowledgements. Cloudflare customers were not affected. We examine the \"Optimistic ACK\" attack vector and our solution, which dynamically skips packet numbers to validate client behavior.",
      "publishedAt": "2025-10-29T13:00:00.000Z",
      "author": "Apoorv Kothari",
      "source": "rss",
      "feedName": "Cloudflare Blog",
      "ingestedAt": "2025-11-21T02:45:18.420Z",
      "tags": [
        "Research",
        "QUIC",
        "Protocols",
        "Vulnerabilities",
        "Security"
      ]
    },
    {
      "id": "b3fac0df66a2922b262193e88454d763",
      "title": "Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models",
      "url": "https://arxiv.org/html/2511.15304v1",
      "content": "<p><a href=\"https://lobste.rs/s/w9lkk3/adversarial_poetry_as_universal_single\">Comments</a></p>",
      "summary": "Comments",
      "publishedAt": "2025-11-20T17:27:13.000Z",
      "author": "arxiv.org via df",
      "source": "rss",
      "feedName": "Lobste.rs",
      "ingestedAt": "2025-11-21T02:45:18.874Z",
      "tags": [
        "security",
        "ai"
      ]
    },
    {
      "id": "15e65832f0b102ac86c2e147a819c642",
      "title": "Agentic Pelican on a Bicycle: Gemini 3 Pro",
      "url": "https://www.robert-glaser.de/agentic-pelican-on-a-bicycle-gemini-3-pro/",
      "content": "<p><a href=\"https://lobste.rs/s/towtni/agentic_pelican_on_bicycle_gemini_3_pro\">Comments</a></p>",
      "summary": "Comments",
      "publishedAt": "2025-11-20T10:34:45.000Z",
      "author": "robert-glaser.de by youngbrioche",
      "source": "rss",
      "feedName": "Lobste.rs",
      "ingestedAt": "2025-11-21T02:45:18.874Z",
      "tags": [
        "vibecoding"
      ]
    }
  ],
  "lastSync": "2025-11-21T03:13:11.554Z"
}