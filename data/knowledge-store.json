{
  "papers": [
    {
      "id": "37573748",
      "bibcode": "2025arXiv251105385Z",
      "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework",
      "authors": [
        "Zhang, Chao",
        "Wang, Yuhao",
        "Xu, Derong",
        "Zhang, Haoxin",
        "Lyu, Yuanjie",
        "Chen, Yuhao",
        "Liu, Shuochen",
        "Xu, Tong",
        "Zhao, Xiangyu",
        "Gao, Yan",
        "Hu, Yao",
        "Chen, Enhong"
      ],
      "year": "2025",
      "abstract": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs autonomous, multi-round retrieval and reasoning to resolve queries. Although recent agentic RAG has improved via reinforcement learning, they often incur substantial token overhead from search and reasoning processes. This trade-off prioritizes accuracy over efficiency. To address this issue, this work proposes TeaRAG, a token-efficient agentic RAG framework capable of compressing both retrieval content and reasoning steps. 1) First, the retrieved content is compressed by augmenting chunk-based semantic retrieval with a graph retrieval using concise triplets. A knowledge association graph is then built from semantic similarity and co-occurrence. Finally, Personalized PageRank is leveraged to highlight key knowledge within this graph, reducing the number of tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative Process-aware Direct Preference Optimization (IP-DPO) is proposed. Specifically, our reward function evaluates the knowledge sufficiency by a knowledge matching mechanism, while penalizing excessive reasoning steps. This design can produce high-quality preference-pair datasets, supporting iterative DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at https://github.com/Applied-Machine-Learning-Lab/TeaRAG.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251105385Z/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37609525",
      "bibcode": "2025arXiv251106179W",
      "title": "MemoriesDB: A Temporal-Semantic-Relational Database for Long-Term Agent Memory / Modeling Experience as a Graph of Temporal-Semantic Surfaces",
      "authors": [
        "Ward, Joel"
      ],
      "year": "2025",
      "abstract": "We introduce MemoriesDB, a unified data architecture designed to avoid decoherence across time, meaning, and relation in long-term computational memory. Each memory is a time-semantic-relational entity-a structure that simultaneously encodes when an event occurred, what it means, and how it connects to other events. Built initially atop PostgreSQL with pgvector extensions, MemoriesDB combines the properties of a time-series datastore, a vector database, and a graph system within a single append-only schema. Each memory is represented as a vertex uniquely labeled by its microsecond timestamp and accompanied by low- and high-dimensional normalized embeddings that capture semantic context. Directed edges between memories form labeled relations with per-edge metadata, enabling multiple contextual links between the same vertices. Together these constructs form a time-indexed stack of temporal-semantic surfaces, where edges project as directional arrows in a 1+1-dimensional similarity field, tracing the evolution of meaning through time while maintaining cross-temporal coherence. This formulation supports efficient time-bounded retrieval, hybrid semantic search, and lightweight structural reasoning in a single query path. A working prototype demonstrates scalable recall and contextual reinforcement using standard relational infrastructure, and we discuss extensions toward a columnar backend, distributed clustering, and emergent topic modeling.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251106179W/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37619702",
      "bibcode": "2025arXiv251111653S",
      "title": "GroupRank: A Groupwise Reranking Paradigm Driven by Reinforcement Learning",
      "authors": [
        "Sun, Duolin",
        "Long, Meixiu",
        "Yang, Dan",
        "Jiao, Yihan",
        "Tan, Zhehao",
        "Feng, Jie",
        "Wang, Junjie",
        "Shen, Yue",
        "Wei, Peng",
        "Wang, Jian",
        "Gu, Jinjie"
      ],
      "year": "2025",
      "abstract": "Large Language Models have shown strong potential as rerankers to enhance the overall performance of RAG systems. However, existing reranking paradigms are constrained by a core theoretical and practical dilemma: Pointwise methods, while simple and highly flexible, evaluate documents independently, making them prone to the Ranking Myopia Trap, overlooking the relative importance between documents. In contrast, Listwise methods can perceive the global ranking context, but suffer from inherent List Rigidity, leading to severe scalability and flexibility issues when handling large candidate sets. To address these challenges, we propose Groupwise, a novel reranking paradigm. In this approach, the query and a group of candidate documents are jointly fed into the model, which performs within-group comparisons to assign individual relevance scores to each document. This design retains the flexibility of Pointwise methods while enabling the comparative capability of Listwise methods. We further adopt GRPO for model training, equipped with a heterogeneous reward function that integrates ranking metrics with a distributional reward aimed at aligning score distributions across groups. To overcome the bottleneck caused by the scarcity of high quality labeled data, we further propose an innovative pipeline for synthesizing high quality retrieval and ranking data. The resulting data can be leveraged not only for training the reranker but also for training the retriever. Extensive experiments validate the effectiveness of our approach. On two reasoning intensive retrieval benchmarks, BRIGHT and R2MED.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251111653S/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37501083",
      "bibcode": "2025arXiv251103217K",
      "title": "Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification",
      "authors": [
        "Kolli, Shaghayegh",
        "Rosenbaum, Richard",
        "Cavelius, Timo",
        "Strothe, Lasse",
        "Lata, Andrii",
        "Diesner, Jana"
      ],
      "year": "2025",
      "abstract": "Large language models (LLMs) excel in generating fluent utterances but can lack reliable grounding in verified information. At the same time, knowledge-graph-based fact-checkers deliver precise and interpretable evidence, yet suffer from limited coverage or latency. By integrating LLMs with knowledge graphs and real-time search agents, we introduce a hybrid fact-checking approach that leverages the individual strengths of each component. Our system comprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid one-hop lookups in DBpedia, 2) an LM-based classification guided by a task-specific labeling prompt, producing outputs with internal rule-based logic, and 3) a Web Search Agent invoked only when KG coverage is insufficient. Our pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the Supported/Refuted split without task-specific fine-tuning. To address Not enough information cases, we conduct a targeted reannotation study showing that our approach frequently uncovers valid evidence for claims originally labeled as Not Enough Information (NEI), as confirmed by both expert annotators and LLM reviewers. With this paper, we present a modular, opensource fact-checking pipeline with fallback strategies and generalization across datasets.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251103217K/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37610601",
      "bibcode": "2025arXiv251107262J",
      "title": "AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning",
      "authors": [
        "Jiang, Qile",
        "Karniadakis, George"
      ],
      "year": "2025",
      "abstract": "Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251107262J/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37618950",
      "bibcode": "2025arXiv251111257Y",
      "title": "AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery",
      "authors": [
        "Yin, Yuqi",
        "Fu, Yibo",
        "Wang, Siyuan",
        "Sun, Peng",
        "Wang, Hongyu",
        "Wang, Xiaohui",
        "Zheng, Lei",
        "Li, Zhiyong",
        "Liu, Zhirong",
        "Wang, Jianji",
        "Sun, Zhaoxi"
      ],
      "year": "2025",
      "abstract": "The discovery of novel Ionic Liquids (ILs) is hindered by critical challenges in property prediction, including limited data, poor model accuracy, and fragmented workflows. Leveraging the power of Large Language Models (LLMs), we introduce AIonopedia, to the best of our knowledge, the first LLM agent for IL discovery. Powered by an LLM-augmented multimodal domain foundation model for ILs, AIonopedia enables accurate property predictions and incorporates a hierarchical search architecture for molecular screening and design. Trained and evaluated on a newly curated and comprehensive IL dataset, our model delivers superior performance. Complementing these results, evaluations on literature-reported systems indicate that the agent can perform effective IL modification. Moving beyond offline tests, the practical efficacy was further confirmed through real-world wet-lab validation, in which the agent demonstrated exceptional generalization capabilities on challenging out-of-distribution tasks, underscoring its ability to accelerate real-world IL discovery.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251111257Y/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37609272",
      "bibcode": "2025arXiv251105933Z",
      "title": "Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs",
      "authors": [
        "Zhang, Renfei",
        "Kaniselvan, Manasa",
        "Mireshghallah, Niloofar"
      ],
      "year": "2025",
      "abstract": "Reinforcement learning (RL) is often credited with improving language model reasoning and generalization at the expense of degrading memorized knowledge. We challenge this narrative by observing that RL-enhanced models consistently outperform their base and supervised fine-tuned (SFT) counterparts on pure knowledge recall tasks, particularly those requiring traversal of hierarchical, structured knowledge (e.g., medical codes). We hypothesize these gains stem not from newly acquired data, but from improved procedural skills in navigating and searching existing knowledge hierarchies within the model parameters. To support this hypothesis, we show that structured prompting, which explicitly guides SFTed models through hierarchical traversal, recovers most of the performance gap (reducing 24pp to 7pp on MedConceptsQA for DeepSeek-V3/R1). We further find that while prompting improves final-answer accuracy, RL-enhanced models retain superior ability to recall correct procedural paths on deep-retrieval tasks. Finally our layer-wise internal activation analysis reveals that while factual representations (e.g., activations for the statement \"code 57.95 refers to urinary infection\") maintain high cosine similarity between SFT and RL models, query representations (e.g., \"what is code 57.95\") diverge noticeably, indicating that RL primarily transforms how models traverse knowledge rather than the knowledge representation itself.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251105933Z/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37611367",
      "bibcode": "2025arXiv251107943X",
      "title": "Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction",
      "authors": [
        "Xu, Jun",
        "Du, Xinkai",
        "Ao, Yu",
        "Zhao, Peilong",
        "Li, Yang",
        "Zhong, Ling",
        "Yuan, Lin",
        "Bo, Zhongpu",
        "Wang, Xiaorui",
        "Sun, Mengshu",
        "Gui, Zhengke",
        "Zhang, Dalong",
        "Wang, Zhaoyang",
        "Wang, Qiwei",
        "Hou, Yangyang",
        "Yin, Zhiying",
        "Wang, Haofen",
        "Chen, Huajun",
        "Liang, Lei",
        "Zhou, Jun"
      ],
      "year": "2025",
      "abstract": "Efficient retrieval of external knowledge bases and web pages is crucial for enhancing the reasoning abilities of LLMs. Previous works on training LLMs to leverage external retrievers for solving complex problems have predominantly employed end-to-end reinforcement learning. However, these approaches neglect supervision over the reasoning process, making it difficult to guarantee logical coherence and rigor. To address these limitations, we propose Thinker, a hierarchical thinking model for deep search through multi-turn interaction, making the reasoning process supervisable and verifiable. It decomposes complex problems into independently solvable sub-problems, each dually represented in both natural language and an equivalent logical function to support knowledge base and web searches. Concurrently, dependencies between sub-problems are passed as parameters via these logical functions, enhancing the logical coherence of the problem-solving process. To avoid unnecessary external searches, we perform knowledge boundary determination to check if a sub-problem is within the LLM's intrinsic knowledge, allowing it to answer directly. Experimental results indicate that with as few as several hundred training samples, the performance of Thinker is competitive with established baselines. Furthermore, when scaled to the full training set, Thinker significantly outperforms these methods across various datasets and model sizes. The source code is available at https://github.com/OpenSPG/KAG-Thinker.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251107943X/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "38058601",
      "bibcode": "2025arXiv251114426O",
      "title": "MiAD: Mirage Atom Diffusion for De Novo Crystal Generation",
      "authors": [
        "Okhotin, Andrey",
        "Nakhodnov, Maksim",
        "Kazeev, Nikita",
        "E Ustyuzhanin, Andrey",
        "Vetrov, Dmitry"
      ],
      "year": "2025",
      "abstract": "In recent years, diffusion-based models have demonstrated exceptional performance in searching for simultaneously stable, unique, and novel (S.U.N.) crystalline materials. However, most of these models don't have the ability to change the number of atoms in the crystal during the generation process, which limits the variability of model sampling trajectories. In this paper, we demonstrate the severity of this restriction and introduce a simple yet powerful technique, mirage infusion, which enables diffusion models to change the state of the atoms that make up the crystal from existent to non-existent (mirage) and vice versa. We show that this technique improves model quality by up to $\\times2.5$ compared to the same model without this modification. The resulting model, Mirage Atom Diffusion (MiAD), is an equivariant joint diffusion model for de novo crystal generation that is capable of altering the number of atoms during the generation process. MiAD achieves an $8.2\\%$ S.U.N. rate on the MP-20 dataset, which substantially exceeds existing state-of-the-art approaches. The source code can be found at \\href{https://github.com/andrey-okhotin/miad.git}{\\texttt{github.com/andrey-okhotin/miad}}.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251114426O/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37499515",
      "bibcode": "2025arXiv251101643C",
      "title": "A Graph-based RAG for Energy Efficiency Question Answering",
      "authors": [
        "Campi, Riccardo",
        "Pinciroli Vago, NicolÃ² Oreste",
        "Giudici, Mathyas",
        "Barrachina Rodriguez-Guisado, Pablo",
        "Brambilla, Marco",
        "Fraternali, Piero"
      ],
      "year": "2025",
      "abstract": "In this work, we investigate the use of Large Language Models (LLMs) within a graph-based Retrieval Augmented Generation (RAG) architecture for Energy Efficiency (EE) Question Answering. First, the system automatically extracts a Knowledge Graph (KG) from guidance and regulatory documents in the energy field. Then, the generated graph is navigated and reasoned upon to provide users with accurate answers in multiple languages. We implement a human-based validation using the RAGAs framework properties, a validation dataset comprising 101 question-answer pairs, and domain experts. Results confirm the potential of this architecture and identify its strengths and weaknesses. Validation results show how the system correctly answers in about three out of four of the cases (75.2 +- 2.7%), with higher results on questions related to more general EE answers (up to 81.0 +- 4.1%), and featuring promising multilingual abilities (4.4% accuracy loss due to translation).",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251101643C/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37609624",
      "bibcode": "2025arXiv251106285H",
      "title": "Exploiting Inter-Session Information with Frequency-enhanced Dual-Path Networks for Sequential Recommendation",
      "authors": [
        "He, Peng",
        "Liu, Yao",
        "Gan, Yanglei",
        "Lin, Run",
        "Dai, Tingting",
        "Liu, Qiao",
        "Li, Xuexin"
      ],
      "year": "2025",
      "abstract": "Sequential recommendation (SR) aims to predict a user's next item preference by modeling historical interaction sequences. Recent advances often integrate frequency-domain modules to compensate for self-attention's low-pass nature by restoring the high-frequency signals critical for personalized recommendations. Nevertheless, existing frequency-aware solutions process each session in isolation and optimize exclusively with time-domain objectives. Consequently, they overlook cross-session spectral dependencies and fail to enforce alignment between predicted and actual spectral signatures, leaving valuable frequency information under-exploited. To this end, we propose FreqRec, a Frequency-Enhanced Dual-Path Network for sequential Recommendation that jointly captures inter-session and intra-session behaviors via a learnable Frequency-domain Multi-layer Perceptrons. Moreover, FreqRec is optimized under a composite objective that combines cross entropy with a frequency-domain consistency loss, explicitly aligning predicted and true spectral signatures. Extensive experiments on three benchmarks show that FreqRec surpasses strong baselines and remains robust under data sparsity and noisy-log conditions.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251106285H/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37610152",
      "bibcode": "2025arXiv251106803Z",
      "title": "Learning to Fast Unrank in Collaborative Filtering Recommendation",
      "authors": [
        "Zhao, Junpeng",
        "Li, Lin",
        "Li, Ming",
        "Bhuiyan, Amran",
        "Huang, Jimmy"
      ],
      "year": "2025",
      "abstract": "Modern data-driven recommendation systems risk memorizing sensitive user behavioral patterns, raising privacy concerns. Existing recommendation unlearning methods, while capable of removing target data influence, suffer from inefficient unlearning speed and degraded performance, failing to meet real-time unlearning demands. Considering the ranking-oriented nature of recommendation systems, we present unranking, the process of reducing the ranking positions of target items while ensuring the formal guarantees of recommendation unlearning. To achieve efficient unranking, we propose Learning to Fast Unrank in Collaborative Filtering Recommendation (L2UnRank), which operates through three key stages: (a) identifying the influenced scope via interaction-based p-hop propagation, (b) computing structural and semantic influences for entities within this scope, and (c) performing efficient, ranking-aware parameter updates guided by influence information. Extensive experiments across multiple datasets and backbone models demonstrate L2UnRank's model-agnostic nature, achieving state-of-the-art unranking effectiveness and maintaining recommendation quality comparable to retraining, while also delivering a 50x speedup over existing methods. Codes are available at https://github.com/Juniper42/L2UnRank.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251106803Z/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "38058442",
      "bibcode": "2025arXiv251114256L",
      "title": "PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models",
      "authors": [
        "Liu, Yu",
        "Lin, Xixun",
        "Shang, Yanmin",
        "Li, Yangxi",
        "Wang, Shi",
        "Cao, Yanan"
      ],
      "year": "2025",
      "abstract": "Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a \"Retrieve-Prioritize-Reason\" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251114256L/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "38059617",
      "bibcode": "2025arXiv251115383J",
      "title": "A Compliance-Preserving Retrieval System for Aircraft MRO Task Search",
      "authors": [
        "Jo, Byungho"
      ],
      "year": "2025",
      "abstract": "Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251115383J/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37500686",
      "bibcode": "2025arXiv251102824M",
      "title": "Kosmos: An AI Scientist for Autonomous Discovery",
      "authors": [
        "Mitchener, Ludovico",
        "Yiu, Angela",
        "Chang, Benjamin",
        "Bourdenx, Mathieu",
        "Nadolski, Tyler",
        "Sulovari, Arvis",
        "Landsness, Eric C.",
        "Barabasi, Daniel L.",
        "Narayanan, Siddharth",
        "Evans, Nicky",
        "Reddy, Shriya",
        "Foiani, Martha",
        "Kamal, Aizad",
        "Shriver, Leah P.",
        "Cao, Fang",
        "Wassie, Asmamaw T.",
        "Laurent, Jon M.",
        "Melville-Green, Edwin",
        "Caldas, Mayk",
        "Bou, Albert",
        "Roberts, Kaleigh F.",
        "Zagorac, Sladjana",
        "Orr, Timothy C.",
        "Orr, Miranda E.",
        "Zwezdaryk, Kevin J.",
        "Ghareeb, Ali E.",
        "McCoy, Laurie",
        "Gomes, Bruna",
        "Ashley, Euan A.",
        "Duff, Karen E.",
        "Buonassisi, Tonio",
        "Rainforth, Tom",
        "Bateman, Randall J.",
        "Skarlinski, Michael",
        "Rodriques, Samuel G.",
        "Hinks, Michaela M.",
        "White, Andrew D."
      ],
      "year": "2025",
      "abstract": "Data-driven scientific discovery requires iterative cycles of literature search, hypothesis generation, and data analysis. Substantial progress has been made towards AI agents that can automate scientific research, but all such agents remain limited in the number of actions they can take before losing coherence, thus limiting the depth of their findings. Here we present Kosmos, an AI scientist that automates data-driven discovery. Given an open-ended objective and a dataset, Kosmos runs for up to 12 hours performing cycles of parallel data analysis, literature search, and hypothesis generation before synthesizing discoveries into scientific reports. Unlike prior systems, Kosmos uses a structured world model to share information between a data analysis agent and a literature search agent. The world model enables Kosmos to coherently pursue the specified objective over 200 agent rollouts, collectively executing an average of 42,000 lines of code and reading 1,500 papers per run. Kosmos cites all statements in its reports with code or primary literature, ensuring its reasoning is traceable. Independent scientists found 79.4% of statements in Kosmos reports to be accurate, and collaborators reported that a single 20-cycle Kosmos run performed the equivalent of 6 months of their own research time on average. Furthermore, collaborators reported that the number of valuable scientific findings generated scales linearly with Kosmos cycles (tested up to 20 cycles). We highlight seven discoveries made by Kosmos that span metabolomics, materials science, neuroscience, and statistical genetics. Three discoveries independently reproduce findings from preprinted or unpublished manuscripts that were not accessed by Kosmos at runtime, while four make novel contributions to the scientific literature.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251102824M/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37571138",
      "bibcode": "2025arXiv251103985Y",
      "title": "ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering",
      "authors": [
        "Yuan, Zhuowen",
        "Liu, Tao",
        "Yang, Yang",
        "Wang, Yang",
        "Qi, Feng",
        "Rangadurai, Kaushik",
        "Li, Bo",
        "Yang, Shuang"
      ],
      "year": "2025",
      "abstract": "Recent LLM-based agents have demonstrated strong capabilities in automated ML engineering. However, they heavily rely on repeated full training runs to evaluate candidate solutions, resulting in significant computational overhead, limited scalability to large search spaces, and slow iteration cycles. To address these challenges, we introduce ArchPilot, a multi-agent system that integrates architecture generation, proxy-based evaluation, and adaptive search into a unified framework. ArchPilot consists of three specialized agents: an orchestration agent that coordinates the search process using a Monte Carlo Tree Search (MCTS)-inspired novel algorithm with a restart mechanism and manages memory of previous candidates; a generation agent that iteratively generates, improves, and debugs candidate architectures; and an evaluation agent that executes proxy training runs, generates and optimizes proxy functions, and aggregates the proxy scores into a fidelity-aware performance metric. This multi-agent collaboration allows ArchPilot to prioritize high-potential candidates with minimal reliance on expensive full training runs, facilitating efficient ML engineering under limited budgets. Experiments on MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE and ML-Master, validating the effectiveness of our multi-agent system.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251103985Y/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37621022",
      "bibcode": "2025arXiv251112971C",
      "title": "Esim: EVM Bytecode Similarity Detection Based on Stable-Semantic Graph",
      "authors": [
        "Chen, Zhuo",
        "Ji, Gaoqiang",
        "He, Yiling",
        "Wu, Lei",
        "Zhou, Yajin"
      ],
      "year": "2025",
      "abstract": "Decentralized finance (DeFi) is experiencing rapid expansion. However, prevalent code reuse and limited open-source contributions have introduced significant challenges to the blockchain ecosystem, including plagiarism and the propagation of vulnerable code. Consequently, an effective and accurate similarity detection method for EVM bytecode is urgently needed to identify similar contracts. Traditional binary similarity detection methods are typically based on instruction stream or control flow graph (CFG), which have limitations on EVM bytecode due to specific features like low-level EVM bytecode and heavily-reused basic blocks. Moreover, the highly-diverse Solidity Compiler (Solc) versions further complicate accurate similarity detection. Motivated by these challenges, we propose a novel EVM bytecode representation called Stable-Semantic Graph (SSG), which captures relationships between 'stable instructions' (special instructions identified by our study). Moreover, we implement a prototype, Esim, which embeds SSG into matrices for similarity detection using a heterogeneous graph neural network. Esim demonstrates high accuracy in SSG construction, achieving F1-scores of 100% for control flow and 95.16% for data flow, and its similarity detection performance reaches 96.3% AUC, surpassing traditional approaches. Our large-scale study, analyzing 2,675,573 smart contracts on six EVM-compatible chains over a one-year period, also demonstrates that Esim outperforms the SOTA tool Etherscan in vulnerability search.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251112971C/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "38059346",
      "bibcode": "2025arXiv251115122Z",
      "title": "Multi-Aspect Cross-modal Quantization for Generative Recommendation",
      "authors": [
        "Zhang, Fuwei",
        "Liu, Xiaoyu",
        "Xi, Dongbo",
        "Yin, Jishen",
        "Chen, Huan",
        "Yan, Peng",
        "Zhuang, Fuzhen",
        "Zhang, Zhao"
      ],
      "year": "2025",
      "abstract": "Generative Recommendation (GR) has emerged as a new paradigm in recommender systems. This approach relies on quantized representations to discretize item features, modeling users' historical interactions as sequences of discrete tokens. Based on these tokenized sequences, GR predicts the next item by employing next-token prediction methods. The challenges of GR lie in constructing high-quality semantic identifiers (IDs) that are hierarchically organized, minimally conflicting, and conducive to effective generative model training. However, current approaches remain limited in their ability to harness multimodal information and to capture the deep and intricate interactions among diverse modalities, both of which are essential for learning high-quality semantic IDs and for effectively training GR models. To address this, we propose Multi-Aspect Cross-modal quantization for generative Recommendation (MACRec), which introduces multimodal information and incorporates it into both semantic ID learning and generative model training from different aspects. Specifically, we first introduce cross-modal quantization during the ID learning process, which effectively reduces conflict rates and thus improves codebook usability through the complementary integration of multimodal information. In addition, to further enhance the generative ability of our GR model, we incorporate multi-aspect cross-modal alignments, including the implicit and explicit alignments. Finally, we conduct extensive experiments on three well-known recommendation datasets to demonstrate the effectiveness of our proposed method.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251115122Z/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "38059646",
      "bibcode": "2025arXiv251115408Z",
      "title": "NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework",
      "authors": [
        "Zhou, Shanlin",
        "Wang, Xinpeng",
        "Lian, Jianxun",
        "Liu, Zhenghao",
        "Lakshmanan, Laks V. S.",
        "Yi, Xiaoyuan",
        "Hao, Yongtao"
      ],
      "year": "2025",
      "abstract": "Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251115408Z/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37621321",
      "bibcode": "2025arXiv251113271C",
      "title": "Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming",
      "authors": [
        "Chen, Rufeng",
        "Jiang, Shuaishuai",
        "Shen, Jiyun",
        "Moon, AJung",
        "Wei, Lili"
      ],
      "year": "2025",
      "abstract": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, intermediate) to examine how students interact with ChatGPT while solving programming tasks. We analyzed task performance, conceptual understanding, and interaction behaviors. Our findings reveal that generating complete solutions with GenAI significantly improves task performance, especially for beginners, but does not consistently result in knowledge gains. Importantly, usage strategies differ by experience: beginners tend to rely heavily on GenAI toward task completion often without knowledge gain in the process, while intermediates adopt more selective approaches. We find that both over-reliance and minimal use result in weaker knowledge gains overall. Based on our results, we call on students and educators to adopt GenAI as a learning rather than a problem solving tool. Our study highlights the urgent need for guidance when integrating GenAI into programming education to foster deeper understanding.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251113271C/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37499138",
      "bibcode": "2025arXiv251101268K",
      "title": "Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems",
      "authors": [
        "Kim, Minseok",
        "Lee, Hankook",
        "Koo, Hyungjoon"
      ],
      "year": "2025",
      "abstract": "Large language models (LLMs) are reshaping numerous facets of our daily lives, leading widespread adoption as web-based services. Despite their versatility, LLMs face notable challenges, such as generating hallucinated content and lacking access to up-to-date information. Lately, to address such limitations, Retrieval-Augmented Generation (RAG) has emerged as a promising direction by generating responses grounded in external knowledge sources. A typical RAG system consists of i) a retriever that probes a group of relevant passages from a knowledge base and ii) a generator that formulates a response based on the retrieved content. However, as with other AI systems, recent studies demonstrate the vulnerability of RAG, such as knowledge corruption attacks by injecting misleading information. In response, several defense strategies have been proposed, including having LLMs inspect the retrieved passages individually or fine-tuning robust retrievers. While effective, such approaches often come with substantial computational costs. In this work, we introduce RAGDefender, a resource-efficient defense mechanism against knowledge corruption (i.e., by data poisoning) attacks in practical RAG deployments. RAGDefender operates during the post-retrieval phase, leveraging lightweight machine learning techniques to detect and filter out adversarial content without requiring additional model training or inference. Our empirical evaluations show that RAGDefender consistently outperforms existing state-of-the-art defenses across multiple models and adversarial scenarios: e.g., RAGDefender reduces the attack success rate (ASR) against the Gemini model from 0.89 to as low as 0.02, compared to 0.69 for RobustRAG and 0.24 for Discern-and-Answer when adversarial passages outnumber legitimate ones by a factor of four (4x).",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251101268K/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37621120",
      "bibcode": "2025arXiv251113057P",
      "title": "Dimension vs. Precision: A Comparative Analysis of Autoencoders and Quantization for Efficient Vector Retrieval on BEIR SciFact",
      "authors": [
        "Pati, Satyanarayan"
      ],
      "year": "2025",
      "abstract": "Dense retrieval models have become a standard for state-of-the-art information retrieval. However, their high-dimensional, high-precision (float32) vector embeddings create significant storage and memory challenges for real-world deployment. To address this, we conduct a rigorous empirical study on the BEIR SciFact benchmark, evaluating the trade-offs between two primary compression strategies: (1) Dimensionality Reduction via deep Autoencoders (AE), reducing original 384-dim vectors to latent spaces from 384 down to 12, and (2) Precision Reduction via Quantization (float16, int8, and binary). We systematically compare each method by measuring the \"performance loss\" (or gain) relative to a float32 baseline across a full suite of retrieval metrics (NDCG, MAP, MRR, Recall, Precision) at various k cutoffs. Our results show that int8 scalar quantization provides the most effective \"sweet spot,\" achieving a 4x compression with a negligible [~1-2%] drop in nDCG@10. In contrast, Autoencoders show a graceful degradation but suffer a more significant performance loss at equivalent 4x compression ratios (AE-96). binary quantization was found to be unsuitable for this task due to catastrophic performance drops. This work provides a practical guide for deploying efficient, high-performance retrieval systems.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251113057P/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "38059669",
      "bibcode": "2025arXiv251115435L",
      "title": "HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation",
      "authors": [
        "Luo, Linyin",
        "Ding, Yujuan",
        "Ma, Yunshan",
        "Fan, Wenqi",
        "Lai, Hanjiang"
      ],
      "year": "2025",
      "abstract": "Advanced multimodal Retrieval-Augmented Generation (MRAG) techniques have been widely applied to enhance the capabilities of Large Multimodal Models (LMMs), but they also bring along novel safety issues. Existing adversarial research has revealed the vulnerability of MRAG systems to knowledge poisoning attacks, which fool the retriever into recalling injected poisoned contents. However, our work considers a different setting: visual attack of MRAG by solely adding imperceptible perturbations at the image inputs of users, without manipulating any other components. This is challenging due to the robustness of fine-tuned retrievers and large-scale generators, and the effect of visual perturbation may be further weakened by propagation through the RAG chain. We propose a novel Hierarchical Visual Attack that misaligns and disrupts the two inputs (the multimodal query and the augmented knowledge) of MRAG's generator to confuse its generation. We further design a hierarchical two-stage strategy to obtain misaligned augmented knowledge. We disrupt the image input of the retriever to make it recall irrelevant knowledge from the original database, by optimizing the perturbation which first breaks the cross-modal alignment and then disrupts the multimodal semantic alignment. We conduct extensive experiments on two widely-used MRAG datasets: OK-VQA and InfoSeek. We use CLIP-based retrievers and two LMMs BLIP-2 and LLaVA as generators. Results demonstrate the effectiveness of our visual attack on MRAG through the significant decrease in both retrieval and generation performance.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251115435L/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37573054",
      "bibcode": "2025arXiv251104720K",
      "title": "Learning to reason about rare diseases through retrieval-augmented agents",
      "authors": [
        "Kim, Ha Young",
        "Li, Jun",
        "Solana, Ana Beatriz",
        "Pirkl, Carolin M.",
        "Wiestler, Benedikt",
        "Schnabel, Julia A.",
        "Bercea, Cosmin I."
      ],
      "year": "2025",
      "abstract": "Rare diseases represent the long tail of medical imaging, where AI models often fail due to the scarcity of representative training data. In clinical workflows, radiologists frequently consult case reports and literature when confronted with unfamiliar findings. Following this line of reasoning, we introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic system for rare disease detection in brain MRI. Our approach uses AI agents with access to external medical knowledge by embedding both case reports and literature using sentence transformers and indexing them with FAISS to enable efficient similarity search. The agent retrieves clinically relevant evidence to guide diagnostic decision making on unseen diseases, without the need of additional training. Designed as a model-agnostic reasoning module, RADAR can be seamlessly integrated with diverse large language models, consistently improving their rare pathology recognition and interpretability. On the NOVA dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2% performance gain, with the strongest improvements observed for open source models such as DeepSeek. Beyond accuracy, the retrieved examples provide interpretable, literature grounded explanations, highlighting retrieval-augmented reasoning as a powerful paradigm for low-prevalence conditions in medical imaging.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251104720K/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37620969",
      "bibcode": "2025arXiv251112922H",
      "title": "Tokenize Once, Recommend Anywhere: Unified Item Tokenization for Multi-domain LLM-based Recommendation",
      "authors": [
        "Hou, Yu",
        "Shin, Won-Yong"
      ],
      "year": "2025",
      "abstract": "Large language model (LLM)-based recommender systems have achieved high-quality performance by bridging the discrepancy between the item space and the language space through item tokenization. However, existing item tokenization methods typically require training separate models for each item domain, limiting generalization. Moreover, the diverse distributions and semantics across item domains make it difficult to construct a unified tokenization that preserves domain-specific information. To address these challenges, we propose UniTok, a Unified item Tokenization framework that integrates our own mixture-of-experts (MoE) architecture with a series of codebooks to convert items into discrete tokens, enabling scalable tokenization while preserving semantic information across multiple item domains. Specifically, items from different domains are first projected into a unified latent space through a shared encoder. They are then routed to domain-specific experts to capture the unique semantics, while a shared expert, which is always active, encodes common knowledge transferable across domains. Additionally, to mitigate semantic imbalance across domains, we present a mutual information calibration mechanism, which guides the model towards retaining similar levels of semantic information for each domain. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed UniTok framework is (a) highly effective: achieving up to 51.89% improvements over strong benchmarks, (b) theoretically sound: showing the analytical validity of our architectural design and optimization; and (c) highly generalizable: demonstrating robust performance across diverse domains without requiring per-domain retraining, a capability not supported by existing baselines.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251112922H/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37499717",
      "bibcode": "2025arXiv251101857E",
      "title": "Trove: A Flexible Toolkit for Dense Retrieval",
      "authors": [
        "Esfandiarpoor, Reza",
        "Zuo, Max",
        "Bach, Stephen H."
      ],
      "year": "2025",
      "abstract": "We introduce Trove, an easy-to-use open-source retrieval toolkit that simplifies research experiments without sacrificing flexibility or speed. For the first time, we introduce efficient data management features that load and process (filter, select, transform, and combine) retrieval datasets on the fly, with just a few lines of code. This gives users the flexibility to easily experiment with different dataset configurations without the need to compute and store multiple copies of large datasets. Trove is highly customizable: in addition to many built-in options, it allows users to freely modify existing components or replace them entirely with user-defined objects. It also provides a low-code and unified pipeline for evaluation and hard negative mining, which supports multi-node execution without any code changes. Trove's data management features reduce memory consumption by a factor of 2.6. Moreover, Trove's easy-to-use inference pipeline incurs no overhead, and inference times decrease linearly with the number of available nodes. Most importantly, we demonstrate how Trove simplifies retrieval experiments and allows for arbitrary customizations, thus facilitating exploratory research.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251101857E/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.611Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37621215",
      "bibcode": "2025arXiv251113166S",
      "title": "Local Collaborative Filtering: A Collaborative Filtering Method that Utilizes Local Similarities among Users",
      "authors": [
        "Shen, Zhaoxin",
        "Wu, Dan"
      ],
      "year": "2025",
      "abstract": "To leverage user behavior data from the Internet more effectively in recommender systems, this paper proposes a novel collaborative filtering (CF) method called Local Collaborative Filtering (LCF). LCF utilizes local similarities among users and integrates their data using the law of large numbers (LLN), thereby improving the utilization of user behavior data. Experiments are conducted on the Steam game dataset, and the results of LCF align with real-world needs.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251113166S/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37571275",
      "bibcode": "2025arXiv251104137L",
      "title": "Learning from Online Videos at Inference Time for Computer-Use Agents",
      "authors": [
        "Liu, Yujian",
        "Wang, Ze",
        "Chen, Hao",
        "Sun, Ximeng",
        "Yu, Xiaodong",
        "Wu, Jialian",
        "Liu, Jiang",
        "Barsoum, Emad",
        "Liu, Zicheng",
        "Chang, Shiyu"
      ],
      "year": "2025",
      "abstract": "Computer-use agents can operate computers and automate laborious tasks, but despite recent rapid progress, they still lag behind human users, especially when tasks require domain-specific procedural knowledge about particular applications, platforms, and multi-step workflows. Humans can bridge this gap by watching video tutorials: we search, skim, and selectively imitate short segments that match our current subgoal. In this paper, we study how to enable computer-use agents to learn from online videos at inference time effectively. We propose a framework that retrieves and filters tutorial videos, converts them into structured demonstration trajectories, and dynamically selects trajectories as in-context guidance during execution. Particularly, using a VLM, we infer UI actions, segment videos into short subsequences of actions, and assign each subsequence a textual objective. At inference time, a two-stage selection mechanism dynamically chooses a single trajectory to add in context at each step, focusing the agent on the most helpful local guidance for its next decision. Experiments on two widely used benchmarks show that our framework consistently outperforms strong base agents and variants that use only textual tutorials or transcripts. Analyses highlight the importance of trajectory segmentation and selection, action filtering, and visual information, suggesting that abundant online videos can be systematically distilled into actionable guidance that improves computer-use agents at inference time. Our code is available at https://github.com/UCSB-NLP-Chang/video_demo.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251104137L/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37620972",
      "bibcode": "2025arXiv251112920H",
      "title": "Auditing Google's AI Overviews and Featured Snippets: A Case Study on Baby Care and Pregnancy",
      "authors": [
        "Hu, Desheng",
        "Baumann, Joachim",
        "Urman, Aleksandra",
        "Lichtenegger, Elsa",
        "Forsberg, Robin",
        "Hannak, Aniko",
        "Wilson, Christo"
      ],
      "year": "2025",
      "abstract": "Google Search increasingly surfaces AI-generated content through features like AI Overviews (AIO) and Featured Snippets (FS), which users frequently rely on despite having no control over their presentation. Through a systematic algorithm audit of 1,508 real baby care and pregnancy-related queries, we evaluate the quality and consistency of these information displays. Our robust evaluation framework assesses multiple quality dimensions, including answer consistency, relevance, presence of medical safeguards, source categories, and sentiment alignment. Our results reveal concerning gaps in information consistency, with information in AIO and FS displayed on the same search result page being inconsistent with each other in 33% of cases. Despite high relevance scores, both features critically lack medical safeguards (present in just 11% of AIO and 7% of FS responses). While health and wellness websites dominate source categories for both, AIO and FS, FS also often link to commercial sources. These findings have important implications for public health information access and demonstrate the need for stronger quality controls in AI-mediated health information. Our methodology provides a transferable framework for auditing AI systems across high-stakes domains where information quality directly impacts user well-being.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251112920H/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37621466",
      "bibcode": "2025arXiv251113418B",
      "title": "Exploring Multi-Table Retrieval Through Iterative Search",
      "authors": [
        "Boutaleb, Allaa",
        "Amann, Bernd",
        "Angarita, Rafael",
        "Naacke, Hubert"
      ],
      "year": "2025",
      "abstract": "Open-domain question answering over datalakes requires retrieving and composing information from multiple tables, a challenging subtask that demands semantic relevance and structural coherence (e.g., joinability). While exact optimization methods like Mixed-Integer Programming (MIP) can ensure coherence, their computational complexity is often prohibitive. Conversely, simpler greedy heuristics that optimize for query coverage alone often fail to find these coherent, joinable sets. This paper frames multi-table retrieval as an iterative search process, arguing this approach offers advantages in scalability, interpretability, and flexibility. We propose a general framework and a concrete instantiation: a fast, effective Greedy Join-Aware Retrieval algorithm that holistically balances relevance, coverage, and joinability. Experiments across 5 NL2SQL benchmarks demonstrate that our iterative method achieves competitive retrieval performance compared to the MIP-based approach while being 4-400x faster depending on the benchmark and search space settings. This work highlights the potential of iterative heuristics for practical, scalable, and composition-aware retrieval.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251113418B/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37608894",
      "bibcode": "2025arXiv251105549W",
      "title": "AGRAG: Advanced Graph-based Retrieval-Augmented Generation for LLMs",
      "authors": [
        "Wang, Yubo",
        "Li, Haoyang",
        "Teng, Fei",
        "Chen, Lei"
      ],
      "year": "2025",
      "abstract": "Graph-based retrieval-augmented generation (Graph-based RAG) has demonstrated significant potential in enhancing Large Language Models (LLMs) with structured knowledge. However, existing methods face three critical challenges: Inaccurate Graph Construction, caused by LLM hallucination; Poor Reasoning Ability, caused by failing to generate explicit reasons telling LLM why certain chunks were selected; and Inadequate Answering, which only partially answers the query due to the inadequate LLM reasoning, making their performance lag behind NaiveRAG on certain tasks. To address these issues, we propose AGRAG, an advanced graph-based retrieval-augmented generation framework. When constructing the graph, AGRAG substitutes the widely used LLM entity extraction method with a statistics-based method, avoiding hallucination and error propagation. When retrieval, AGRAG formulates the graph reasoning procedure as the Minimum Cost Maximum Influence (MCMI) subgraph generation problem, where we try to include more nodes with high influence score, but with less involving edge cost, to make the generated reasoning paths more comprehensive. We prove this problem to be NP-hard, and propose a greedy algorithm to solve it. The MCMI subgraph generated can serve as explicit reasoning paths to tell LLM why certain chunks were retrieved, thereby making the LLM better focus on the query-related part contents of the chunks, reducing the impact of noise, and improving AGRAG's reasoning ability. Furthermore, compared with the simple tree-structured reasoning paths, our MCMI subgraph can allow more complex graph structures, such as cycles, and improve the comprehensiveness of the generated reasoning paths.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251105549W/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37499248",
      "bibcode": "2025arXiv251101386Y",
      "title": "RAGSmith: A Framework for Finding the Optimal Composition of Retrieval-Augmented Generation Methods Across Datasets",
      "authors": [
        "Yusuf Kartal, Muhammed",
        "Kagan Kose, Suha",
        "SevinÃ§, Korhan",
        "Aktas, Burak"
      ],
      "year": "2025",
      "abstract": "Retrieval-Augmented Generation (RAG) quality depends on many interacting choices across retrieval, ranking, augmentation, prompting, and generation, so optimizing modules in isolation is brittle. We introduce RAGSmith, a modular framework that treats RAG design as an end-to-end architecture search over nine technique families and 46{,}080 feasible pipeline configurations. A genetic search optimizes a scalar objective that jointly aggregates retrieval metrics (recall@k, mAP, nDCG, MRR) and generation metrics (LLM-Judge and semantic similarity). We evaluate on six Wikipedia-derived domains (Mathematics, Law, Finance, Medicine, Defense Industry, Computer Science), each with 100 questions spanning factual, interpretation, and long-answer types. RAGSmith finds configurations that consistently outperform naive RAG baseline by +3.8\\% on average (range +1.2\\% to +6.9\\% across domains), with gains up to +12.5\\% in retrieval and +7.5\\% in generation. The search typically explores $\\approx 0.2\\%$ of the space ($\\sim 100$ candidates) and discovers a robust backbone -- vector retrieval plus post-generation reflection/revision -- augmented by domain-dependent choices in expansion, reranking, augmentation, and prompt reordering; passage compression is never selected. Improvement magnitude correlates with question type, with larger gains on factual/long-answer mixes than interpretation-heavy sets. These results provide practical, domain-aware guidance for assembling effective RAG systems and demonstrate the utility of evolutionary search for full-pipeline optimization.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251101386Y/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "38058638",
      "bibcode": "2025arXiv251114461W",
      "title": "Effective Diversification of Multi-Carousel Book Recommendation",
      "authors": [
        "Wilten, DaniÃ«l",
        "Maillette de Buy Wenniger, Gideon",
        "Hommersom, Arjen",
        "Lucassen, Paul",
        "Poortman, Emiel"
      ],
      "year": "2025",
      "abstract": "Using multiple carousels, lists that wrap around and can be scrolled, is the basis for offering content in most contemporary movie streaming platforms. Carousels allow for highlighting different aspects of users' taste, that fall in categories such as genres and authors. However, while carousels offer structure and greater ease of navigation, they alone do not increase diversity in recommendations, while this is essential to keep users engaged. In this work we propose several approaches to effectively increase item diversity within the domain of book recommendations, on top of a collaborative filtering algorithm. These approaches are intended to improve book recommendations in the web catalogs of public libraries. Furthermore, we introduce metrics to evaluate the resulting strategies, and show that the proposed system finds a suitable balance between accuracy and beyond-accuracy aspects.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251114461W/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37611597",
      "bibcode": "2025arXiv251108181C",
      "title": "MARC: Multimodal and Multi-Task Agentic Retrieval-Augmented Generation for Cold-Start Recommender System",
      "authors": [
        "Cho, Seung Hwan",
        "Yang, Yujin",
        "Baeck, Danik",
        "Kim, Minjoo",
        "Kim, Young-Min",
        "Lee, Heejung",
        "Park, Sangjin"
      ],
      "year": "2025",
      "abstract": "Recommender systems (RS) are currently being studied to mitigate limitations during cold-start conditions by leveraging modality information or introducing Agent concepts based on the exceptional reasoning capabilities of Large Language Models (LLMs). Meanwhile, food and beverage recommender systems have traditionally used knowledge graph and ontology concepts due to the domain's unique data attributes and relationship characteristics. On this background, we propose MARC, a multimodal and multi-task cocktail recommender system based on Agentic Retrieval-Augmented Generation (RAG) utilizing graph database under cold-start conditions. The proposed system generates high-quality, contextually appropriate answers through two core processes: a task recognition router and a reflection process. The graph database was constructed by processing cocktail data from Kaggle, and its effectiveness was evaluated using 200 manually crafted questions. The evaluation used both LLM-as-a-judge and human evaluation to demonstrate that answers generated via the graph database outperformed those from a simple vector database in terms of quality. The code is available at https://github.com/diddbwls/cocktail_rec_agentrag",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251108181C/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37611792",
      "bibcode": "2025arXiv251108378W",
      "title": "Bid Farewell to Seesaw: Towards Accurate Long-tail Session-based Recommendation via Dual Constraints of Hybrid Intents",
      "authors": [
        "Wang, Xiao",
        "Qin, Ke",
        "Zhang, Dongyang",
        "Xie, Xiurui",
        "Liang, Shuang"
      ],
      "year": "2025",
      "abstract": "Session-based recommendation (SBR) aims to predict anonymous users' next interaction based on their interaction sessions. In the practical recommendation scenario, low-exposure items constitute the majority of interactions, creating a long-tail distribution that severely compromises recommendation diversity. Existing approaches attempt to address this issue by promoting tail items but incur accuracy degradation, exhibiting a \"see-saw\" effect between long-tail and accuracy performance. We attribute such conflict to session-irrelevant noise within the tail items, which existing long-tail approaches fail to identify and constrain effectively. To resolve this fundamental conflict, we propose \\textbf{HID} (\\textbf{H}ybrid \\textbf{I}ntent-based \\textbf{D}ual Constraint Framework), a plug-and-play framework that transforms the conventional \"see-saw\" into \"win-win\" through introducing the hybrid intent-based dual constraints for both long-tail and accuracy. Two key innovations are incorporated in this framework: (i) \\textit{Hybrid Intent Learning}, where we reformulate the intent extraction strategies by employing attribute-aware spectral clustering to reconstruct the item-to-intent mapping. Furthermore, discrimination of session-irrelevant noise is achieved through the assignment of the target and noise intents to each session. (ii) \\textit{Intent Constraint Loss}, which incorporates two novel constraint paradigms regarding the \\textit{diversity} and \\textit{accuracy} to regulate the representation learning process of both items and sessions. These two objectives are unified into a single training loss through rigorous theoretical derivation. Extensive experiments across multiple SBR models and datasets demonstrate that HID can enhance both long-tail performance and recommendation accuracy, establishing new state-of-the-art performance in long-tail recommender systems.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251108378W/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37610281",
      "bibcode": "2025arXiv251106937H",
      "title": "Fine-Tuning Diffusion-Based Recommender Systems via Reinforcement Learning with Reward Function Optimization",
      "authors": [
        "Hou, Yu",
        "Li, Hua",
        "Kim, Ha Young",
        "Shin, Won-Yong"
      ],
      "year": "2025",
      "abstract": "Diffusion models recently emerged as a powerful paradigm for recommender systems, offering state-of-the-art performance by modeling the generative process of user-item interactions. However, training such models from scratch is both computationally expensive and yields diminishing returns once convergence is reached. To remedy these challenges, we propose ReFiT, a new framework that integrates Reinforcement learning (RL)-based Fine-Tuning into diffusion-based recommender systems. In contrast to prior RL approaches for diffusion models depending on external reward models, ReFiT adopts a task-aligned design: it formulates the denoising trajectory as a Markov decision process (MDP) and incorporates a collaborative signal-aware reward function that directly reflects recommendation quality. By tightly coupling the MDP structure with this reward signal, ReFiT empowers the RL agent to exploit high-order connectivity for fine-grained optimization, while avoiding the noisy or uninformative feedback common in naive reward designs. Leveraging policy gradient optimization, ReFiT maximizes exact log-likelihood of observed interactions, thereby enabling effective post hoc fine-tuning of diffusion recommenders. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed ReFiT framework (a) exhibits substantial performance gains over strong competitors (up to 36.3% on sequential recommendation), (b) demonstrates strong efficiency with linear complexity in the number of users or items, and (c) generalizes well across multiple diffusion-based recommendation scenarios. The source code and datasets are publicly available at https://anonymous.4open.science/r/ReFiT-4C60.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251106937H/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37618963",
      "bibcode": "2025arXiv251111265R",
      "title": "SQuaD: The Software Quality Dataset",
      "authors": [
        "Robredo, Mikel",
        "Esposito, Matteo",
        "Taibi, Davide",
        "PeÃ±aloza, Rafael",
        "Lenarduzzi, Valentina"
      ],
      "year": "2025",
      "abstract": "Software quality research increasingly relies on large-scale datasets that measure both the product and process aspects of software systems. However, existing resources often focus on limited dimensions, such as code smells, technical debt, or refactoring activity, thereby restricting comprehensive analyses across time and quality dimensions. To address this gap, we present the Software Quality Dataset (SQuaD), a multi-dimensional, time-aware collection of software quality metrics extracted from 450 mature open-source projects across diverse ecosystems, including Apache, Mozilla, FFmpeg, and the Linux kernel. By integrating nine state-of-the-art static analysis tools, i.e., SonarQube, CodeScene, PMD, Understand, CK, JaSoMe, RefactoringMiner, RefactoringMiner++, and PyRef, our dataset unifies over 700 unique metrics at method, class, file, and project levels. Covering a total of 63,586 analyzed project releases, SQuaD also provides version control and issue-tracking histories, software vulnerability data (CVE/CWE), and process metrics proven to enhance Just-In-Time (JIT) defect prediction. The SQuaD enables empirical research on maintainability, technical debt, software evolution, and quality assessment at unprecedented scale. We also outline emerging research directions, including automated dataset updates and cross-project quality modeling to support the continuous evolution of software analytics. The dataset is publicly available on ZENODO (DOI: 10.5281/zenodo.17566690).",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251111265R/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37618876",
      "bibcode": "2025arXiv251111172S",
      "title": "Enhancing Group Recommendation using Soft Impute Singular Value Decomposition",
      "authors": [
        "Sani Ibrahim, Mubaraka",
        "Saidu, Isah Charles",
        "Csato, Lehel"
      ],
      "year": "2025",
      "abstract": "The growing popularity of group activities increased the need to develop methods for providing recommendations to a group of users based on the collective preferences of the group members. Several group recommender systems have been proposed, but these methods often struggle due to sparsity and high-dimensionality of the available data, common in many real-world applications. In this paper, we propose a group recommender system called Group Soft-Impute SVD, which leverages soft-impute singular value decomposition to enhance group recommendations. This approach addresses the challenge of sparse high-dimensional data using low-rank matrix completion. We compared the performance of Group Soft-Impute SVD with Group MF based approaches and found that our method outperforms the baselines in recall for small user groups while achieving comparable results across all group sizes when tasked on Goodbooks, Movielens, and Synthetic datasets. Furthermore, our method recovers lower matrix ranks than the baselines, demonstrating its effectiveness in handling high-dimensional data.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251111172S/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37616840",
      "bibcode": "2025arXiv251110585E",
      "title": "Textual understanding boost in the WikiRace",
      "authors": [
        "Ebrahimi, Raman",
        "Fuhrman, Sean",
        "Nguyen, Kendrick",
        "Gurusankar, Harini",
        "Franceschetti, Massimo"
      ],
      "year": "2025",
      "abstract": "The WikiRace game, where players navigate between Wikipedia articles using only hyperlinks, serves as a compelling benchmark for goal-directed search in complex information networks. This paper presents a systematic evaluation of navigation strategies for this task, comparing agents guided by graph-theoretic structure (betweenness centrality), semantic meaning (language model embeddings), and hybrid approaches. Through rigorous benchmarking on a large Wikipedia subgraph, we demonstrate that a purely greedy agent guided by the semantic similarity of article titles is overwhelmingly effective. This strategy, when combined with a simple loop-avoidance mechanism, achieved a perfect success rate and navigated the network with an efficiency an order of magnitude better than structural or hybrid methods. Our findings highlight the critical limitations of purely structural heuristics for goal-directed search and underscore the transformative potential of large language models to act as powerful, zero-shot semantic navigators in complex information spaces.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251110585E/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37618734",
      "bibcode": "2025arXiv251111043N",
      "title": "Autonomous Vehicle Path Planning by Searching With Differentiable Simulation",
      "authors": [
        "Nachkov, Asen",
        "Zaech, Jan-Nico",
        "Pani Paudel, Danda",
        "Wang, Xi",
        "Van Gool, Luc"
      ],
      "year": "2025",
      "abstract": "Planning allows an agent to safely refine its actions before executing them in the real world. In autonomous driving, this is crucial to avoid collisions and navigate in complex, dense traffic scenarios. One way to plan is to search for the best action sequence. However, this is challenging when all necessary components - policy, next-state predictor, and critic - have to be learned. Here we propose Differentiable Simulation for Search (DSS), a framework that leverages the differentiable simulator Waymax as both a next state predictor and a critic. It relies on the simulator's hardcoded dynamics, making state predictions highly accurate, while utilizing the simulator's differentiability to effectively search across action sequences. Our DSS agent optimizes its actions using gradient descent over imagined future trajectories. We show experimentally that DSS - the combination of planning gradients and stochastic search - significantly improves tracking and path planning accuracy compared to sequence prediction, imitation learning, model-free RL, and other planning methods.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251111043N/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37499387",
      "bibcode": "2025arXiv251101527X",
      "title": "TPS-Bench: Evaluating AI Agents' Tool Planning \\&amp; Scheduling Abilities in Compounding Tasks",
      "authors": [
        "Xu, Hanwen",
        "Huang, Xuyao",
        "Liu, Yuzhe",
        "Yu, Kai",
        "Deng, Zhijie"
      ],
      "year": "2025",
      "abstract": "Large language model (LLM) agents have exhibited strong problem-solving competence across domains like research and coding. Yet, it remains underexplored whether LLM agents can tackle compounding real-world problems that require a diverse set of tools to complete. Given a broad, heterogeneous tool repository, LLM agents must not only select appropriate tools based on task planning analysis but also strategically schedule the execution order to ensure efficiency. This paper introduces TPS-Bench to benchmark the ability of LLM agents in solving such problems that demand Tool Planning and Scheduling. TPS-Bench collects 200 compounding tasks of two difficulty levels, based on a tool repository containing hundreds of model context protocol (MCP) tools. In particular, each task is composed of multiple subtasks, such as web search, map navigation, calendar checking, etc., and each subtask can be completed by a basic tool. Our evaluation emphasizes both task completion rate and efficiency. The empirical studies on popular closed-source and open-source LLMs indicate that most models can perform reasonable tool planning, but differ in scheduling. For example, GLM-4.5 achieves an outperforming task completion rate of 64.72% with extensive sequential tool calls, hence suffering from significantly long execution time. By contrast, GPT-4o prioritizes parallel tool calls but achieves only a 45.08% completion rate. Considering reinforcement learning (RL) can be a viable way to improve the scheduling efficiency without compromising performance, we perform an initial study on Qwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in task completion rate based on rarely 100 RL training samples. Our code is available https://github.com/hanwenxu1/mcp-agent.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251101527X/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37611102",
      "bibcode": "2025arXiv251107678A",
      "title": "AIA Forecaster: Technical Report",
      "authors": [
        "Alur, Rohan",
        "Stadie, Bradly C.",
        "Kang, Daniel",
        "Chen, Ryan",
        "McManus, Matt",
        "Rickert, Michael",
        "Lee, Tyler",
        "Federici, Michael",
        "Zhu, Richard",
        "Fogerty, Dennis",
        "Williamson, Hayley",
        "Lozinski, Nina",
        "Linsky, Aaron",
        "Sekhon, Jasjeet S."
      ],
      "year": "2025",
      "abstract": "This technical report describes the AIA Forecaster, a Large Language Model (LLM)-based system for judgmental forecasting using unstructured data. The AIA Forecaster approach combines three core elements: agentic search over high-quality news sources, a supervisor agent that reconciles disparate forecasts for the same event, and a set of statistical calibration techniques to counter behavioral biases in large language models. On the ForecastBench benchmark (Karger et al., 2024), the AIA Forecaster achieves performance equal to human superforecasters, surpassing prior LLM baselines. In addition to reporting on ForecastBench, we also introduce a more challenging forecasting benchmark sourced from liquid prediction markets. While the AIA Forecaster underperforms market consensus on this benchmark, an ensemble combining AIA Forecaster with market consensus outperforms consensus alone, demonstrating that our forecaster provides additive information. Our work establishes a new state of the art in AI forecasting and provides practical, transferable recommendations for future research. To the best of our knowledge, this is the first work that verifiably achieves expert-level forecasting at scale.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251107678A/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37609724",
      "bibcode": "2025arXiv251106388L",
      "title": "HyMoERec: Hybrid Mixture-of-Experts for Sequential Recommendation",
      "authors": [
        "Li, Kunrong",
        "Sun, Zhu",
        "Lim, Kwan Hui"
      ],
      "year": "2025",
      "abstract": "We propose HyMoERec, a novel sequential recommendation framework that addresses the limitations of uniform Position-wise Feed-Forward Networks in existing models. Current approaches treat all user interactions and items equally, overlooking the heterogeneity in user behavior patterns and diversity in item complexity. HyMoERec initially introduces a hybrid mixture-of-experts architecture that combines shared and specialized expert branches with an adaptive expert fusion mechanism for the sequential recommendation task. This design captures diverse reasoning for varied users and items while ensuring stable training. Experiments on MovieLens-1M and Beauty datasets demonstrate that HyMoERec consistently outperforms state-of-the-art baselines.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251106388L/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37573806",
      "bibcode": "2025arXiv251105489P",
      "title": "TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning",
      "authors": [
        "Pan, Junwen",
        "Zhang, Qizhe",
        "Zhang, Rui",
        "Lu, Ming",
        "Wan, Xin",
        "Zhang, Yuan",
        "Liu, Chang",
        "She, Qi"
      ],
      "year": "2025",
      "abstract": "Temporal search aims to identify a minimal set of relevant frames from tens of thousands based on a given query, serving as a foundation for accurate long-form video understanding. Existing works attempt to progressively narrow the search space. However, these approaches typically rely on a hand-crafted search process, lacking end-to-end optimization for learning optimal search strategies. In this paper, we propose TimeSearch-R, which reformulates temporal search as interleaved text-video thinking, seamlessly integrating searching video clips into the reasoning process through reinforcement learning (RL). However, applying RL training methods, such as Group Relative Policy Optimization (GRPO), to video reasoning can result in unsupervised intermediate search decisions. This leads to insufficient exploration of the video content and inconsistent logical reasoning. To address these issues, we introduce GRPO with Completeness Self-Verification (GRPO-CSV), which gathers searched video frames from the interleaved reasoning process and utilizes the same policy model to verify the adequacy of searched frames, thereby improving the completeness of video reasoning. Additionally, we construct datasets specifically designed for the SFT cold-start and RL training of GRPO-CSV, filtering out samples with weak temporal dependencies to enhance task difficulty and improve temporal search capabilities. Extensive experiments demonstrate that TimeSearch-R achieves significant improvements on temporal search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as long-form video understanding benchmarks like VideoMME and MLVU. Notably, TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1% improvement over the base model Qwen2.5-VL and 2.0% over the advanced video reasoning model Video-R1. Our code is available at https://github.com/Time-Search/TimeSearch-R.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251105489P/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37500739",
      "bibcode": "2025arXiv251102864G",
      "title": "Mathematical exploration and discovery at scale",
      "authors": [
        "Georgiev, Bogdan",
        "GÃ³mez-Serrano, Javier",
        "Tao, Terence",
        "Wagner, Adam Zsolt"
      ],
      "year": "2025",
      "abstract": "AlphaEvolve is a generic evolutionary coding agent that combines the generative capabilities of LLMs with automated evaluation in an iterative evolutionary framework that proposes, tests, and refines algorithmic solutions to challenging scientific and practical problems. In this paper we showcase AlphaEvolve as a tool for autonomously discovering novel mathematical constructions and advancing our understanding of long-standing open problems. To demonstrate its breadth, we considered a list of 67 problems spanning mathematical analysis, combinatorics, geometry, and number theory. The system rediscovered the best known solutions in most of the cases and discovered improved solutions in several. In some instances, AlphaEvolve is also able to generalize results for a finite number of input values into a formula valid for all input values. Furthermore, we are able to combine this methodology with Deep Think and AlphaProof in a broader framework where the additional proof-assistants and reasoning systems provide automated proof generation and further mathematical insights. These results demonstrate that large language model-guided evolutionary search can autonomously discover mathematical constructions that complement human intuition, at times matching or even improving the best known results, highlighting the potential for significant new ways of interaction between mathematicians and AI systems. We present AlphaEvolve as a powerful new tool for mathematical discovery, capable of exploring vast search spaces to solve complex optimization problems at scale, often with significantly reduced requirements on preparation and computation time.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251102864G/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37571015",
      "bibcode": "2025arXiv251103878P",
      "title": "KnowThyself: An Agentic Assistant for LLM Interpretability",
      "authors": [
        "Prasai, Suraj",
        "Du, Mengnan",
        "Zhang, Ying",
        "Yang, Fan"
      ],
      "year": "2025",
      "abstract": "We develop KnowThyself, an agentic assistant that advances large language model (LLM) interpretability. Existing tools provide useful insights but remain fragmented and code-intensive. KnowThyself consolidates these capabilities into a chat-based interface, where users can upload models, pose natural language questions, and obtain interactive visualizations with guided explanations. At its core, an orchestrator LLM first reformulates user queries, an agent router further directs them to specialized modules, and the outputs are finally contextualized into coherent explanations. This design lowers technical barriers and provides an extensible platform for LLM inspection. By embedding the whole process into a conversational workflow, KnowThyself offers a robust foundation for accessible LLM interpretability.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251103878P/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37609266",
      "bibcode": "2025arXiv251105919F",
      "title": "Injecting Falsehoods: Adversarial Man-in-the-Middle Attacks Undermining Factual Recall in LLMs",
      "authors": [
        "Fastowski, Alina",
        "Prenkaj, Bardh",
        "Li, Yuxiao",
        "Kasneci, Gjergji"
      ],
      "year": "2025",
      "abstract": "LLMs are now an integral part of information retrieval. As such, their role as question answering chatbots raises significant concerns due to their shown vulnerability to adversarial man-in-the-middle (MitM) attacks. Here, we propose the first principled attack evaluation on LLM factual memory under prompt injection via Xmera, our novel, theory-grounded MitM framework. By perturbing the input given to \"victim\" LLMs in three closed-book and fact-based QA settings, we undermine the correctness of the responses and assess the uncertainty of their generation process. Surprisingly, trivial instruction-based attacks report the highest success rate (up to ~85.3%) while simultaneously having a high uncertainty for incorrectly answered questions. To provide a simple defense mechanism against Xmera, we train Random Forest classifiers on the response uncertainty levels to distinguish between attacked and unattacked queries (average AUC of up to ~96%). We believe that signaling users to be cautious about the answers they receive from black-box and potentially corrupt LLMs is a first checkpoint toward user cyberspace safety.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251105919F/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37573615",
      "bibcode": "2025arXiv251105271H",
      "title": "DeepEyesV2: Toward Agentic Multimodal Model",
      "authors": [
        "Hong, Jack",
        "Zhao, Chenxiao",
        "Zhu, ChengLin",
        "Lu, Weiheng",
        "Xu, Guohai",
        "Yu, Xing"
      ],
      "year": "2025",
      "abstract": "Agentic multimodal models should not only comprehend text and images, but also actively invoke external tools, such as code execution environments and web search, and integrate these operations into reasoning. In this work, we introduce DeepEyesV2 and explore how to build an agentic multimodal model from the perspectives of data construction, training methods, and model evaluation. We observe that direct reinforcement learning alone fails to induce robust tool-use behavior. This phenomenon motivates a two-stage training pipeline: a cold-start stage to establish tool-use patterns, and reinforcement learning stage to further refine tool invocation. We curate a diverse, moderately challenging training dataset, specifically including examples where tool use is beneficial. We further introduce RealX-Bench, a comprehensive benchmark designed to evaluate real-world multimodal reasoning, which inherently requires the integration of multiple capabilities, including perception, search, and reasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative benchmarks, demonstrating its effectiveness across real-world understanding, mathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2 exhibits task-adaptive tool invocation, tending to use image operations for perception tasks and numerical computations for reasoning tasks. Reinforcement learning further enables complex tool combinations and allows model to selectively invoke tools based on context. We hope our study can provide guidance for community in developing agentic multimodal models.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251105271H/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37619842",
      "bibcode": "2025arXiv251111788S",
      "title": "MALBO: Optimizing LLM-Based Multi-Agent Teams via Multi-Objective Bayesian Optimization",
      "authors": [
        "Sabbatella, Antonio"
      ],
      "year": "2025",
      "abstract": "The optimal assignment of Large Language Models (LLMs) to specialized roles in multi-agent systems is a significant challenge, defined by a vast combinatorial search space, expensive black-box evaluations, and an inherent trade-off between performance and cost. Current optimization methods focus on single-agent settings and lack a principled framework for this multi-agent, multi-objective problem. This thesis introduces MALBO (Multi-Agent LLM Bayesian Optimization), a systematic framework designed to automate the efficient composition of LLM-based agent teams. We formalize the assignment challenge as a multi-objective optimization problem, aiming to identify the Pareto front of configurations between task accuracy and inference cost. The methodology employs multi-objective Bayesian Optimization (MOBO) with independent Gaussian Process surrogate models. By searching over a continuous feature-space representation of the LLMs, this approach performs a sample-efficient exploration guided by the expected hypervolume improvement. The primary contribution is a principled and automated methodology that yields a Pareto front of optimal team configurations. Our results demonstrate that the Bayesian optimization phase, compared to an initial random search, maintained a comparable average performance while reducing the average configuration cost by over 45%. Furthermore, MALBO identified specialized, heterogeneous teams that achieve cost reductions of up to 65.8% compared to homogeneous baselines, all while maintaining maximum performance. The framework thus provides a data-driven tool for deploying cost-effective and highly specialized multi-agent AI systems.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251111788S/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    },
    {
      "id": "37610998",
      "bibcode": "2025arXiv251107581V",
      "title": "Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models",
      "authors": [
        "Vijay, Supriti",
        "Priyanshu, Aman",
        "Vellore, Anu",
        "Saglam, Baturay",
        "Karbasi, Amin"
      ],
      "year": "2025",
      "abstract": "Effective information retrieval requires reasoning over partial evidence and refining strategies as information emerges. Yet current approaches fall short: neural retrievers lack reasoning capabilities, large language models (LLMs) provide semantic depth but at prohibitive cost, and query rewriting or decomposition limits improvement to static transformations. As a result, existing methods fail to capture the iterative dynamics of exploration, feedback, and revision that complex user queries demand. We introduce Orion, a training framework that enables compact models (350M-1.2B parameters) to perform iterative retrieval through learned search strategies. Orion combines: (1) synthetic trajectory generation and supervised fine-tuning to encourage diverse exploration patterns in models, (2) reinforcement learning (RL) that rewards effective query refinement and backtracking behaviors, and (3) inference-time beam search algorithms that exploit the self-reflection capabilities learned during RL. Despite using only 3% of the training data available, our 1.2B model achieves 77.6% success on SciFact (vs. 72.6% for prior retrievers), 25.2% on BRIGHT (vs. 22.1%), 63.2% on NFCorpus (vs. 57.8%), and remains competitive on FEVER, HotpotQA, and MSMarco. It outperforms retrievers up to 200-400x larger on five of six benchmarks. These findings suggest that retrieval performance can emerge from learned strategies, not just model scale, when models are trained to search, reflect, and revise.",
      "publication": "arXiv e-prints",
      "url": "https://ui.adsabs.harvard.edu/abs/2025arXiv251107581V/abstract",
      "source": "ads",
      "ingestedAt": "2025-11-21T18:34:00.612Z",
      "libraryId": "ads-ingest"
    }
  ],
  "articles": [
    {
      "id": "5e59a8e3a87a68eb8723077bd2fe1e05",
      "title": "OpenAI and Foxconn collaborate to strengthen U.S. manufacturing across the AI supply chain",
      "url": "https://openai.com/index/openai-and-foxconn-collaborate",
      "content": "OpenAI and Foxconn are collaborating to design and manufacture next-generation AI infrastructure hardware in the U.S. The partnership will develop multiple generations of data-center systems, strengthen U.S. supply chains, and build key components domestically to accelerate advanced AI infrastructure.",
      "summary": "OpenAI and Foxconn are collaborating to design and manufacture next-generation AI infrastructure hardware in the U.S. The partnership will develop multiple generations of data-center systems, strengthen U.S. supply chains, and build key components domestically to accelerate advanced AI infrastructure.",
      "publishedAt": "2025-11-20T14:50:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "security_incident",
      "tags": [],
      "ingestedAt": "2025-11-21T18:34:16.843Z",
      "score": 5.524572463570857
    },
    {
      "id": "72be2ab1ebb821913376387da739f8d4",
      "title": "Helping 1,000 small businesses build with AI",
      "url": "https://openai.com/index/small-business-ai-jam",
      "content": "OpenAI is partnering with DoorDash, SCORE, and local organizations to help 1,000 small businesses build with AI. The Small Business AI Jam gives Main Street business owners hands-on tools and training to compete and grow.",
      "summary": "OpenAI is partnering with DoorDash, SCORE, and local organizations to help 1,000 small businesses build with AI. The Small Business AI Jam gives Main Street business owners hands-on tools and training to compete and grow.",
      "publishedAt": "2025-11-20T06:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [],
      "ingestedAt": "2025-11-21T18:34:16.843Z",
      "score": 2.6906128666995404
    },
    {
      "id": "0c40a000ff645391fcc87c00e55a58bd",
      "title": "Early experiments in accelerating science with GPT-5",
      "url": "https://openai.com/index/accelerating-science-gpt-5",
      "content": "OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math, physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover new insights, and reshape the pace of discovery.",
      "summary": "OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math, physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover new insights, and reshape the pace of discovery.",
      "publishedAt": "2025-11-20T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.843Z",
      "score": 5.285985308490593
    },
    {
      "id": "0ebef0cfe225255149ed76d29443910d",
      "title": "Strengthening our safety ecosystem with external testing",
      "url": "https://openai.com/index/strengthening-safety-with-external-testing",
      "content": "OpenAI works with independent experts to evaluate frontier AI systems. Third-party testing strengthens safety, validates safeguards, and increases transparency in how we assess model capabilities and risks.",
      "summary": "OpenAI works with independent experts to evaluate frontier AI systems. Third-party testing strengthens safety, validates safeguards, and increases transparency in how we assess model capabilities and risks.",
      "publishedAt": "2025-11-19T12:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [
        "testing"
      ],
      "ingestedAt": "2025-11-21T18:34:16.843Z",
      "score": 3.8253986294105067
    },
    {
      "id": "2aba7a56124890447b62f7caad623b9d",
      "title": "How evals drive the next chapter in AI for businesses",
      "url": "https://openai.com/index/evals-drive-next-chapter-of-ai",
      "content": "Learn how evals help businesses define, measure, and improve AI performanceâreducing risk, boosting productivity, and driving strategic advantage.",
      "summary": "Learn how evals help businesses define, measure, and improve AI performanceâreducing risk, boosting productivity, and driving strategic advantage.",
      "publishedAt": "2025-11-19T11:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.843Z",
      "score": 5.085373919709623
    },
    {
      "id": "94c1a542d3710b59d4d9aec07e4b9c31",
      "title": "OpenAI and Target team up on new AI-powered experiences",
      "url": "https://openai.com/index/target-partnership",
      "content": "OpenAI and Target are partnering to bring a new Target app to ChatGPT, offering personalized shopping and faster checkout. Target will also expand its use of ChatGPT Enterprise to boost productivity and guest experiences.",
      "summary": "OpenAI and Target are partnering to bring a new Target app to ChatGPT, offering personalized shopping and faster checkout. Target will also expand its use of ChatGPT Enterprise to boost productivity and guest experiences.",
      "publishedAt": "2025-11-19T06:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "pricing_business",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.843Z",
      "score": 8.350431649255611
    },
    {
      "id": "8a6a49d607bcd5fa4da85f6781aec3aa",
      "title": "Building more with GPT-5.1-Codex-Max",
      "url": "https://openai.com/index/gpt-5-1-codex-max",
      "content": "Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed for long-running, project-scale work with enhanced reasoning and token efficiency.",
      "summary": "Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed for long-running, project-scale work with enhanced reasoning and token efficiency.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "product_launch",
      "tags": [
        "code_review",
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:16.843Z",
      "score": 9.022904320462779
    },
    {
      "id": "10c90d7cc7819d97e798a3759b2b0abf",
      "title": "A free version of ChatGPT built for teachers",
      "url": "https://openai.com/index/chatgpt-for-teachers",
      "content": "ChatGPT for Teachers is a secure workspace with educationâgrade privacy and admin controls. Free for verified U.S. Kâ12 educators through June 2027.",
      "summary": "ChatGPT for Teachers is a secure workspace with educationâgrade privacy and admin controls. Free for verified U.S. Kâ12 educators through June 2027.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.843Z",
      "score": 4.921584174797879
    },
    {
      "id": "2cebf18ae568df8657f35714cc29b1bc",
      "title": "GPT-5.1-Codex-Max System Card",
      "url": "https://openai.com/index/gpt-5-1-codex-max-system-card",
      "content": "This system card outlines the comprehensive safety measures implemented for GPTâ5.1-CodexMax. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.",
      "summary": "This system card outlines the comprehensive safety measures implemented for GPTâ5.1-CodexMax. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [
        "code_review",
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:16.843Z",
      "score": 8.202640284548515
    },
    {
      "id": "17045c091cb6e6fcb5f6a7f519b1245e",
      "title": "How Scania is accelerating work with AI across its global workforce",
      "url": "https://openai.com/index/scania",
      "content": "Description: Global manufacturer Scania is scaling AI with ChatGPT Enterprise. With team-based onboarding and strong guardrails, AI is boosting productivity, quality, and innovation.",
      "summary": "Description: Global manufacturer Scania is scaling AI with ChatGPT Enterprise. With team-based onboarding and strong guardrails, AI is boosting productivity, quality, and innovation.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "pricing_business",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 8.202640284548515
    },
    {
      "id": "e6949d4d910f746de520e1d46478a327",
      "title": "Teacher Access Terms",
      "url": "https://openai.com/policies/education-terms",
      "content": "Teacher Access Terms outline how verified educators may use ChatGPT for Teachers, covering eligibility, account management, and data privacy requirements.",
      "summary": "Teacher Access Terms outline how verified educators may use ChatGPT for Teachers, covering eligibility, account management, and data privacy requirements.",
      "publishedAt": "2025-11-19T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 4.921584170729108
    },
    {
      "id": "b7f6337287f50eb44829e8f73a37876f",
      "title": "Intuit and OpenAI join forces on new AI-powered experiences",
      "url": "https://openai.com/index/intuit-partnership",
      "content": "OpenAI and Intuit have entered a $100M+ multi-year partnership to launch Intuit app experiences in ChatGPT and expand Intuitâs use of OpenAIâs frontier models to power personalized financial tools.",
      "summary": "OpenAI and Intuit have entered a $100M+ multi-year partnership to launch Intuit app experiences in ChatGPT and expand Intuitâs use of OpenAIâs frontier models to power personalized financial tools.",
      "publishedAt": "2025-11-18T05:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "product_launch",
      "tags": [],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 6.976504153173402
    },
    {
      "id": "0ee69ec84e3309ca88e2a257f13122c4",
      "title": "OpenAI named Emerging Leader in Generative AI",
      "url": "https://openai.com/index/gartner-2025-emerging-leader",
      "content": "OpenAI has been named an Emerging Leader in Gartnerâs 2025 Innovation Guide for Generative AI Model Providers. The recognition reflects our enterprise momentum, with over 1 million companies building with ChatGPT.",
      "summary": "OpenAI has been named an Emerging Leader in Gartnerâs 2025 Innovation Guide for Generative AI Model Providers. The recognition reflects our enterprise momentum, with over 1 million companies building with ChatGPT.",
      "publishedAt": "2025-11-17T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "pricing_business",
      "tags": [
        "code_review",
        "ide"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 8.058045473874742
    },
    {
      "id": "41722a5599ac5dfac4a04db42448e49f",
      "title": "Introducing OpenAI for Ireland",
      "url": "https://openai.com/index/openai-for-ireland",
      "content": "OpenAI launches OpenAI for Ireland, partnering with the Irish Government, Dogpatch Labs and Patch to help SMEs, founders and young builders use AI to innovate, boost productivity and build the next generation of Irish tech startups.",
      "summary": "OpenAI launches OpenAI for Ireland, partnering with the Irish Government, Dogpatch Labs and Patch to help SMEs, founders and young builders use AI to innovate, boost productivity and build the next generation of Irish tech startups.",
      "publishedAt": "2025-11-14T04:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "product_launch",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 6.969472566237452
    },
    {
      "id": "965e60a14502559303595f93f6b0ee74",
      "title": "Understanding neural networks through sparse circuits",
      "url": "https://openai.com/index/understanding-neural-networks-through-sparse-circuits",
      "content": "OpenAI is exploring mechanistic interpretability to understand how neural networks reason. Our new sparse model approach could make AI systems more transparent and support safer, more reliable behavior.",
      "summary": "OpenAI is exploring mechanistic interpretability to understand how neural networks reason. Our new sparse model approach could make AI systems more transparent and support safer, more reliable behavior.",
      "publishedAt": "2025-11-13T10:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 3.302966291009973
    },
    {
      "id": "c78557dbdad9b4f12ac173ddd735e477",
      "title": "Introducing GPT-5.1 for developers",
      "url": "https://openai.com/index/gpt-5-1-for-developers",
      "content": "GPT-5.1 is now available in the API, bringing faster adaptive reasoning, extended prompt caching, improved coding performance, and new apply_patch and shell tools.",
      "summary": "GPT-5.1 is now available in the API, bringing faster adaptive reasoning, extended prompt caching, improved coding performance, and new apply_patch and shell tools.",
      "publishedAt": "2025-11-13T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "product_launch",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 4.809168230609298
    },
    {
      "id": "402d1c676b28ff91394671aa38a74c10",
      "title": "Introducing group chats in ChatGPT",
      "url": "https://openai.com/index/group-chats-in-chatgpt",
      "content": "Weâre piloting group chats in ChatGPT to make collaboration simple. Bring othersâand ChatGPTâinto one shared conversation to plan, brainstorm, and create together.",
      "summary": "Weâre piloting group chats in ChatGPT to make collaboration simple. Bring othersâand ChatGPTâinto one shared conversation to plan, brainstorm, and create together.",
      "publishedAt": "2025-11-13T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "product_launch",
      "tags": [],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 3.2061121537395323
    },
    {
      "id": "a7818ab7bde93e745d5e7e936314b982",
      "title": "How Philips is scaling AI literacy across 70,000 employees",
      "url": "https://openai.com/index/philips",
      "content": "Philips is scaling AI literacy with ChatGPT Enterprise, training 70,000 employees to use AI responsibly and improve healthcare outcomes worldwide.",
      "summary": "Philips is scaling AI literacy with ChatGPT Enterprise, training 70,000 employees to use AI responsibly and improve healthcare outcomes worldwide.",
      "publishedAt": "2025-11-13T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "pricing_business",
      "tags": [
        "code_review",
        "ide"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 5.877872281855809
    },
    {
      "id": "39cff7c19932507f265b3e9ed2a3a7c3",
      "title": "Neuro drives national retail wins with ChatGPT Business",
      "url": "https://openai.com/index/neurogum",
      "content": "Neuro uses ChatGPT Business to scale nationwide with fewer than seventy employees. From drafting contracts to uncovering insights in customer data, the team saves time, cuts costs, and turns ideas into growth.",
      "summary": "Neuro uses ChatGPT Business to scale nationwide with fewer than seventy employees. From drafting contracts to uncovering insights in customer data, the team saves time, cuts costs, and turns ideas into growth.",
      "publishedAt": "2025-11-12T11:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [
        "ide"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 2.05629013057129
    },
    {
      "id": "b377a85ca19b7ac5211137128691f9b5",
      "title": "Fighting the New York Timesâ invasion of user privacy",
      "url": "https://openai.com/index/fighting-nyt-user-privacy-invasion",
      "content": "OpenAI is fighting the New York Timesâ demand for 20 million private ChatGPT conversations and accelerating new security and privacy protections to protect your data.",
      "summary": "OpenAI is fighting the New York Timesâ demand for 20 million private ChatGPT conversations and accelerating new security and privacy protections to protect your data.",
      "publishedAt": "2025-11-12T06:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "security_incident",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 5.571272094213206
    },
    {
      "id": "36ade2f70cc53016a3448fc3a473cc35",
      "title": "GPT-5.1 Instant and GPT-5.1 Thinking System Card Addendum",
      "url": "https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1",
      "content": "This GPT-5 system card addendum provides updated safety metrics for GPT-5.1 Instant and Thinking, including new evaluations for mental health and emotional reliance.",
      "summary": "This GPT-5 system card addendum provides updated safety metrics for GPT-5.1 Instant and Thinking, including new evaluations for mental health and emotional reliance.",
      "publishedAt": "2025-11-12T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "feature_update",
      "tags": [
        "code_review",
        "ide",
        "observability"
      ],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 4.975152823172634
    },
    {
      "id": "9cbe22667b832a7e186116d4a4eebc4c",
      "title": "GPT-5.1: A smarter, more conversational ChatGPT",
      "url": "https://openai.com/index/gpt-5-1",
      "content": "Weâre upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPTâs tone and style. GPT-5.1 starts rolling out today to paid users.",
      "summary": "Weâre upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPTâs tone and style. GPT-5.1 starts rolling out today to paid users.",
      "publishedAt": "2025-11-12T00:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 1.49254584695179
    },
    {
      "id": "963896ca7550df724537c1d3a3f6fb07",
      "title": "Free ChatGPT for transitioning U.S. servicemembers and veterans",
      "url": "https://openai.com/index/chatgpt-for-veterans",
      "content": "OpenAI is offering U.S. servicemembers and veterans within 12 months of retirement or separation a free year of ChatGPT Plus to support their transition to civilian life. The tools can help with resumes, interviews, education, and planning for whatâs next.",
      "summary": "OpenAI is offering U.S. servicemembers and veterans within 12 months of retirement or separation a free year of ChatGPT Plus to support their transition to civilian life. The tools can help with resumes, interviews, education, and planning for whatâs next.",
      "publishedAt": "2025-11-10T02:00:00.000Z",
      "source": "rss",
      "feedName": "OpenAI News",
      "sourceType": "platform_blog",
      "company": "OpenAI",
      "contentType": "general",
      "tags": [],
      "ingestedAt": "2025-11-21T18:34:16.844Z",
      "score": 1.3015794937282095
    },
    {
      "id": "c6c36d19bd8a791c8f3ef1931c1b1c82",
      "title": "GitLab 18.6: From configuration to control",
      "url": "https://about.gitlab.com/blog/gitlab-18-6-from-configuration-to-control/",
      "content": "<p>With <a href=\"https://about.gitlab.com/releases/2025/11/20/gitlab-18-6-released/\">GitLab 18.6</a>, weâre continuing to advance how AI integrates into everyday software development with enhancements that give teams greater choice and control. GitLab 18.6 will help plan, build, and secure software more intelligently across the entire software lifecycle.\nTeams now have greater flexibility to select the right models for their workflows, extend AI into secure and self-managed environments, and strengthen visibility and governance across every stage of development.</p>\n<h2>AI that adapts to you</h2>\n<p>With 18.6, GitLabâs AI becomes more adaptable to real-world workflows. GitLab Duo Agents now plan with greater context, work seamlessly across IDEs and self-managed instances, and offer new open-source model options â helping teams accelerate delivery without compromising compliance or control.</p>\n<p><strong>GitLab Duo Planner and Security Analyst agent enhancements</strong></p>\n<p>In 18.6, <a href=\"https://about.gitlab.com/blog/ace-your-planning-without-the-context-switching/\">GitLab Duo Planner</a> and <a href=\"https://docs.gitlab.com/user/duo_agent_platform/agents/foundational_agents/security_analyst_agent/\">GitLab Duo Security Analyst</a> are now available by default in the Agentic Chat dropdown â no configuration or setup required. Both agents can be used immediately across projects and groups, giving teams built-in assistance for planning, issue refinement, and security analysis.</p>\n<p>GitLab Duo Planner agent now works at the group level with awareness of the epic being viewed and supports milestone and iteration workflows. Security Analyst agent provides automated vulnerability review, context interpretation, and guided remediation suggestions. Both agents are also available to self-managed customers.</p>\n<p>For a full list of what these agents can do, see the <a href=\"https://docs.gitlab.com/user/duo_agent_platform/agents/foundational_agents/\">documentation</a>.</p>\n<p><strong>gpt-oss-120b model support for GitLab Duo Agent Platform</strong></p>\n<p>GitLab Duo Self-Hosted customers can now deploy the <a href=\"https://platform.openai.com/docs/models/gpt-oss-120b\"><strong>gpt-oss-120b</strong></a> model within the GitLab Duo Agent Platform â a high-performance, fully open-source model optimized for agentic workflows. This addition enables teams to execute complex tasks and reasoning-driven processes while maintaining control over model transparency and infrastructure. For organizations that require open, auditable models to address compliance or data sovereignty requirements, gpt-oss-120b provides a reliable alternative to proprietary models without sacrificing performance.</p>\n<p>For more information on supported models, please see our <a href=\"https://docs.gitlab.com/administration/gitlab_duo_self_hosted/supported_models_and_hardware_requirements/#supported-models\">documentation</a>.</p>\n<p><strong>End-user model selection for cloud-connected self-managed instances (GA)</strong></p>\n<p>Cloud-connected self-managed end users can now choose which AI model powers their GitLab Duo Agentic Chat experience directly from the GitLab UI. This gives administrators and end users more control over how conversations perform and how costs and governance requirements are managed.</p>\n<p>No matter the deployment environment â on-premises, private cloud, or public cloud â  teams can select regionally compliant or in-house models to help satisfy data residency needs and compare model quality for speed or accuracy. This flexibility ensures that every organization can tailor Agentic Chat to its operational priorities.</p>\n<p>For full details on how to select a model in Agentic Chat, see the model selection section of the GitLab <a href=\"https://docs.gitlab.com/user/gitlab_duo_chat/agentic_chat/#select-a-model\">documentation</a>.</p>\n<p><strong>Web IDE support for air-gapped deployments</strong></p>\n<p>Air-gapped or tightly controlled environments â such as public sector organizations, defense agencies, and regulated enterprises â can now run the Web IDE with full functionality even without internet access. By allowing administrators to configure their own Web IDE extension host domain, GitLab enables markdown preview, code editing, and GitLab Duo Chat capabilities in isolated or offline systems. This makes it possible for development teams in secure or restricted networks to benefit from modern IDE workflows without sacrificing security and compliance.</p>\n<p><strong>Modern interface now default for self-managed instances</strong></p>\n<p>Self-managed GitLab instances now default to the modern interface in 18.6, bringing the same streamlined experience already available on GitLab.com to on-premises deployments. The updated layout improves navigation consistency and makes core workflows more intuitive across the platform. Administrators maintain full flexibility with opt-out controls via feature flag or user-level toggling if needed. This update ensures self-managed customers benefit from GitLab's latest interface improvements while maintaining the control and customization options enterprise environments require.</p>\n<h2>Platform security with awareness and authority</h2>\n<p>GitLab 18.6 strengthens platform security with deeper context and clearer control, helping security teams focus on the risks that matter most while maintaining governance across every project.</p>\n<p><strong>Security attributes and context filtering</strong></p>\n<p>Security teams can now apply custom business context labels to projects and groups, transforming raw scan results into prioritized, risk-based insights. Instead of viewing vulnerabilities in isolation, teams can tag projects by business unit, application type, or criticality â then filter and sort security data by impact. This allows organizations to focus remediation on the areas of greatest business risk, helping to accelerate time to resolution for the issues that matter most.</p>\n<p><strong>Security Manager default role</strong></p>\n<p>To simplify access control and onboarding for security professionals, GitLab introduces a new Security Manager role. This role provides comprehensive permissions across vulnerability management, policy configuration, and compliance features â while maintaining separation of duties by restricting administrative and code modification rights. Security teams gain the access they need from day one, along with governance, consistency, and accountability across the platform.</p>\n<h2>AI that adapts to your workflow</h2>\n<p>This release represents more than new capabilities â it's about how GitLab Duo Agent Platform is becoming an embedded part of everyday software development workflows. Watch a walkthrough video that shows how a member of your software development team can start on a new project using GitLab Duo Agent Platform:</p>\n<p>&lt;div style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe src=&quot;https://player.vimeo.com/video/1138657697?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share&quot; referrerpolicy=&quot;strict-origin-when-cross-origin&quot; style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot; title=&quot;18.6 Demo (TO BE UPDATED)&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;script src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;</p>\n<h2>Get started today</h2>\n<p>GitLab Premium and Ultimate users can start using these capabilities today on <a href=\"https://GitLab.com\">GitLab.com</a> and self-managed environments, with availability for GitLab Dedicated customers planned for next month.</p>\n<p>New to GitLab? <a href=\"https://about.gitlab.com/free-trial/devsecops/\">Start your free trial</a> and see why the future of development is AI-powered, secure, and orchestrated through the worldâs most comprehensive DevSecOps platform.</p>\n<p><em><strong>Note:</strong> GitLab Duo Agent Platform is currently in beta. Platform capabilities that are in beta are available as part of the GitLab Beta program. They are free to use during the beta period, and when generally available, they are planned to be made available with a paid add-on option for GitLab Duo Agent Platform.</em></p>\n<h3>Stay up to date with GitLab</h3>\n<p>To make sure youâre getting the latest features, security updates, and performance improvements, we recommend keeping your GitLab instance up to date. The following resources can help you plan and complete your upgrade:</p>\n<ul>\n<li>\n<p><a href=\"https://gitlab-com.gitlab.io/support/toolbox/upgrade-path/\">Upgrade Path Tool</a> â enter your current version and see the exact upgrade steps for your instance</p>\n</li>\n<li>\n<p><a href=\"https://docs.gitlab.com/update/upgrade_paths/\">Upgrade Documentation</a> â detailed guides for each supported version, including requirements, step-by-step instructions, and best practices</p>\n</li>\n</ul>\n<p>By upgrading regularly, youâll ensure your team benefits from the newest GitLab capabilities and remains secure and supported.</p>\n<p>For organizations that want a hands-off approach, consider <a href=\"https://content.gitlab.com/viewer/d1fe944dddb06394e6187f0028f010ad#1\">GitLabâs Managed Maintenance service</a>. With Managed Maintenance, your team stays focused on innovation while GitLab experts keep your Self-Managed instance reliably upgraded, secure, and ready to lead in DevSecOps. Ask your account manager for more information.</p>\n<p><em>This blog post contains &quot;forwardâlooking statements&quot; within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934. Although we believe that the expectations reflected in these statements are reasonable, they are subject to known and unknown risks, uncertainties, assumptions and other factors that may cause actual results or outcomes to differ materially. Further information on these risks and other factors is included under the caption &quot;Risk Factors&quot; in our filings with the SEC. We do not undertake any obligation to update or revise these statements after the date of this blog post, except as required by law.</em></p>\n",
      "summary": "With GitLab 18.6, weâre continuing to advance how AI integrates into everyday software development with enhancements that give teams greater choice and control. GitLab 18.6 will help plan, build, and secure software more intelligently across the entire software lifecycle.\nTeams now have greater flexibility to select the right models for their workflows, extend AI into secure and self-managed environments, and strengthen visibility and governance across every stage of development.\nAI that adapts to you\nWith 18.6, GitLabâs AI becomes more adaptable to real-world workflows. GitLab Duo Agents now plan with greater context, work seamlessly across IDEs and self-managed instances, and offer new open-source model options â helping teams accelerate delivery without compromising compliance or control.\nGitLab Duo Planner and Security Analyst agent enhancements\nIn 18.6, GitLab Duo Planner and GitLab Duo Security Analyst are now available by default in the Agentic Chat dropdown â no configuration or setup required. Both agents can be used immediately across projects and groups, giving teams built-in assistance for planning, issue refinement, and security analysis.\nGitLab Duo Planner agent now works at the group level with awareness of the epic being viewed and supports milestone and iteration workflows. Security Analyst agent provides automated vulnerability review, context interpretation, and guided remediation suggestions. Both agents are also available to self-managed customers.\nFor a full list of what these agents can do, see the documentation.\ngpt-oss-120b model support for GitLab Duo Agent Platform\nGitLab Duo Self-Hosted customers can now deploy the gpt-oss-120b model within the GitLab Duo Agent Platform â a high-performance, fully open-source model optimized for agentic workflows. This addition enables teams to execute complex tasks and reasoning-driven processes while maintaining control over model transparency and infrastructure. For organizations that require open, auditable models to address compliance or data sovereignty requirements, gpt-oss-120b provides a reliable alternative to proprietary models without sacrificing performance.\nFor more information on supported models, please see our documentation.\nEnd-user model selection for cloud-connected self-managed instances (GA)\nCloud-connected self-managed end users can now choose which AI model powers their GitLab Duo Agentic Chat experience directly from the GitLab UI. This gives administrators and end users more control over how conversations perform and how costs and governance requirements are managed.\nNo matter the deployment environment â on-premises, private cloud, or public cloud â  teams can select regionally compliant or in-house models to help satisfy data residency needs and compare model quality for speed or accuracy. This flexibility ensures that every organization can tailor Agentic Chat to its operational priorities.\nFor full details on how to select a model in Agentic Chat, see the model selection section of the GitLab documentation.\nWeb IDE support for air-gapped deployments\nAir-gapped or tightly controlled environments â such as public sector organizations, defense agencies, and regulated enterprises â can now run the Web IDE with full functionality even without internet access. By allowing administrators to configure their own Web IDE extension host domain, GitLab enables markdown preview, code editing, and GitLab Duo Chat capabilities in isolated or offline systems. This makes it possible for development teams in secure or restricted networks to benefit from modern IDE workflows without sacrificing security and compliance.\nModern interface now default for self-managed instances\nSelf-managed GitLab instances now default to the modern interface in 18.6, bringing the same streamlined experience already available on GitLab.com to on-premises deployments. The updated layout improves navigation consistency and makes core workflows more intuitive across the platform. Administrators maintain full flexibility with opt-out controls via feature flag or user-level toggling if needed. This update ensures self-managed customers benefit from GitLab's latest interface improvements while maintaining the control and customization options enterprise environments require.\nPlatform security with awareness and authority\nGitLab 18.6 strengthens platform security with deeper context and clearer control, helping security teams focus on the risks that matter most while maintaining governance across every project.\nSecurity attributes and context filtering\nSecurity teams can now apply custom business context labels to projects and groups, transforming raw scan results into prioritized, risk-based insights. Instead of viewing vulnerabilities in isolation, teams can tag projects by business unit, application type, or criticality â then filter and sort security data by impact. This allows organizations to focus remediation on the areas of greatest business risk, helping to accelerate time to resolution for the issues that matter most.\nSecurity Manager default role\nTo simplify access control and onboarding for security professionals, GitLab introduces a new Security Manager role. This role provides comprehensive permissions across vulnerability management, policy configuration, and compliance features â while maintaining separation of duties by restricting administrative and code modification rights. Security teams gain the access they need from day one, along with governance, consistency, and accountability across the platform.\nAI that adapts to your workflow\nThis release represents more than new capabilities â it's about how GitLab Duo Agent Platform is becoming an embedded part of everyday software development workflows. Watch a walkthrough video that shows how a member of your software development team can start on a new project using GitLab Duo Agent Platform:\n<div style=\"padding:56.25% 0 0 0;position:relative;\"><iframe src=\"https://player.vimeo.com/video/1138657697?badge=0&autopause=0&player_id=0&app_id=58479\" frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"18.6 Demo (TO BE UPDATED)\"></iframe></div><script src=\"https://player.vimeo.com/api/player.js\"></script>\nGet started today\nGitLab Premium and Ultimate users can start using these capabilities today on GitLab.com and self-managed environments, with availability for GitLab Dedicated customers planned for next month.\nNew to GitLab? Start your free trial and see why the future of development is AI-powered, secure, and orchestrated through the worldâs most comprehensive DevSecOps platform.\nNote: GitLab Duo Agent Platform is currently in beta. Platform capabilities that are in beta are available as part of the GitLab Beta program. They are free to use during the beta period, and when generally available, they are planned to be made available with a paid add-on option for GitLab Duo Agent Platform.\nStay up to date with GitLab\nTo make sure youâre getting the latest features, security updates, and performance improvements, we recommend keeping your GitLab instance up to date. The following resources can help you plan and complete your upgrade:\nUpgrade Path Tool â enter your current version and see the exact upgrade steps for your instance\nUpgrade Documentation â detailed guides for each supported version, including requirements, step-by-step instructions, and best practices\nBy upgrading regularly, youâll ensure your team benefits from the newest GitLab capabilities and remains secure and supported.\nFor organizations that want a hands-off approach, consider GitLabâs Managed Maintenance service. With Managed Maintenance, your team stays focused on innovation while GitLab experts keep your Self-Managed instance reliably upgraded, secure, and ready to lead in DevSecOps. Ask your account manager for more information.\nThis blog post contains \"forwardâlooking statements\" within the meaning of Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934. Although we believe that the expectations reflected in these statements are reasonable, they are subject to known and unknown risks, uncertainties, assumptions and other factors that may cause actual results or outcomes to differ materially. Further information on these risks and other factors is included under the caption \"Risk Factors\" in our filings with the SEC. We do not undertake any obligation to update or revise these statements after the date of this blog post, except as required by law.",
      "publishedAt": "2025-11-20T00:00:00.000Z",
      "author": "Bill Staples",
      "source": "rss",
      "feedName": "GitLab Blog",
      "sourceType": "platform_blog",
      "company": "GitLab",
      "contentType": "product_launch",
      "tags": [
        "code_review",
        "documentation",
        "agents",
        "ide",
        "governance"
      ],
      "ingestedAt": "2025-11-21T18:34:16.876Z",
      "score": 22.024938184498698
    },
    {
      "id": "e1a987b4ca19fee90af038f7a93e15f0",
      "title": "GitLab engineer: How I improved my onboarding experience with AI",
      "url": "https://about.gitlab.com/blog/gitlab-engineer-how-i-improved-my-onboarding-experience-with-ai/",
      "content": "<p>Starting a new job is exciting, and overwhelming. New teammates, new tools, and, in GitLabâs case, a lot of documentation. Six weeks ago, I joined GitLabâs Growth team as a fullstack engineer. Anyone who has gone through <a href=\"https://about.gitlab.com/the-source/platform/how-to-accelerate-developer-onboarding-and-why-it-matters/\">onboarding at GitLab</a> knows itâs transparent, extensive, and thorough.</p>\n<p>GitLab's onboarding process includes a lot of docs, videos, and trainings that will bring you up to speed. Also, in line with GitLab's values, my team encouraged me to start contributing right away. I quickly realized that onboarding here is both diligent and intense. Luckily, I had a secret helper: <a href=\"https://about.gitlab.com/gitlab-duo/\">GitLab Duo</a>.</p>\n<h2>My main use cases</h2>\n<p>Iâve found GitLab Duo's AI assistance, available throughout the software development lifecycle, useful in three key areas: exploration, reviewing, and debugging. With GitLab Duo, I was able to get my first tiny MR deployed to production in the first week and actively contribute to <a href=\"https://about.gitlab.com/releases/2025/10/16/gitlab-18-5-released/#pick-up-where-you-left-off-on-the-new-personal-homepage\">the personal homepage</a> in GitLab 18.5 in the weeks after.</p>\n<h3>Exploration</h3>\n<p>Early in onboarding, I often remembered reading something but couldnât recall where. GitLab has a <a href=\"https://handbook.gitlab.com/\">public-facing handbook</a>, an internal handbook, and <a href=\"https://docs.gitlab.com/\">GitLab Docs</a>. It can be difficult to search across all of them efficiently.</p>\n<p>GitLab Duo simplifies this task: I can describe what Iâm looking for in natural language via <a href=\"https://docs.gitlab.com/user/gitlab_duo_chat/\">GitLab Duo Chat</a> and search across all resources at once.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>I remember reading about how RSpec tests are done at GitLab. Can you find relevant documentation across the Handbook, the internal handbook and the GitLab Docs?</p>\n</blockquote>\n<p>Before starting work on an issue, I use GitLab Duo to identify edge cases and hidden dependencies. GitLab Duo will relate the requirements of the issue against the whole GitLab codebase, assess similar features, and prepare all the findings. Based on its output I am able to refine the issue with my product manager and designer, and make sure my implementation covers all edge cases or define future iterations.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>Analyze this issue in the context of its epic and identify:</p>\n<ul>\n<li>Implementation questions to ask PM/design before coding</li>\n<li>Edge cases not covered in requirements</li>\n<li>Cross-feature dependencies that might be affected</li>\n<li>Missing acceptance criteria</li>\n</ul>\n</blockquote>\n<p>I also check that my planned solution follows GitLab best practices and common patterns.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>I want to implement XZY behavior â how is this usually done at GitLab, and what other options do I have?</p>\n</blockquote>\n<h3>Reviewing</h3>\n<p>I always <a href=\"https://docs.gitlab.com/user/project/merge_requests/duo_in_merge_requests/#have-gitlab-duo-review-your-code\">let GitLab Duo review my merge requests</a> before assigning human reviewers. It often catches small mistakes, suggests improvements, and highlights edge cases I missed. This shortens the review cycle and helps my teammates focus on more complex and bigger-picture feedback.</p>\n<p>Since Iâm still new to GitLabâs codebase and coding practices, some review comments are hard to interpret. In those cases, GitLab Duo helps me understand what a reviewer means and how it relates to my code.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>I donât understand the comment on this MR about following the user instead of testing component internals, what does it mean and how does it relate to my implementation?</p>\n</blockquote>\n<h3>Debugging</h3>\n<p>Sometimes pipeline tests on my merge requests failed unexpectedly. If I canât tell whether my changes are the cause, GitLab Duo helps me investigate and fix the failures. Using <a href=\"https://docs.gitlab.com/user/gitlab_duo_chat/agentic_chat/\">GitLab Duo Agentic Chat</a>, Duo can apply changes to debug the failing job.</p>\n<p>Example prompt:</p>\n<blockquote>\n<p>The pipeline job ârspec system pg16 12/32â is failing, but I donât know whether that relates to my changes. Can you check, if my changes are causing the pipeline failure and, if so, guide me through the steps of fixing it.</p>\n</blockquote>\n<h2>How Duo aligns with GitLabâs values</h2>\n<p>Using GitLab Duo doesnât just help me, it also supports <a href=\"https://handbook.gitlab.com/handbook/values/\">GitLabâs CREDIT values</a>:</p>\n<ul>\n<li>\n<p><strong>Collaboration:</strong> I ask teammates fewer basic questions. And when I do ask questions, theyâre more thoughtful and informed. This respects their time.</p>\n</li>\n<li>\n<p><strong>Results for customers:</strong> By identifying edge cases early and improving code quality, GitLab Duo helps me deliver better outcomes for customers.</p>\n</li>\n<li>\n<p><strong>Efficiency:</strong> Streamlined preparation, faster reviews, and improved debugging make me more efficient.</p>\n</li>\n<li>\n<p><strong>Diversity, inclusion &amp; belonging:</strong> AI guidance might mitigate misunderstandings and different barriers to entry based on differing backgrounds and abilities.</p>\n</li>\n<li>\n<p><strong>Iteration:</strong> The ability to try ideas faster and identify potential improvements, enables faster iteration.</p>\n</li>\n<li>\n<p><strong>Transparency:</strong> GitLab Duo makes the already transparent documentation at GitLab more accessible.</p>\n</li>\n</ul>\n<h2>Staying cautious with AI</h2>\n<p>It never has been as easy and difficult to be competent as in the days of AI. It can be a powerful tool, but AI does get things wrong. Therefore, I avoid <a href=\"https://link.springer.com/article/10.1007/s00146-025-02422-7\">automation bias</a> by always validating AI's outputs. If I donât understand the output, I donât use it.\nIâm also cautious of over-reliance. Studies suggest that heavy AI use can lead to <a href=\"https://www.mdpi.com/2075-4698/15/1/6\">cognitive offloading</a> and worse outcomes in the long run. One study shows that users of AI <a href=\"https://arxiv.org/abs/2404.19699?utm_source=chatgpt.com\">perform worse in exams</a>. To avoid negatively affecting my skills, I use AI as a discussion partner rather than just implementing the code it generates.</p>\n<h2>Summary</h2>\n<p>Onboarding is always a stressful time, but using GitLab Duo made mine smoother and less overwhelming. I learned more about GitLabâs codebase, culture, and best practices than I could have managed on my own.</p>\n<blockquote>\n<p>Want to make GitLab Duo part of your onboarding experience? Sign up for <a href=\"https://about.gitlab.com/gitlab-duo/\">a free trial</a> today.</p>\n</blockquote>\n<h2>Resources</h2>\n<ul>\n<li><a href=\"https://docs.gitlab.com/user/get_started/getting_started_gitlab_duo/\">Getting started with GitLab Duo</a></li>\n<li><a href=\"https://about.gitlab.com/blog/get-started-with-gitlab-duo-agentic-chat-in-the-web-ui/\">Get started with GitLab Duo Agentic Chat in the web UI</a></li>\n<li><a href=\"https://about.gitlab.com/blog/10-best-practices-for-using-ai-powered-gitlab-duo-chat/\">10 best practices for using AI-powered GitLab Duo Chat</a></li>\n</ul>\n",
      "summary": "Starting a new job is exciting, and overwhelming. New teammates, new tools, and, in GitLabâs case, a lot of documentation. Six weeks ago, I joined GitLabâs Growth team as a fullstack engineer. Anyone who has gone through onboarding at GitLab knows itâs transparent, extensive, and thorough.\nGitLab's onboarding process includes a lot of docs, videos, and trainings that will bring you up to speed. Also, in line with GitLab's values, my team encouraged me to start contributing right away. I quickly realized that onboarding here is both diligent and intense. Luckily, I had a secret helper: GitLab Duo.\nMy main use cases\nIâve found GitLab Duo's AI assistance, available throughout the software development lifecycle, useful in three key areas: exploration, reviewing, and debugging. With GitLab Duo, I was able to get my first tiny MR deployed to production in the first week and actively contribute to the personal homepage in GitLab 18.5 in the weeks after.\nExploration\nEarly in onboarding, I often remembered reading something but couldnât recall where. GitLab has a public-facing handbook, an internal handbook, and GitLab Docs. It can be difficult to search across all of them efficiently.\nGitLab Duo simplifies this task: I can describe what Iâm looking for in natural language via GitLab Duo Chat and search across all resources at once.\nExample prompt:\nI remember reading about how RSpec tests are done at GitLab. Can you find relevant documentation across the Handbook, the internal handbook and the GitLab Docs?\nBefore starting work on an issue, I use GitLab Duo to identify edge cases and hidden dependencies. GitLab Duo will relate the requirements of the issue against the whole GitLab codebase, assess similar features, and prepare all the findings. Based on its output I am able to refine the issue with my product manager and designer, and make sure my implementation covers all edge cases or define future iterations.\nExample prompt:\nAnalyze this issue in the context of its epic and identify:\nImplementation questions to ask PM/design before coding\nEdge cases not covered in requirements\nCross-feature dependencies that might be affected\nMissing acceptance criteria\nI also check that my planned solution follows GitLab best practices and common patterns.\nExample prompt:\nI want to implement XZY behavior â how is this usually done at GitLab, and what other options do I have?\nReviewing\nI always let GitLab Duo review my merge requests before assigning human reviewers. It often catches small mistakes, suggests improvements, and highlights edge cases I missed. This shortens the review cycle and helps my teammates focus on more complex and bigger-picture feedback.\nSince Iâm still new to GitLabâs codebase and coding practices, some review comments are hard to interpret. In those cases, GitLab Duo helps me understand what a reviewer means and how it relates to my code.\nExample prompt:\nI donât understand the comment on this MR about following the user instead of testing component internals, what does it mean and how does it relate to my implementation?\nDebugging\nSometimes pipeline tests on my merge requests failed unexpectedly. If I canât tell whether my changes are the cause, GitLab Duo helps me investigate and fix the failures. Using GitLab Duo Agentic Chat, Duo can apply changes to debug the failing job.\nExample prompt:\nThe pipeline job ârspec system pg16 12/32â is failing, but I donât know whether that relates to my changes. Can you check, if my changes are causing the pipeline failure and, if so, guide me through the steps of fixing it.\nHow Duo aligns with GitLabâs values\nUsing GitLab Duo doesnât just help me, it also supports GitLabâs CREDIT values:\nCollaboration: I ask teammates fewer basic questions. And when I do ask questions, theyâre more thoughtful and informed. This respects their time.\nResults for customers: By identifying edge cases early and improving code quality, GitLab Duo helps me deliver better outcomes for customers.\nEfficiency: Streamlined preparation, faster reviews, and improved debugging make me more efficient.\nDiversity, inclusion & belonging: AI guidance might mitigate misunderstandings and different barriers to entry based on differing backgrounds and abilities.\nIteration: The ability to try ideas faster and identify potential improvements, enables faster iteration.\nTransparency: GitLab Duo makes the already transparent documentation at GitLab more accessible.\nStaying cautious with AI\nIt never has been as easy and difficult to be competent as in the days of AI. It can be a powerful tool, but AI does get things wrong. Therefore, I avoid automation bias by always validating AI's outputs. If I donât understand the output, I donât use it.\nIâm also cautious of over-reliance. Studies suggest that heavy AI use can lead to cognitive offloading and worse outcomes in the long run. One study shows that users of AI perform worse in exams. To avoid negatively affecting my skills, I use AI as a discussion partner rather than just implementing the code it generates.\nSummary\nOnboarding is always a stressful time, but using GitLab Duo made mine smoother and less overwhelming. I learned more about GitLabâs codebase, culture, and best practices than I could have managed on my own.\nWant to make GitLab Duo part of your onboarding experience? Sign up for a free trial today.\nResources\nGetting started with GitLab Duo\nGet started with GitLab Duo Agentic Chat in the web UI\n10 best practices for using AI-powered GitLab Duo Chat",
      "publishedAt": "2025-11-17T00:00:00.000Z",
      "author": "Konstantin Greif",
      "source": "rss",
      "feedName": "GitLab Blog",
      "sourceType": "platform_blog",
      "company": "GitLab",
      "contentType": "security_incident",
      "tags": [
        "code_review",
        "documentation",
        "retrieval",
        "agents",
        "ide",
        "testing"
      ],
      "ingestedAt": "2025-11-21T18:34:16.877Z",
      "score": 12.088168560082254
    },
    {
      "id": "b33941af2e8b543ac60d0bed12fca5d3",
      "title": "Achieve CMMC Level 2 with GitLab Dedicated for Government",
      "url": "https://about.gitlab.com/blog/achieve-cmmc-level-2-fast-with-gitlab-dedicated-for-government/",
      "content": "<p>For Defense Industrial Base (DIB) companies, the U.S. Department of Defense's release of the Cybersecurity Maturity Model Certification (CMMC) <a href=\"https://www.federalregister.gov/documents/2025/09/10/2025-17359/defense-federal-acquisition-regulation-supplement-assessing-contractor-implementation-of_\">Final Rule</a> and new guidance on âFedRAMP equivalencyâ has dramatically increased the cost of compliance and fundamentally changed the way in which they drive their risk management programs. Gone is the era of âself-attestationâ of security programs; DIB companies are required to strictly apply NIST 800-171 to their environments that handle Controlled Unclassified Information (CUI), and have their security controls audited by a Third-Party Assessment Organization (3PAO) every three years.</p>\n<p>DIB companies are engineering focused, not compliance driven, and formal audits get pricey quickly. These changes add significant complications for companies focused on supporting the warfighter. The good news? <a href=\"https://about.gitlab.com/press/releases/2025-05-19-gitlab-announces-gitlab-achieves-fedramp-moderate-authorization/\">GitLab Dedicated for Government's FedRAMP Moderate Authorization</a> means DIB companies can directly use GitLab Dedicated for Government with no additional audits or authorizations, which reduces the impact and cost of compliance.</p>\n<h2>The foundational rule: FedRAMP Moderate Equivalency</h2>\n<p>The protection of Controlled Unclassified Information (CUI) within the DIB is driven by a foundational legal and contractual mandate: the Defense Federal Acquisition Regulation Supplement (DFARS) <a href=\"https://www.acquisition.gov/dfars/252.204-7012-safeguarding-covered-defense-information-and-cyber-incident-reporting.\">Clause 252.204-7012</a>. This clause specifically states that if a contractor uses an external cloud service provider to &quot;store, process, or transmit any covered defense information,&quot; that provider must meet security requirements &quot;equivalent to those established by the Government for the FedRAMP Moderate baseline.&quot;</p>\n<p>The DOD's January 2, 2024, memorandum, &quot;<a href=\"https://dodcio.defense.gov/Portals/0/Documents/Library/FEDRAMP-EquivalencyCloudServiceProviders.pdf\">Federal Risk and Authorization Management Program (FedRAMP) Moderate Equivalency for Cloud Service Provider's (CSPs) Cloud Service Offerings</a>&quot; defines âFedRAMP Moderate Equivalency,â and also directly specifies that FedRAMP Moderate Cloud Service Offerings (CSOs) can be used without any additional assessment, such as individual CMMC assessment, to meet equivalency requirements:</p>\n<p>âThis memorandum does not apply to CSOs that are FedRAMP Moderate Authorized under the existing FedRAMP process. <strong>FedRAMP Moderate Authorized CSOs identified in the FedRAMP Marketplace</strong> provide the required security to store, process or transmit CDI in accordance with Defense Federal Acquisition Regulations Supplement (DFARS) Clause 252.204-7012, &quot;Safeguarding Covered Defense Information and Cyber Incident Reporting&quot; and <strong>can be leveraged without further assessment to meet the equivalency requirements</strong>.â</p>\n<h2>The GitLab platform: A proven path to compliance</h2>\n<p>GitLab's GovCloud Offering, GitLab Dedicated for Government, <a href=\"https://marketplace.fedramp.gov/products/FR2411959145\">has achieved FedRAMP Moderate Authorization</a>. This means that DIB companies can leverage GitLab Dedicated for Government as their DevSecOps platform immediately and without any additional audits or compliance checks. DIB companies leveraging GitLab Dedicated for Government inherit all of our security controls and our Body of Evidence, shifting the risk and cost of compliance away from themselves and allowing them to focus on their mission.</p>\n<h2>The Shared Responsibility Matrix: Your role as a DIB contractor</h2>\n<p>While a FedRAMP-authorized solution significantly reduces your compliance burden, compliance is a joint effort. You are responsible for the security controls that fall under your purview. This is where the Shared Responsibility Matrix (SRM), also called the Customer Responsibility Matrix (CRM), comes in.</p>\n<p>When you adopt GitLab Dedicated for Government, you will receive a comprehensive SRM that clearly delineates which security controls are managed by GitLab and which are your responsibility as the customer. Your CMMC C3PAO will use this document to ensure you have implemented the necessary controls on your end. By leveraging GitLab's FedRAMP-authorized platform, you can confidently address your CMMC Level 2 compliance requirements, focusing on your mission while trusting that GitLab has you covered.</p>\n<blockquote>\n<p>To learn more about GitLab Dedicated for Government, visit our <a href=\"https://about.gitlab.com/solutions/public-sector/\">GitLab for Public Sector</a> page. Interested in a demo? Contact Sales for more information at <a href=\"mailto:sales-pubsec@gitlab.com\">sales-pubsec@gitlab.com</a>.</p>\n</blockquote>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://www.federalregister.gov/documents/2025/09/10/2025-17359/defense-federal-acquisition-regulation-supplement-assessing-contractor-implementation-of\">CMMC âFinal Ruleâ DFARS Supplement</a></li>\n<li><a href=\"https://dodcio.defense.gov/Portals/0/Documents/Library/FEDRAMP-EquivalencyCloudServiceProviders.pdf\">DOD-CIO âFedRAMP Moderate Equivalencyâ Memo</a></li>\n<li><a href=\"https://marketplace.fedramp.gov/products/FR2411959145\">GitLab Dedicated for Government FedRAMP Marketplace Listing</a></li>\n</ul>\n",
      "summary": "For Defense Industrial Base (DIB) companies, the U.S. Department of Defense's release of the Cybersecurity Maturity Model Certification (CMMC) Final Rule and new guidance on âFedRAMP equivalencyâ has dramatically increased the cost of compliance and fundamentally changed the way in which they drive their risk management programs. Gone is the era of âself-attestationâ of security programs; DIB companies are required to strictly apply NIST 800-171 to their environments that handle Controlled Unclassified Information (CUI), and have their security controls audited by a Third-Party Assessment Organization (3PAO) every three years.\nDIB companies are engineering focused, not compliance driven, and formal audits get pricey quickly. These changes add significant complications for companies focused on supporting the warfighter. The good news? GitLab Dedicated for Government's FedRAMP Moderate Authorization means DIB companies can directly use GitLab Dedicated for Government with no additional audits or authorizations, which reduces the impact and cost of compliance.\nThe foundational rule: FedRAMP Moderate Equivalency\nThe protection of Controlled Unclassified Information (CUI) within the DIB is driven by a foundational legal and contractual mandate: the Defense Federal Acquisition Regulation Supplement (DFARS) Clause 252.204-7012. This clause specifically states that if a contractor uses an external cloud service provider to \"store, process, or transmit any covered defense information,\" that provider must meet security requirements \"equivalent to those established by the Government for the FedRAMP Moderate baseline.\"\nThe DOD's January 2, 2024, memorandum, \"Federal Risk and Authorization Management Program (FedRAMP) Moderate Equivalency for Cloud Service Provider's (CSPs) Cloud Service Offerings\" defines âFedRAMP Moderate Equivalency,â and also directly specifies that FedRAMP Moderate Cloud Service Offerings (CSOs) can be used without any additional assessment, such as individual CMMC assessment, to meet equivalency requirements:\nâThis memorandum does not apply to CSOs that are FedRAMP Moderate Authorized under the existing FedRAMP process. FedRAMP Moderate Authorized CSOs identified in the FedRAMP Marketplace provide the required security to store, process or transmit CDI in accordance with Defense Federal Acquisition Regulations Supplement (DFARS) Clause 252.204-7012, \"Safeguarding Covered Defense Information and Cyber Incident Reporting\" and can be leveraged without further assessment to meet the equivalency requirements.â\nThe GitLab platform: A proven path to compliance\nGitLab's GovCloud Offering, GitLab Dedicated for Government, has achieved FedRAMP Moderate Authorization. This means that DIB companies can leverage GitLab Dedicated for Government as their DevSecOps platform immediately and without any additional audits or compliance checks. DIB companies leveraging GitLab Dedicated for Government inherit all of our security controls and our Body of Evidence, shifting the risk and cost of compliance away from themselves and allowing them to focus on their mission.\nThe Shared Responsibility Matrix: Your role as a DIB contractor\nWhile a FedRAMP-authorized solution significantly reduces your compliance burden, compliance is a joint effort. You are responsible for the security controls that fall under your purview. This is where the Shared Responsibility Matrix (SRM), also called the Customer Responsibility Matrix (CRM), comes in.\nWhen you adopt GitLab Dedicated for Government, you will receive a comprehensive SRM that clearly delineates which security controls are managed by GitLab and which are your responsibility as the customer. Your CMMC C3PAO will use this document to ensure you have implemented the necessary controls on your end. By leveraging GitLab's FedRAMP-authorized platform, you can confidently address your CMMC Level 2 compliance requirements, focusing on your mission while trusting that GitLab has you covered.\nTo learn more about GitLab Dedicated for Government, visit our GitLab for Public Sector page. Interested in a demo? Contact Sales for more information at sales-pubsec@gitlab.com.\nReferences\nCMMC âFinal Ruleâ DFARS Supplement\nDOD-CIO âFedRAMP Moderate Equivalencyâ Memo\nGitLab Dedicated for Government FedRAMP Marketplace Listing",
      "publishedAt": "2025-11-12T00:00:00.000Z",
      "author": "Drew Wilmoth",
      "source": "rss",
      "feedName": "GitLab Blog",
      "sourceType": "platform_blog",
      "company": "GitLab",
      "contentType": "security_incident",
      "tags": [
        "code_review",
        "retrieval",
        "ide",
        "governance"
      ],
      "ingestedAt": "2025-11-21T18:34:16.877Z",
      "score": 8.706517203023115
    },
    {
      "id": "fb31a67a2b8db1c5c327d58bb2b8e97e",
      "title": "Secure AI agent deployment to GKE",
      "url": "https://about.gitlab.com/blog/secure-ai-agent-deployment-to-gke/",
      "content": "<p>Building <a href=\"https://about.gitlab.com/gitlab-duo/agent-platform/\">AI agents</a> is</p>\n<p>exciting, but deploying them securely to production shouldn't be</p>\n<p>complicated. In this tutorial, you will learn how GitLab's <a href=\"https://cloud.google.com/blog/topics/partners/understand-the-google-cloud-gitlab-integration\">native Google Cloud integration</a> makes it straightforward to deploy AI agents to Google Kubernetes Engine (GKE) â with built-in scanning and zero service account keys.</p>\n<h2>Why choose GKE to deploy your AI agents?</h2>\n<p>GKE provides enterprise-grade orchestration that connects seamlessly with GitLab CI/CD pipelines through OIDC authentication. Your development team can deploy AI agents while maintaining complete visibility, compliance, and control over your cloud infrastructure. This guide uses Google's Agent Development Kit (<a href=\"https://developers.googleblog.com/en/agent-development-kit-easy-to-build-multi-agent-applications/\">ADK</a>) to build the app, so you can expect increased seamlessness as this is deployed using GitLab.</p>\n<p>Three key advantages to this approach:</p>\n<p><strong>Full infrastructure control</strong> - Your data, your rules, your environment. You maintain complete control over where your AI agents run and how they're configured.</p>\n<p><strong>Native GitLab integration</strong> - No complex workarounds. Your existing pipelines work right out of the box thanks to GitLab's native integration with Google Cloud.</p>\n<p><strong>Production-grade scaling</strong> - GKE automatically handles the heavy lifting of scaling and internal orchestration as your AI workloads grow.</p>\n<p>The key point is that GitLab with GKE provides the enterprise reliability your AI deployments demand without sacrificing the developer experience your teams expect.</p>\n<h2>Prerequisites</h2>\n<p>Before you start, make sure you have these APIs enabled:</p>\n<ul>\n<li>\n<p>GKE API</p>\n</li>\n<li>\n<p>Artifact Registry API</p>\n</li>\n<li>\n<p>Vertex AI API</p>\n</li>\n</ul>\n<p>Also make sure you have:</p>\n<ul>\n<li>\n<p>GitLab project created</p>\n</li>\n<li>\n<p>GKE cluster provisioned</p>\n</li>\n<li>\n<p>Artifact Registry repository created</p>\n</li>\n</ul>\n<h2>The deployment process</h2>\n<h3>1. Set up IAM and permissions on GitLab</h3>\n<p>Navigate to your GitLab integrations to configure Google Cloud authentication (IAM).</p>\n<p>Go to <strong>Settings &gt; Integrations</strong> and configure the Google Cloud integration. If you're using a group-level integration, notice that default settings are already inherited by projects. This means you configure once at the group level, and all projects benefit and inherit this setting.</p>\n<p>To set this up from scratch, provide:</p>\n<ul>\n<li>\n<p>Project ID</p>\n</li>\n<li>\n<p>Project Number</p>\n</li>\n<li>\n<p>Workload Identity Pool ID</p>\n</li>\n<li>\n<p>Provider ID</p>\n</li>\n</ul>\n<p>Once configured, GitLab provides a script to run in Google Cloud Console, via Cloud Shell. The outcome of running this script is a Workload Identity Federation pool with the necessary service principal to enable the proper access.</p>\n<h3>2. Configure Artifact Registry integration</h3>\n<p>Still in GitLab's integration settings, configure Artifact Management:</p>\n<ol>\n<li>\n<p>Click <strong>Artifact Management</strong>.</p>\n</li>\n<li>\n<p>Select <strong>Google Artifact Registry</strong>.</p>\n</li>\n<li>\n<p>Provide:</p>\n<ul>\n<li>Project ID</li>\n<li>Repository Name (created beforehand)</li>\n<li>Repository Location</li>\n</ul>\n</li>\n</ol>\n<p>GitLab provides another script to run in Google Cloud Console.</p>\n<p><strong>Important:</strong> Before proceeding, add these extra roles to the Workload Identity Federation pool:</p>\n<ul>\n<li>\n<p>Service Account User</p>\n</li>\n<li>\n<p>Kubernetes Developer</p>\n</li>\n<li>\n<p>Kubernetes Cluster Viewer</p>\n</li>\n</ul>\n<p>These permissions allow GitLab to deploy to GKE in subsequent steps.</p>\n<h3>3. Create the CI/CD pipeline</h3>\n<p>Now for the key part â creating the CI/CD pipeline for deployment.</p>\n<p>Head to <strong>Build &gt; Pipeline Editor</strong> and define your pipeline with four stages:</p>\n<ul>\n<li>\n<p><strong>Build</strong> - Docker creates the container image.</p>\n</li>\n<li>\n<p><strong>Test</strong> - GitLab Auto DevOps provides built-in security scans to ensure there are no vulnerabilities.</p>\n</li>\n<li>\n<p><strong>Upload</strong> - Uses GitLab's built-in CI/CD component to push to Google Artifact Registry.</p>\n</li>\n<li>\n<p><strong>Deploy</strong> - Uses Kubernetes configuration to deploy to GKE.</p>\n</li>\n</ul>\n<p>Here's the complete <code>.gitlab-ci.yml</code>:</p>\n<pre><code class=\"language-yaml\">\n\ndefault:\n  tags: [ saas-linux-2xlarge-amd64 ]\n\nstages:\n  - build\n  - test\n  - upload\n  - deploy\n\nvariables:\n  GITLAB_IMAGE: $CI_REGISTRY_IMAGE/main:$CI_COMMIT_SHORT_SHA\n  AR_IMAGE: $GOOGLE_ARTIFACT_REGISTRY_REPOSITORY_LOCATION-docker.pkg.dev/$GOOGLE_ARTIFACT_REGISTRY_PROJECT_ID/$GOOGLE_ARTIFACT_REGISTRY_REPOSITORY_NAME/main:$CI_COMMIT_SHORT_SHA\n  GCP_PROJECT_ID: &quot;your-project-id&quot;\n  GKE_CLUSTER: &quot;your-cluster&quot;\n  GKE_REGION: &quot;us-central1&quot;\n  KSA_NAME: &quot;ai-agent-ksa&quot;\n\nbuild:\n  image: docker:24.0.5\n  stage: build\n  services:\n    - docker:24.0.5-dind\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  script:\n    - docker build -t $GITLAB_IMAGE .\n    - docker push $GITLAB_IMAGE\n\ninclude:\n  - template: Jobs/Dependency-Scanning.gitlab-ci.yml\n  - template: Jobs/Container-Scanning.gitlab-ci.yml\n  - template: Jobs/Secret-Detection.gitlab-ci.yml\n  - component: gitlab.com/google-gitlab-components/artifact-registry/upload-artifact-registry@main\n    inputs:\n      stage: upload\n      source: $GITLAB_IMAGE\n      target: $AR_IMAGE\n\ndeploy:\n  stage: deploy\n  image: google/cloud-sdk:slim\n  identity: google_cloud\n  before_script:\n    - apt-get update &amp;&amp; apt-get install -y kubectl google-cloud-sdk-gke-gcloud-auth-plugin\n    - gcloud container clusters get-credentials $GKE_CLUSTER --region $GKE_REGION --project $GCP_PROJECT_ID\n  script:\n    - |\n      kubectl apply -f - &lt;&lt;EOF\n      apiVersion: apps/v1\n      kind: Deployment\n      metadata:\n        name: ai-agent\n        namespace: default\n      spec:\n        replicas: 2\n        selector:\n          matchLabels:\n            app: ai-agent\n        template:\n          metadata:\n            labels:\n              app: ai-agent\n          spec:\n            serviceAccountName: $KSA_NAME\n            containers:\n            - name: ai-agent\n              image: $AR_IMAGE\n              ports:\n              - containerPort: 8080\n              resources:\n                requests: {cpu: 500m, memory: 1Gi}\n                limits: {cpu: 2000m, memory: 4Gi}\n              livenessProbe:\n                httpGet: {path: /health, port: 8080}\n                initialDelaySeconds: 60\n              readinessProbe:\n                httpGet: {path: /health, port: 8080}\n                initialDelaySeconds: 30\n      ---\n      apiVersion: v1\n      kind: Service\n      metadata:\n        name: ai-agent-service\n        namespace: default\n      spec:\n        type: LoadBalancer\n        ports:\n        - port: 80\n          targetPort: 8080\n        selector:\n          app: ai-agent\n      ---\n      apiVersion: autoscaling/v2\n      kind: HorizontalPodAutoscaler\n      metadata:\n        name: ai-agent-hpa\n        namespace: default\n      spec:\n        scaleTargetRef:\n          apiVersion: apps/v1\n          kind: Deployment\n          name: ai-agent\n        minReplicas: 2\n        maxReplicas: 10\n        metrics:\n        - type: Resource\n          resource:\n            name: cpu\n            target: {type: Utilization, averageUtilization: 70}\n      EOF\n      \n      kubectl rollout status deployment/ai-agent -n default --timeout=5m\n      EXTERNAL_IP=$(kubectl get service ai-agent-service -n default -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n      echo &quot;Deployed at: http://$EXTERNAL_IP&quot;\n  only:\n    - main\n</code></pre>\n<h4>The critical configuration for GKE</h4>\n<p>What makes this work â and why we need this extra configuration for GKEâ is that we must have a Kubernetes Service Account in the cluster that can work with Vertex AI. We need that service account to be permitted to access the AI capabilities of Google Cloud.</p>\n<p>Without this, we can deploy the application, but the AI agent won't work. We need to create a Kubernetes Service Account that can access Vertex AI.</p>\n<p>Run this one-time setup:</p>\n<pre><code class=\"language-bash\">\n\n#!/bin/bash\n\n\nPROJECT_ID=&quot;your-project-id&quot;\n\n\nGSA_NAME=&quot;ai-agent-vertex&quot;\n\n\nGSA_EMAIL=&quot;${GSA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com&quot;\n\n\nKSA_NAME=&quot;ai-agent-ksa&quot;\n\n\nCLUSTER_NAME=&quot;your-cluster&quot;\n\n\nREGION=&quot;us-central1&quot;\n\n\n\n# Create GCP Service Account\n\n\ngcloud iam service-accounts create $GSA_NAME \\\n    --display-name=&quot;AI Agent Vertex AI&quot; \\\n    --project=$PROJECT_ID\n\n# Grant Vertex AI permissions\n\n\ngcloud projects add-iam-policy-binding $PROJECT_ID \\\n    --member=&quot;serviceAccount:${GSA_EMAIL}&quot; \\\n    --role=&quot;roles/aiplatform.user&quot;\n\n# Get cluster credentials\n\n\ngcloud container clusters get-credentials $CLUSTER_NAME \\\n    --region $REGION --project $PROJECT_ID\n\n# Create Kubernetes Service Account\n\n\nkubectl create serviceaccount $KSA_NAME -n default\n\n\n\n# Link accounts\n\n\nkubectl annotate serviceaccount $KSA_NAME -n default \\\n    iam.gke.io/gcp-service-account=${GSA_EMAIL}\n\ngcloud iam service-accounts add-iam-policy-binding ${GSA_EMAIL} \\\n    --role=roles/iam.workloadIdentityUser \\\n    --member=&quot;serviceAccount:${PROJECT_ID}.svc.id.goog[default/${KSA_NAME}]&quot; \\\n    --project=$PROJECT_ID\n</code></pre>\n<h3>4. Deploy to GKE</h3>\n<p>Once you're done, push this change to the pipeline and you're good to go.</p>\n<p>You can see the pipeline has just deployed. Go to <strong>CI/CD &gt; Pipelines</strong> and you'll see the four stages:</p>\n<ul>\n<li>\n<p>Build</p>\n</li>\n<li>\n<p>Test (with all defined security scans)</p>\n</li>\n<li>\n<p>Upload to Artifact Registry (successful)</p>\n</li>\n<li>\n<p>Deploy to Kubernetes in GKE (success)</p>\n</li>\n</ul>\n<h2>Summary</h2>\n<p>With GitLab and Google Cloud together, you're able to deploy your AI agent to GKE with ease and security. We didn't have to go through a lot of steps â we were able to do that thanks to GitLab's native integration with Google Cloud.</p>\n<p>Watch this demo:</p>\n<p>&lt;!-- blank line --&gt;</p>\n<p>&lt;figure class=&quot;video_container&quot;&gt;\n&lt;iframe src=&quot;https://www.youtube.com/embed/mc2pCL5Qjus?si=QoH02lvz5KH5Ku9O&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt; &lt;/iframe&gt;\n&lt;/figure&gt;</p>\n<p>&lt;!-- blank line --&gt;</p>\n<blockquote>\n<p>Use this tutorial's <a href=\"https://gitlab.com/gitlab-partners-public/google-cloud/demos/gke-ai-agent\">complete code example</a> to get started now. Not a GitLab customer yet? Explore the DevSecOps platform with <a href=\"https://about.gitlab.com/free-trial/\">a free trial</a>. Startups hosted on Google Cloud have a <a href=\"https://about.gitlab.com/solutions/startups/google-cloud/\">special perk to try and use GitLab</a>.</p>\n</blockquote>\n",
      "summary": "Building AI agents is\nexciting, but deploying them securely to production shouldn't be\ncomplicated. In this tutorial, you will learn how GitLab's native Google Cloud integration makes it straightforward to deploy AI agents to Google Kubernetes Engine (GKE) â with built-in scanning and zero service account keys.\nWhy choose GKE to deploy your AI agents?\nGKE provides enterprise-grade orchestration that connects seamlessly with GitLab CI/CD pipelines through OIDC authentication. Your development team can deploy AI agents while maintaining complete visibility, compliance, and control over your cloud infrastructure. This guide uses Google's Agent Development Kit (ADK) to build the app, so you can expect increased seamlessness as this is deployed using GitLab.\nThree key advantages to this approach:\nFull infrastructure control - Your data, your rules, your environment. You maintain complete control over where your AI agents run and how they're configured.\nNative GitLab integration - No complex workarounds. Your existing pipelines work right out of the box thanks to GitLab's native integration with Google Cloud.\nProduction-grade scaling - GKE automatically handles the heavy lifting of scaling and internal orchestration as your AI workloads grow.\nThe key point is that GitLab with GKE provides the enterprise reliability your AI deployments demand without sacrificing the developer experience your teams expect.\nPrerequisites\nBefore you start, make sure you have these APIs enabled:\nGKE API\nArtifact Registry API\nVertex AI API\nAlso make sure you have:\nGitLab project created\nGKE cluster provisioned\nArtifact Registry repository created\nThe deployment process\n1. Set up IAM and permissions on GitLab\nNavigate to your GitLab integrations to configure Google Cloud authentication (IAM).\nGo to Settings > Integrations and configure the Google Cloud integration. If you're using a group-level integration, notice that default settings are already inherited by projects. This means you configure once at the group level, and all projects benefit and inherit this setting.\nTo set this up from scratch, provide:\nProject ID\nProject Number\nWorkload Identity Pool ID\nProvider ID\nOnce configured, GitLab provides a script to run in Google Cloud Console, via Cloud Shell. The outcome of running this script is a Workload Identity Federation pool with the necessary service principal to enable the proper access.\n2. Configure Artifact Registry integration\nStill in GitLab's integration settings, configure Artifact Management:\nClick Artifact Management.\nSelect Google Artifact Registry.\nProvide:\nProject ID\nRepository Name (created beforehand)\nRepository Location\nGitLab provides another script to run in Google Cloud Console.\nImportant: Before proceeding, add these extra roles to the Workload Identity Federation pool:\nService Account User\nKubernetes Developer\nKubernetes Cluster Viewer\nThese permissions allow GitLab to deploy to GKE in subsequent steps.\n3. Create the CI/CD pipeline\nNow for the key part â creating the CI/CD pipeline for deployment.\nHead to Build > Pipeline Editor and define your pipeline with four stages:\nBuild - Docker creates the container image.\nTest - GitLab Auto DevOps provides built-in security scans to ensure there are no vulnerabilities.\nUpload - Uses GitLab's built-in CI/CD component to push to Google Artifact Registry.\nDeploy - Uses Kubernetes configuration to deploy to GKE.\nHere's the complete .gitlab-ci.yml:\n\n\ndefault:\n  tags: [ saas-linux-2xlarge-amd64 ]\n\nstages:\n  - build\n  - test\n  - upload\n  - deploy\n\nvariables:\n  GITLAB_IMAGE: $CI_REGISTRY_IMAGE/main:$CI_COMMIT_SHORT_SHA\n  AR_IMAGE: $GOOGLE_ARTIFACT_REGISTRY_REPOSITORY_LOCATION-docker.pkg.dev/$GOOGLE_ARTIFACT_REGISTRY_PROJECT_ID/$GOOGLE_ARTIFACT_REGISTRY_REPOSITORY_NAME/main:$CI_COMMIT_SHORT_SHA\n  GCP_PROJECT_ID: \"your-project-id\"\n  GKE_CLUSTER: \"your-cluster\"\n  GKE_REGION: \"us-central1\"\n  KSA_NAME: \"ai-agent-ksa\"\n\nbuild:\n  image: docker:24.0.5\n  stage: build\n  services:\n    - docker:24.0.5-dind\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  script:\n    - docker build -t $GITLAB_IMAGE .\n    - docker push $GITLAB_IMAGE\n\ninclude:\n  - template: Jobs/Dependency-Scanning.gitlab-ci.yml\n  - template: Jobs/Container-Scanning.gitlab-ci.yml\n  - template: Jobs/Secret-Detection.gitlab-ci.yml\n  - component: gitlab.com/google-gitlab-components/artifact-registry/upload-artifact-registry@main\n    inputs:\n      stage: upload\n      source: $GITLAB_IMAGE\n      target: $AR_IMAGE\n\ndeploy:\n  stage: deploy\n  image: google/cloud-sdk:slim\n  identity: google_cloud\n  before_script:\n    - apt-get update && apt-get install -y kubectl google-cloud-sdk-gke-gcloud-auth-plugin\n    - gcloud container clusters get-credentials $GKE_CLUSTER --region $GKE_REGION --project $GCP_PROJECT_ID\n  script:\n    - |\n      kubectl apply -f - <<EOF\n      apiVersion: apps/v1\n      kind: Deployment\n      metadata:\n        name: ai-agent\n        namespace: default\n      spec:\n        replicas: 2\n        selector:\n          matchLabels:\n            app: ai-agent\n        template:\n          metadata:\n            labels:\n              app: ai-agent\n          spec:\n            serviceAccountName: $KSA_NAME\n            containers:\n            - name: ai-agent\n              image: $AR_IMAGE\n              ports:\n              - containerPort: 8080\n              resources:\n                requests: {cpu: 500m, memory: 1Gi}\n                limits: {cpu: 2000m, memory: 4Gi}\n              livenessProbe:\n                httpGet: {path: /health, port: 8080}\n                initialDelaySeconds: 60\n              readinessProbe:\n                httpGet: {path: /health, port: 8080}\n                initialDelaySeconds: 30\n      ---\n      apiVersion: v1\n      kind: Service\n      metadata:\n        name: ai-agent-service\n        namespace: default\n      spec:\n        type: LoadBalancer\n        ports:\n        - port: 80\n          targetPort: 8080\n        selector:\n          app: ai-agent\n      ---\n      apiVersion: autoscaling/v2\n      kind: HorizontalPodAutoscaler\n      metadata:\n        name: ai-agent-hpa\n        namespace: default\n      spec:\n        scaleTargetRef:\n          apiVersion: apps/v1\n          kind: Deployment\n          name: ai-agent\n        minReplicas: 2\n        maxReplicas: 10\n        metrics:\n        - type: Resource\n          resource:\n            name: cpu\n            target: {type: Utilization, averageUtilization: 70}\n      EOF\n      \n      kubectl rollout status deployment/ai-agent -n default --timeout=5m\n      EXTERNAL_IP=$(kubectl get service ai-agent-service -n default -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n      echo \"Deployed at: http://$EXTERNAL_IP\"\n  only:\n    - main\n\nThe critical configuration for GKE\nWhat makes this work â and why we need this extra configuration for GKEâ is that we must have a Kubernetes Service Account in the cluster that can work with Vertex AI. We need that service account to be permitted to access the AI capabilities of Google Cloud.\nWithout this, we can deploy the application, but the AI agent won't work. We need to create a Kubernetes Service Account that can access Vertex AI.\nRun this one-time setup:\n\n\n#!/bin/bash\n\n\nPROJECT_ID=\"your-project-id\"\n\n\nGSA_NAME=\"ai-agent-vertex\"\n\n\nGSA_EMAIL=\"${GSA_NAME}@${PROJECT_ID}.iam.gserviceaccount.com\"\n\n\nKSA_NAME=\"ai-agent-ksa\"\n\n\nCLUSTER_NAME=\"your-cluster\"\n\n\nREGION=\"us-central1\"\n\n\n\n# Create GCP Service Account\n\n\ngcloud iam service-accounts create $GSA_NAME \\\n    --display-name=\"AI Agent Vertex AI\" \\\n    --project=$PROJECT_ID\n\n# Grant Vertex AI permissions\n\n\ngcloud projects add-iam-policy-binding $PROJECT_ID \\\n    --member=\"serviceAccount:${GSA_EMAIL}\" \\\n    --role=\"roles/aiplatform.user\"\n\n# Get cluster credentials\n\n\ngcloud container clusters get-credentials $CLUSTER_NAME \\\n    --region $REGION --project $PROJECT_ID\n\n# Create Kubernetes Service Account\n\n\nkubectl create serviceaccount $KSA_NAME -n default\n\n\n\n# Link accounts\n\n\nkubectl annotate serviceaccount $KSA_NAME -n default \\\n    iam.gke.io/gcp-service-account=${GSA_EMAIL}\n\ngcloud iam service-accounts add-iam-policy-binding ${GSA_EMAIL} \\\n    --role=roles/iam.workloadIdentityUser \\\n    --member=\"serviceAccount:${PROJECT_ID}.svc.id.goog[default/${KSA_NAME}]\" \\\n    --project=$PROJECT_ID\n\n4. Deploy to GKE\nOnce you're done, push this change to the pipeline and you're good to go.\nYou can see the pipeline has just deployed. Go to CI/CD > Pipelines and you'll see the four stages:\nBuild\nTest (with all defined security scans)\nUpload to Artifact Registry (successful)\nDeploy to Kubernetes in GKE (success)\nSummary\nWith GitLab and Google Cloud together, you're able to deploy your AI agent to GKE with ease and security. We didn't have to go through a lot of steps â we were able to do that thanks to GitLab's native integration with Google Cloud.\nWatch this demo:\n<!-- blank line -->\n<figure class=\"video_container\">\n<iframe src=\"https://www.youtube.com/embed/mc2pCL5Qjus?si=QoH02lvz5KH5Ku9O\" frameborder=\"0\" allowfullscreen=\"true\"> </iframe>\n</figure>\n<!-- blank line -->\nUse this tutorial's complete code example to get started now. Not a GitLab customer yet? Explore the DevSecOps platform with a free trial. Startups hosted on Google Cloud have a special perk to try and use GitLab.",
      "publishedAt": "2025-11-10T00:00:00.000Z",
      "author": "Regnard Raquedan",
      "source": "rss",
      "feedName": "GitLab Blog",
      "sourceType": "platform_blog",
      "company": "GitLab",
      "contentType": "feature_update",
      "tags": [
        "code_review",
        "retrieval",
        "agents",
        "ide",
        "observability",
        "governance"
      ],
      "ingestedAt": "2025-11-21T18:34:16.877Z",
      "score": 10.566482285933704
    },
    {
      "id": "985131f8ceb79cd47bb3ef57884a8bfb",
      "title": "How Jimdo empower solopreneurs with AI-powered business assistance",
      "url": "https://blog.langchain.com/customers-jimdo/",
      "content": "See how Jimdo uses LangChain.js, LangGraph.js, and LangSmith to deliver personalized business insights that drive 50% more first customer contacts and 40% more overall customer activity.",
      "summary": "See how Jimdo uses LangChain.js, LangGraph.js, and LangSmith to deliver personalized business insights that drive 50% more first customer contacts and 40% more overall customer activity.",
      "publishedAt": "2025-11-20T01:47:31.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "sourceType": "platform_blog",
      "company": "LangChain",
      "contentType": "feature_update",
      "tags": [
        "code_review",
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:17.212Z",
      "score": 11.514208425591073
    },
    {
      "id": "b27ae2bc05a737f23fcecb6269b3a5da",
      "title": "How ServiceNow uses LangSmith to get visibility into its customer success agents",
      "url": "https://blog.langchain.com/customers-servicenow/",
      "content": "<p><strong>Authors: </strong><em>Ganesh Srinivasan (ServiceNow), Linda Ye (LangChain), and Jake Broekhuizen (LangChain)</em></p><p>ServiceNow is a leading digital workflow platform that helps enterprises transform service management across IT, customer service, and other departments. To improve their internal sales and customer success operations, ServiceNow&apos;s AI team is using LangSmith and LangGraph</p>",
      "summary": "Authors: Ganesh Srinivasan (ServiceNow), Linda Ye (LangChain), and Jake Broekhuizen (LangChain)\nServiceNow is a leading digital workflow platform that helps enterprises transform service management across IT, customer service, and other departments. To improve their internal sales and customer success operations, ServiceNow's AI team is using LangSmith and LangGraph",
      "publishedAt": "2025-11-17T22:42:50.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "sourceType": "platform_blog",
      "company": "LangChain",
      "contentType": "feature_update",
      "tags": [
        "code_review",
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:17.212Z",
      "score": 11.411990594458743
    },
    {
      "id": "8f5798e972d05abecb217992caf57325",
      "title": "Execute Code with Sandboxes for DeepAgents",
      "url": "https://blog.langchain.com/execute-code-with-sandboxes-for-deepagents/",
      "content": "<p>By Vivek Trivedy</p><p>Today we&apos;re excited to launch Sandboxes for DeepAgents, a new set of integrations that allow you to safely execute arbitrary DeepAgent code in remote sandboxes. We currently support sandboxes from 3 of our partners: <a href=\"https://www.runloop.ai/?ref=blog.langchain.com\">Runloop</a>, <a href=\"https://www.daytona.io/?ref=blog.langchain.com\">Daytona</a>, and <a href=\"https://modal.com/?ref=blog.langchain.com\">Modal</a>. Below, we dive into what you can</p>",
      "summary": "By Vivek Trivedy\nToday we're excited to launch Sandboxes for DeepAgents, a new set of integrations that allow you to safely execute arbitrary DeepAgent code in remote sandboxes. We currently support sandboxes from 3 of our partners: Runloop, Daytona, and Modal. Below, we dive into what you can",
      "publishedAt": "2025-11-13T16:22:20.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "sourceType": "platform_blog",
      "company": "LangChain",
      "contentType": "product_launch",
      "tags": [
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:17.212Z",
      "score": 6.171373281981025
    },
    {
      "id": "bfe9dd799455d3b59dc1944a15f55f52",
      "title": "Join LangChain at AWS re:Invent 2025",
      "url": "https://blog.langchain.com/join-langchain-at-aws-re-invent-2025/",
      "content": "<p>If you&apos;re attending AWS re:Invent in Las Vegas this year and working on agent development, here&apos;s what we have planned:</p><h2 id=\"visit-us-at-booth-524\">Visit Us at Booth #524</h2><p>We&apos;ll be at Booth #524 in the Venetian Expo Center, next to the Industry Pavilion, December 1-4. Our</p>",
      "summary": "If you're attending AWS re:Invent in Las Vegas this year and working on agent development, here's what we have planned:\nVisit Us at Booth #524\nWe'll be at Booth #524 in the Venetian Expo Center, next to the Industry Pavilion, December 1-4. Our",
      "publishedAt": "2025-11-11T00:58:44.000Z",
      "author": "LangChain",
      "source": "rss",
      "feedName": "LangChain Blog",
      "sourceType": "platform_blog",
      "company": "LangChain",
      "contentType": "general",
      "tags": [
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:17.212Z",
      "score": 2.3228465433754844
    },
    {
      "id": "4ca1404851c2e19e589f8054a6f04504",
      "title": "Deploy geospatial agents with Foursquare Spatial H3 Hub and Amazon SageMaker AI",
      "url": "https://aws.amazon.com/blogs/machine-learning/deploy-geospatial-agents-with-foursquare-spatial-h3-hub-and-amazon-sagemaker-ai/",
      "content": "In this post, you'll learn how to deploy geospatial AI agents that can answer complex spatial questions in minutes instead of months. By combining Foursquare Spatial H3 Hub's analysis-ready geospatial data with reasoning models deployed on Amazon SageMaker AI, you can build agents that enable nontechnical domain experts to perform sophisticated spatial analysis through natural language queriesâwithout requiring geographic information system (GIS) expertise or custom data engineering pipelines.",
      "summary": "In this post, you'll learn how to deploy geospatial AI agents that can answer complex spatial questions in minutes instead of months. By combining Foursquare Spatial H3 Hub's analysis-ready geospatial data with reasoning models deployed on Amazon SageMaker AI, you can build agents that enable nontechnical domain experts to perform sophisticated spatial analysis through natural language queriesâwithout requiring geographic information system (GIS) expertise or custom data engineering pipelines.",
      "publishedAt": "2025-11-21T17:15:31.000Z",
      "author": "Vikram Gundeti",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "feature_update",
      "tags": [
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 9.961002050467435
    },
    {
      "id": "f6e1d86180ce547dac4c6efd2f47050d",
      "title": "How Wipro PARI accelerates PLC code generation using Amazon Bedrock",
      "url": "https://aws.amazon.com/blogs/machine-learning/how-wipro-pari-accelerates-plc-code-generation-using-amazon-bedrock/",
      "content": "In this post, we share how Wipro implemented advanced prompt engineering techniques, custom validation logic, and automated code rectification to streamline the development of industrial automation code at scale using Amazon Bedrock. We walk through the architecture along with the key use cases, explain core components and workflows, and share real-world results that show the transformative impact on manufacturing operations.",
      "summary": "In this post, we share how Wipro implemented advanced prompt engineering techniques, custom validation logic, and automated code rectification to streamline the development of industrial automation code at scale using Amazon Bedrock. We walk through the architecture along with the key use cases, explain core components and workflows, and share real-world results that show the transformative impact on manufacturing operations.",
      "publishedAt": "2025-11-21T16:10:26.000Z",
      "author": "Aparajithan Vaidyanathan",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "general",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 5.957337840896191
    },
    {
      "id": "fd1ecf3769b9412e73a1452f3e495ff3",
      "title": "MSD explores applying generative Al to improve the deviation management process using AWS services",
      "url": "https://aws.amazon.com/blogs/machine-learning/msd-explores-applying-generative-al-to-improve-the-deviation-management-process-using-aws-services/",
      "content": "This blog post has explores how MSD is harnessing the power of generative AI and databases to optimize and transform its manufacturing deviation management process. By creating an accurate and multifaceted knowledge base of past events, deviations, and findings, the company aims to significantly reduce the time and effort required for each new case while maintaining the highest standards of quality and compliance.",
      "summary": "This blog post has explores how MSD is harnessing the power of generative AI and databases to optimize and transform its manufacturing deviation management process. By creating an accurate and multifaceted knowledge base of past events, deviations, and findings, the company aims to significantly reduce the time and effort required for each new case while maintaining the highest standards of quality and compliance.",
      "publishedAt": "2025-11-20T18:21:49.000Z",
      "author": "Hossein Salami, Jwalant (JD) Vyas,",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "general",
      "tags": [
        "code_review",
        "governance"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 9.304868828022913
    },
    {
      "id": "5c953a086281b4d8d7be39594a24e441",
      "title": "Accelerating genomics variant interpretation with AWS HealthOmics and Amazon Bedrock AgentCore",
      "url": "https://aws.amazon.com/blogs/machine-learning/accelerating-genomics-variant-interpretation-with-aws-healthomics-and-amazon-bedrock-agentcore/",
      "content": "In this blog post, we show you how agentic workflows can accelerate the processing and interpretation of genomics pipelines at scale with a natural language interface. We demonstrate a comprehensive genomic variant interpreter agent that combines automated data processing with intelligent analysis to address the entire workflow from raw VCF file ingestion to conversational query interfaces.",
      "summary": "In this blog post, we show you how agentic workflows can accelerate the processing and interpretation of genomics pipelines at scale with a natural language interface. We demonstrate a comprehensive genomic variant interpreter agent that combines automated data processing with intelligent analysis to address the entire workflow from raw VCF file ingestion to conversational query interfaces.",
      "publishedAt": "2025-11-20T18:18:21.000Z",
      "author": "Edwin Sandanaraj",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "general",
      "tags": [
        "code_review",
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 7.4426151376027
    },
    {
      "id": "e3e46e3755764cb5a5eb8ac39483feec",
      "title": "How Rufus scales conversational shopping experiences to millions of Amazon customers with Amazon Bedrock",
      "url": "https://aws.amazon.com/blogs/machine-learning/how-rufus-scales-conversational-shopping-experiences-to-millions-of-amazon-customers-with-amazon-bedrock/",
      "content": "Our team at Amazon builds Rufus, an AI-powered shopping assistant which delivers intelligent, conversational experiences to delight our customers. More than 250 million customers have used Rufus this year. Monthly users are up 140% YoY and interactions are up 210% YoY. Additionally, customers that use Rufus during a shopping journey are 60% more likely to [â¦]",
      "summary": "Our team at Amazon builds Rufus, an AI-powered shopping assistant which delivers intelligent, conversational experiences to delight our customers. More than 250 million customers have used Rufus this year. Monthly users are up 140% YoY and interactions are up 210% YoY. Additionally, customers that use Rufus during a shopping journey are 60% more likely to [â¦]",
      "publishedAt": "2025-11-20T18:13:39.000Z",
      "author": "James Park",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "general",
      "tags": [],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 2.7903300773841244
    },
    {
      "id": "9467b0c18a8bb2562ae3c7f74a1b9f56",
      "title": "How Care Access achieved 86% data processing cost reductions and 66% faster data processing with Amazon Bedrock prompt caching",
      "url": "https://aws.amazon.com/blogs/machine-learning/how-care-access-achieved-86-data-processing-cost-reductions-and-66-faster-data-processing-with-amazon-bedrock-prompt-caching/",
      "content": "In this post, we demonstrate how healthcare organizations can securely implement prompt caching technology to streamline medical record processing while maintaining compliance requirements.",
      "summary": "In this post, we demonstrate how healthcare organizations can securely implement prompt caching technology to streamline medical record processing while maintaining compliance requirements.",
      "publishedAt": "2025-11-20T16:15:04.000Z",
      "author": "Michelle Tat, Christopher Penrose, Daniel Hansen, Rasmus Buchmann",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "general",
      "tags": [
        "code_review",
        "governance"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 9.246550755439364
    },
    {
      "id": "16ee57334b6b9d736883a100f730ca17",
      "title": "Claude Code deployment patterns and best practices with Amazon Bedrock",
      "url": "https://aws.amazon.com/blogs/machine-learning/claude-code-deployment-patterns-and-best-practices-with-amazon-bedrock/",
      "content": "In this post, we explore deployment patterns and best practices for Claude Code with Amazon Bedrock, covering authentication methods, infrastructure decisions, and monitoring strategies to help enterprises deploy securely at scale. We recommend using Direct IdP integration for authentication, a dedicated AWS account for infrastructure, and OpenTelemetry with CloudWatch dashboards for comprehensive monitoring to ensure secure access, capacity management, and visibility into costs and developer productivity .",
      "summary": "In this post, we explore deployment patterns and best practices for Claude Code with Amazon Bedrock, covering authentication methods, infrastructure decisions, and monitoring strategies to help enterprises deploy securely at scale. We recommend using Direct IdP integration for authentication, a dedicated AWS account for infrastructure, and OpenTelemetry with CloudWatch dashboards for comprehensive monitoring to ensure secure access, capacity management, and visibility into costs and developer productivity .",
      "publishedAt": "2025-11-19T23:17:38.000Z",
      "author": "Court Schuett",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "pricing_business",
      "tags": [
        "code_review",
        "observability"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 12.30806703644581
    },
    {
      "id": "549f0cddbc1ebf95bb1aac474406df62",
      "title": "Amazon Bedrock Guardrails expands support for code domain",
      "url": "https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-guardrails-expands-support-for-code-domain/",
      "content": "Amazon Bedrock Guardrails now extends its safety controls to protect code generation across twelve programming languages, addressing critical security challenges in AI-assisted software development. In this post, we explore how to configure content filters, prompt attack detection, denied topics, and sensitive information filters to safeguard against threats like prompt injection, data exfiltration, and malicious code generation while maintaining developer productivity .",
      "summary": "Amazon Bedrock Guardrails now extends its safety controls to protect code generation across twelve programming languages, addressing critical security challenges in AI-assisted software development. In this post, we explore how to configure content filters, prompt attack detection, denied topics, and sensitive information filters to safeguard against threats like prompt injection, data exfiltration, and malicious code generation while maintaining developer productivity .",
      "publishedAt": "2025-11-19T22:27:14.000Z",
      "author": "Phu Mon Htut",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "feature_update",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 8.769525213951393
    },
    {
      "id": "4c5cccb00630d86db3f973d051092b48",
      "title": "Announcing the AWS Well-Architected Responsible AI LensÂ ",
      "url": "https://aws.amazon.com/blogs/machine-learning/announcing-the-aws-well-architected-responsible-ai-lens/",
      "content": "Today, we're announcing the AWS Well-Architected Responsible AI Lensâa set of thoughtful questions and corresponding best practices that help builders address responsible AI concerns throughout development and operation.",
      "summary": "Today, we're announcing the AWS Well-Architected Responsible AI Lensâa set of thoughtful questions and corresponding best practices that help builders address responsible AI concerns throughout development and operation.",
      "publishedAt": "2025-11-19T20:03:54.000Z",
      "author": "Rachna Chadha",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "product_launch",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 10.448876240488588
    },
    {
      "id": "1d75a849cd250713a502a13fc77c77f8",
      "title": "How Amazon uses AI agents to support compliance screening of billions of transactions per day",
      "url": "https://aws.amazon.com/blogs/machine-learning/how-amazon-uses-ai-agents-to-support-compliance-screening-of-billions-of-transactions-per-day/",
      "content": "Amazon's AI-powered Amazon Compliance Screening system tackles complex compliance challenges through autonomous agents that analyze, reason through, and resolve cases with precision. This blog post explores how Amazonâs Compliance team built its AI-powered investigation system through a series of AI agents built on AWS.",
      "summary": "Amazon's AI-powered Amazon Compliance Screening system tackles complex compliance challenges through autonomous agents that analyze, reason through, and resolve cases with precision. This blog post explores how Amazonâs Compliance team built its AI-powered investigation system through a series of AI agents built on AWS.",
      "publishedAt": "2025-11-19T19:39:18.000Z",
      "author": "Damodar Shetyo",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "feature_update",
      "tags": [
        "code_review",
        "agents",
        "governance"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 14.784523024395806
    },
    {
      "id": "ef99d395f9160940225a8148bb56c048",
      "title": "Build an agentic solution with Amazon Nova, Snowflake, and LangGraph",
      "url": "https://aws.amazon.com/blogs/machine-learning/build-an-agentic-solution-with-amazon-nova-snowflake-and-langgraph/",
      "content": "In this post, we cover how you can use tools from Snowflake AI Data Cloud and Amazon Web Services (AWS) to build generative AI solutions that organizations can use to make data-driven decisions, increase operational efficiency, and ultimately gain a competitive edge.",
      "summary": "In this post, we cover how you can use tools from Snowflake AI Data Cloud and Amazon Web Services (AWS) to build generative AI solutions that organizations can use to make data-driven decisions, increase operational efficiency, and ultimately gain a competitive edge.",
      "publishedAt": "2025-11-19T16:16:49.000Z",
      "author": "Bharath Suresh, Mary Law",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "feature_update",
      "tags": [
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 8.609866600849637
    },
    {
      "id": "ca1ccde5b9583bf95b8804c6e5e5266f",
      "title": "Using Spectrum fine-tuning to improve FM training efficiency on Amazon SageMaker AI",
      "url": "https://aws.amazon.com/blogs/machine-learning/using-spectrum-fine-tuning-to-improve-fm-training-efficiency-on-amazon-sagemaker-ai/",
      "content": "In this post you will learn how to use Spectrum to optimize resource use and shorten training times without sacrificing quality, as well as how to implement Spectrum fine-tuning with Amazon SageMaker AI training jobs. We will also discuss the tradeoff between QLoRA and Spectrum fine-tuning, showing that while QLoRA is more resource efficient, Spectrum results in higher performance overall.",
      "summary": "In this post you will learn how to use Spectrum to optimize resource use and shorten training times without sacrificing quality, as well as how to implement Spectrum fine-tuning with Amazon SageMaker AI training jobs. We will also discuss the tradeoff between QLoRA and Spectrum fine-tuning, showing that while QLoRA is more resource efficient, Spectrum results in higher performance overall.",
      "publishedAt": "2025-11-19T15:51:40.000Z",
      "author": "Mona Mona",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "security_incident",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 7.739219086597517
    },
    {
      "id": "a145fd57a965cb475bd848fdad15c9a8",
      "title": "Bringing tic-tac-toe to life with AWS AI services",
      "url": "https://aws.amazon.com/blogs/machine-learning/bringing-tic-tac-toe-to-life-with-aws-ai-services/",
      "content": "RoboTic-Tac-Toe is an interactive game where two physical robots move around a tic-tac-toe board, with both the gameplay and robotsâ movements orchestrated by LLMs. Players can control the robots using natural language commands, directing them to place their markers on the game board. In this post, we explore the architecture and prompt engineering techniques used to reason about a tic-tac-toe game and decide the next best game strategy and movement plan for the current player.",
      "summary": "RoboTic-Tac-Toe is an interactive game where two physical robots move around a tic-tac-toe board, with both the gameplay and robotsâ movements orchestrated by LLMs. Players can control the robots using natural language commands, directing them to place their markers on the game board. In this post, we explore the architecture and prompt engineering techniques used to reason about a tic-tac-toe game and decide the next best game strategy and movement plan for the current player.",
      "publishedAt": "2025-11-18T22:08:57.000Z",
      "author": "Georges Hamieh",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "general",
      "tags": [
        "code_review",
        "ide"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 5.710303877086684
    },
    {
      "id": "b489465dbe7638a6063cfd22a31cbfbf",
      "title": "HyperPod enhances ML infrastructure with security and storage",
      "url": "https://aws.amazon.com/blogs/machine-learning/hyperpod-enhances-ml-infrastructure-with-security-and-storage/",
      "content": "This blog post introduces two major enhancements to Amazon SageMaker HyperPod that strengthen security and storage capabilities for large-scale machine learning infrastructure. The new features include customer managed key (CMK) support for encrypting EBS volumes with organization-controlled encryption keys, and Amazon EBS CSI driver integration that enables dynamic storage management for Kubernetes volumes in AI workloads.",
      "summary": "This blog post introduces two major enhancements to Amazon SageMaker HyperPod that strengthen security and storage capabilities for large-scale machine learning infrastructure. The new features include customer managed key (CMK) support for encrypting EBS volumes with organization-controlled encryption keys, and Amazon EBS CSI driver integration that enables dynamic storage management for Kubernetes volumes in AI workloads.",
      "publishedAt": "2025-11-18T17:54:27.000Z",
      "author": "Mark Vinciguerra",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "feature_update",
      "tags": [
        "retrieval"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 9.263529384102926
    },
    {
      "id": "b503e4378213b493ad64a7757fa7e367",
      "title": "Accelerating generative AI applications with a platform engineering approach",
      "url": "https://aws.amazon.com/blogs/machine-learning/accelerating-generative-ai-applications-with-a-platform-engineering-approach/",
      "content": "In this post, I will illustrate how applying platform engineering principles to generative AI unlocks faster time-to-value, cost control, and scalable innovation.",
      "summary": "In this post, I will illustrate how applying platform engineering principles to generative AI unlocks faster time-to-value, cost control, and scalable innovation.",
      "publishedAt": "2025-11-18T17:04:13.000Z",
      "author": "Thong Seng Foo",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "general",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 4.821117849167257
    },
    {
      "id": "3a043e42c8b456294b46e4adeabc8d93",
      "title": "Your complete guide to Amazon Quick Suite at AWS re:Invent 2025",
      "url": "https://aws.amazon.com/blogs/machine-learning/your-complete-guide-to-amazon-quick-suite-at-aws-reinvent-2025/",
      "content": "This year, re:Invent will be held in Las Vegas, Nevada, from December 1 to December 5, 2025, and this guide will help you navigate our comprehensive session catalog and plan your week. The sessions cater to business and technology leaders, product and engineering teams, and data and analytics teams interested in incorporating agentic AI capabilities across their teams and organization.",
      "summary": "This year, re:Invent will be held in Las Vegas, Nevada, from December 1 to December 5, 2025, and this guide will help you navigate our comprehensive session catalog and plan your week. The sessions cater to business and technology leaders, product and engineering teams, and data and analytics teams interested in incorporating agentic AI capabilities across their teams and organization.",
      "publishedAt": "2025-11-17T19:26:56.000Z",
      "author": "Pelak Desai",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "thought_leadership",
      "tags": [
        "code_review",
        "agents",
        "ide"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 6.404258390784997
    },
    {
      "id": "0e611a498ed801f9291257a057a7dc7e",
      "title": "Accelerate enterprise solutions with agentic AI-powered consulting: Introducing AWS Professional Service Agents",
      "url": "https://aws.amazon.com/blogs/machine-learning/accelerate-enterprise-solutions-with-agentic-ai-powered-consulting-introducing-aws-professional-service-agents/",
      "content": "I'm excited to announce AWS Professional Services now offers specialized AI agents including the AWS Professional Services Delivery Agent. This represents a transformation to the consulting experience that embeds intelligent agents throughout the consulting life cycle to deliver better value for customers.",
      "summary": "I'm excited to announce AWS Professional Services now offers specialized AI agents including the AWS Professional Services Delivery Agent. This represents a transformation to the consulting experience that embeds intelligent agents throughout the consulting life cycle to deliver better value for customers.",
      "publishedAt": "2025-11-17T19:01:27.000Z",
      "author": "Francessca Vasquez",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "product_launch",
      "tags": [
        "code_review",
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 12.039845976792531
    },
    {
      "id": "94bbe532461f51a938bb68d767dd346c",
      "title": "Amazon Bedrock AgentCore and Claude: Transforming business with agentic AI",
      "url": "https://aws.amazon.com/blogs/machine-learning/amazon-bedrock-agentcore-and-claude-transforming-business-with-agentic-ai/",
      "content": "In this post, we explore how Amazon Bedrock AgentCore and Claude are enabling enterprises like Cox Automotive and Druva to deploy production-ready agentic AI systems that deliver measurable business value, with results including up to 63% autonomous issue resolution and 58% faster response times. We examine the technical foundation combining Claude's frontier AI capabilities with AgentCore's enterprise-grade infrastructure that allows organizations to focus on agent logic rather than building complex operational systems from scratch.",
      "summary": "In this post, we explore how Amazon Bedrock AgentCore and Claude are enabling enterprises like Cox Automotive and Druva to deploy production-ready agentic AI systems that deliver measurable business value, with results including up to 63% autonomous issue resolution and 58% faster response times. We examine the technical foundation combining Claude's frontier AI capabilities with AgentCore's enterprise-grade infrastructure that allows organizations to focus on agent logic rather than building complex operational systems from scratch.",
      "publishedAt": "2025-11-17T18:20:41.000Z",
      "author": "Jawhny Cooke",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "pricing_business",
      "tags": [
        "code_review",
        "agents"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 9.011643096425123
    },
    {
      "id": "f463decb2833d1ef4d5e0c39b70b8408",
      "title": "Build a biomedical research agent with Biomni tools and Amazon Bedrock AgentCore Gateway",
      "url": "https://aws.amazon.com/blogs/machine-learning/build-a-biomedical-research-agent-with-biomni-tools-and-amazon-bedrock-agentcore-gateway/",
      "content": "In this post, we demonstrate how to build a production-ready biomedical research agent by integrating Biomni's specialized tools with Amazon Bedrock AgentCore Gateway, enabling researchers to access over 30 biomedical databases through a secure, scalable infrastructure. The implementation showcases how to transform research prototypes into enterprise-grade systems with persistent memory, semantic tool discovery, and comprehensive observability for scientific reproducibility .",
      "summary": "In this post, we demonstrate how to build a production-ready biomedical research agent by integrating Biomni's specialized tools with Amazon Bedrock AgentCore Gateway, enabling researchers to access over 30 biomedical databases through a secure, scalable infrastructure. The implementation showcases how to transform research prototypes into enterprise-grade systems with persistent memory, semantic tool discovery, and comprehensive observability for scientific reproducibility .",
      "publishedAt": "2025-11-14T18:28:42.000Z",
      "author": "Hasan Poonawala",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "pricing_business",
      "tags": [
        "code_review",
        "agents",
        "observability"
      ],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 7.882712449672482
    },
    {
      "id": "f0033d0b34f811b000b65ae249f5d018",
      "title": "Make your web apps hands-free with Amazon Nova Sonic",
      "url": "https://aws.amazon.com/blogs/machine-learning/make-your-web-apps-hands-free-with-amazon-nova-sonic/",
      "content": "Graphical user interfaces have carried the torch for decades, but todayâs users increasingly expect to talk to their applications. In this post we show how we added a true voice-first experience to a reference applicationâthe&nbsp;Smart&nbsp;Todo&nbsp;Appâturning routine task management into a fluid, hands-free conversation.",
      "summary": "Graphical user interfaces have carried the torch for decades, but todayâs users increasingly expect to talk to their applications. In this post we show how we added a true voice-first experience to a reference applicationâtheÂ SmartÂ TodoÂ Appâturning routine task management into a fluid, hands-free conversation.",
      "publishedAt": "2025-11-14T18:18:54.000Z",
      "author": "Manu Mishra",
      "source": "rss",
      "feedName": "AWS Machine Learning",
      "sourceType": "platform_blog",
      "company": "AWS",
      "contentType": "general",
      "tags": [],
      "ingestedAt": "2025-11-21T18:34:17.414Z",
      "score": 1.818203424639784
    },
    {
      "id": "4d6c298a97dc39c7c8ac85d557d60e3c",
      "title": "MMCTAgent: Enabling multimodal reasoning over large video and image collections",
      "url": "https://www.microsoft.com/en-us/research/blog/mmctagent-enabling-multimodal-reasoning-over-large-video-and-image-collections/",
      "content": "<p>MMCTAgent enables dynamic multimodal reasoning with iterative planning and reflection. Built on Microsoftâs AutoGen framework, it integrates language, vision, and temporal understanding for complex tasks like long video and image analysis.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/research/blog/mmctagent-enabling-multimodal-reasoning-over-large-video-and-image-collections/\">MMCTAgent: Enabling multimodal reasoning over large video and image collections</a> appeared first on <a href=\"https://www.microsoft.com/en-us/research\">Microsoft Research</a>.</p>\n",
      "summary": "MMCTAgent enables dynamic multimodal reasoning with iterative planning and reflection. Built on Microsoftâs AutoGen framework, it integrates language, vision, and temporal understanding for complex tasks like long video and image analysis.\nThe post MMCTAgent: Enabling multimodal reasoning over large video and image collections appeared first on Microsoft Research.",
      "publishedAt": "2025-11-12T12:00:20.000Z",
      "author": "Akshay Nambi, Kavyansh Chourasia, Tanuja Ganu",
      "source": "rss",
      "feedName": "Microsoft Research",
      "sourceType": "platform_blog",
      "company": "Microsoft",
      "contentType": "general",
      "tags": [
        "agents",
        "ide"
      ],
      "ingestedAt": "2025-11-21T18:34:18.108Z",
      "score": 3.093676655469036
    },
    {
      "id": "e1538e7bb48330e25154b09b08d7ed03",
      "title": "BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI",
      "url": "https://www.microsoft.com/en-us/research/blog/bluecodeagent-a-blue-teaming-agent-enabled-by-automated-red-teaming-for-codegen-ai/",
      "content": "<p>BlueCodeAgent is an end-to-end blue-teaming framework built to boost code security using automated red-teaming processes, data, and safety rules to guide LLMsâ defensive decisions. Dynamic testing reduces false positives in vulnerability detection.</p>\n<p>The post <a href=\"https://www.microsoft.com/en-us/research/blog/bluecodeagent-a-blue-teaming-agent-enabled-by-automated-red-teaming-for-codegen-ai/\">BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI</a> appeared first on <a href=\"https://www.microsoft.com/en-us/research\">Microsoft Research</a>.</p>\n",
      "summary": "BlueCodeAgent is an end-to-end blue-teaming framework built to boost code security using automated red-teaming processes, data, and safety rules to guide LLMsâ defensive decisions. Dynamic testing reduces false positives in vulnerability detection.\nThe post BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI appeared first on Microsoft Research.",
      "publishedAt": "2025-11-11T17:00:00.000Z",
      "author": "Chengquan Guo , Yuzhou  Nie, Chulin Xie, Zinan Lin, Wenbo Guo, Bo Li",
      "source": "rss",
      "feedName": "Microsoft Research",
      "sourceType": "platform_blog",
      "company": "Microsoft",
      "contentType": "security_incident",
      "tags": [
        "code_review",
        "agents",
        "ide",
        "testing"
      ],
      "ingestedAt": "2025-11-21T18:34:18.108Z",
      "score": 7.552484945692301
    },
    {
      "id": "da21d94c1b895f9173f86a57a9bcf109",
      "title": "FAWK: LLMs can write a language interpreter",
      "url": "https://martin.janiczek.cz/2025/11/21/fawk-llms-can-write-a-language-interpreter.html",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46003144\">Comments</a>",
      "summary": "Comments",
      "publishedAt": "2025-11-21T10:28:49.000Z",
      "source": "rss",
      "feedName": "Hacker News",
      "sourceType": "curated_ai",
      "contentType": "general",
      "tags": [
        "code_review"
      ],
      "ingestedAt": "2025-11-21T18:34:18.463Z",
      "score": 4.881028789236497
    },
    {
      "id": "833faba5ebe23fe2e84e119a2cb19cfa",
      "title": "McDonald's is losing its low-income customers: a symptom of the wealth divide",
      "url": "https://www.latimes.com/business/story/2025-11-16/mcdonalds-is-losing-its-low-income-customers",
      "content": "<a href=\"https://news.ycombinator.com/item?id=46006848\">Comments</a>",
      "summary": "Comments",
      "publishedAt": "2025-11-21T17:52:37.000Z",
      "source": "rss",
      "feedName": "Hacker News",
      "sourceType": "curated_ai",
      "contentType": "general",
      "tags": [
        "ide"
      ],
      "ingestedAt": "2025-11-21T18:34:18.463Z",
      "score": 2.9938023852708984
    },
    {
      "id": "1e802ce4ceb9c901e8602ad55232d70d",
      "title": "Bringing RAG to Life with Dify and Weaviate",
      "url": "https://weaviate.io/blog/dify-and-weaviate",
      "content": "Learn how to use the Dify and Weaviate integration to build RAG applications.",
      "summary": "Learn how to use the Dify and Weaviate integration to build RAG applications.",
      "publishedAt": "2025-11-20T00:00:00.000Z",
      "source": "rss",
      "feedName": "Weaviate Blog",
      "sourceType": "infra_blog",
      "company": "Weaviate",
      "contentType": "thought_leadership",
      "tags": [
        "retrieval"
      ],
      "ingestedAt": "2025-11-21T18:34:18.581Z",
      "score": 5.7264758561705404
    },
    {
      "id": "e3af55eae5673c9951805a293075367c",
      "title": "Weaviate 1.34 Release",
      "url": "https://weaviate.io/blog/weaviate-1-34-release",
      "content": "1.34 introduces flat index support with RQ quantization, server-side batching improvements, new client libraries, Contextual AI integration and much more.",
      "summary": "1.34 introduces flat index support with RQ quantization, server-side batching improvements, new client libraries, Contextual AI integration and much more.",
      "publishedAt": "2025-11-11T00:00:00.000Z",
      "source": "rss",
      "feedName": "Weaviate Blog",
      "sourceType": "infra_blog",
      "company": "Weaviate",
      "contentType": "general",
      "tags": [
        "code_review",
        "retrieval",
        "ide"
      ],
      "ingestedAt": "2025-11-21T18:34:18.581Z",
      "score": 5.095390261648643
    },
    {
      "id": "ee5dc5979a50f2a3c79f70d9f7d81c49",
      "title": "Exploring the Fragmentation of Wayland, an xdotool adventure",
      "url": "https://www.semicomplete.com/blog/xdotool-and-exploring-wayland-fragmentation/",
      "content": "<p><a href=\"https://lobste.rs/s/gtbhhc/exploring_fragmentation_wayland\">Comments</a></p>",
      "summary": "Comments",
      "publishedAt": "2025-11-21T04:29:04.000Z",
      "author": "semicomplete.com via alexandria",
      "source": "rss",
      "feedName": "Lobste.rs",
      "sourceType": "curated_ai",
      "contentType": "general",
      "tags": [
        "retrieval"
      ],
      "ingestedAt": "2025-11-21T18:34:18.816Z",
      "score": 3.356289463030911
    },
    {
      "id": "e82eec764ca6827be912820066467c26",
      "title": "How Slide Rules Work",
      "url": "https://amenzwa.github.io/stem/ComputingHistory/HowSlideRulesWork/",
      "content": "<p><a href=\"https://lobste.rs/s/smkwo1/how_slide_rules_work\">Comments</a></p>",
      "summary": "Comments",
      "publishedAt": "2025-11-20T22:01:00.000Z",
      "author": "amenzwa.github.io via fanf",
      "source": "rss",
      "feedName": "Lobste.rs",
      "sourceType": "curated_ai",
      "contentType": "general",
      "tags": [
        "ide"
      ],
      "ingestedAt": "2025-11-21T18:34:18.816Z",
      "score": 2.821972246884597
    }
  ],
  "lastSync": "2025-11-21T18:34:18.816Z"
}